{
 "metadata": {
  "name": "",
  "signature": "sha256:46b1af9e3ef675e164301ec8b391a3ec08cb9b1f3f913f65435891d68d7acba6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "                            \"\"\" Code for Fast FSR algorithm \"\"\"\n",
      "\n",
      "\"\"\" Date: 4/2/15 \"\"\"\n",
      "\n",
      "    \n",
      "\"\"\" p-value computation function \"\"\"\n",
      "def pval_comp(max_size=None,prec_f=4):\n",
      "    \n",
      "    import scipy.stats as st\n",
      "    \n",
      "    ### Input params:\n",
      "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
      "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
      "    \n",
      "    ### Output:\n",
      "    # array of p-values of each covariate at its given entry step\n",
      "    \n",
      "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
      "    \n",
      "    # Pull RSS values & num_obs from fwd_proc object\n",
      "    rss = np.array(ro.r('fwd$rss'))\n",
      "    N = np.array(ro.r('fwd$nn'))\n",
      "    \n",
      "    if max_size==None:\n",
      "        max_size = len(rss)-1\n",
      "    \n",
      "    # compute the F stats as defined above where p_f - p_r = 1 for each iteration\n",
      "    fstats = (rss[0:max_size] - rss[1:(max_size+1)]) / (rss[1:(max_size+1)] / (N - (max_size+1)))\n",
      "    \n",
      "    # return the p-values by comparing these stats to the F distn: F(1, n - p_f)\n",
      "    return np.around(1 - st.f.cdf(fstats, 1, N-(max_size+1)),prec_f)\n",
      "\n",
      "\n",
      "\n",
      "\"\"\" Covariate model entry order \"\"\"\n",
      "def cov_order(xcolnames,max_size=None,col_incl=None):\n",
      "    \n",
      "    # Input params:\n",
      "    #   xcolnames = array of names of covariates (same order as columns in original dataset)\n",
      "    #   max_size  = integer max no. of vars in final model (largest model size desired)\n",
      "    #   col_incl  = array vector of columns to forcefully include in all models\n",
      "    \n",
      "    ### Output:\n",
      "    # array of covariate names sorted according to order of entry into the model\n",
      "    \n",
      "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
      "    \n",
      "    if max_size==None:\n",
      "        max_size = len(xcolnames)\n",
      "        \n",
      "    ### Pull the cov entry order\n",
      "    vorder = ro.r('fwd$vorder[-1]') # remove intercept\n",
      "    vorder = vorder[0:max_size] # keep only the max model size number of covs\n",
      "    \n",
      "    ### Shift these values down by two (one to exclude intercept, one to make python indices)\n",
      "    vorderinds = np.array(vorder)-2\n",
      "    \n",
      "    ### Rearrange the var order st forced vars are at start of list\n",
      "    if col_incl==None:\n",
      "        col_incl = np.arange(max_size)+1\n",
      "    keep = xcolnames[[col_incl-1]] # pull var names of those vars forced into model (this is an array)\n",
      "    poss = [x for x in xcolnames if x not in keep] # pull var names of those not forced in (this is a list)\n",
      "    col_names = np.array(list(keep)+poss) # = rearranged array of varnames w/forced-in vars at start of list\n",
      "    \n",
      "    ### Sort the columns of X in order to obtain the var names in the entry order\n",
      "    return col_names[vorderinds[::]]\n",
      "\n",
      "    \n",
      "\n",
      "\"\"\" Forward selection function \"\"\"\n",
      "def forward(x,y,max_size=None,col_incl=None):\n",
      "    \n",
      "    ### Input params:\n",
      "    #   x        = python dataframe of original p covariates, n x p\n",
      "    #   y        = python outcome dataframe, n x 1\n",
      "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
      "    #   col_incl = array vector of columns to forcefully include in all models\n",
      "    \n",
      "    ### Output:\n",
      "    # regsubsets R object -- the raw full output of the forward selection proc\n",
      "    \n",
      "    ### Load python packages to call R functions\n",
      "    import rpy2.robjects as ro\n",
      "    import pandas.rpy.common as com\n",
      "    \n",
      "    ### Convert x and y to R matrices <-- MAKE SURE x,y input == DATAFRAMES (or else change them to df's)!!!\n",
      "    X = com.convert_to_r_matrix(x)\n",
      "    Y = com.convert_to_r_matrix(y)\n",
      "        \n",
      "    ### Declare all objects as R objects in global environment\n",
      "    ro.globalenv['x2'] = X\n",
      "    ro.globalenv['y2'] = Y\n",
      "    if max_size==None:\n",
      "        max_size = x.shape[1]\n",
      "    ro.globalenv['maxv'] = ro.Vector(max_size)\n",
      "    if col_incl==None:\n",
      "        ro.r('coli=NULL')\n",
      "    else:\n",
      "        ro.globalenv['coli'] = ro.FloatVector(col_incl[:])\n",
      "    \n",
      "    ### Perform forward selection with regsubsets function\n",
      "    ro.globalenv['fwd'] = ro.r('leaps::regsubsets(x=x2,y=y2,method=\"forward\",nvmax=maxv,force.in=coli)')\n",
      "    \n",
      "    \n",
      "    \n",
      "\"\"\" Alpha computation for model selection \"\"\"\n",
      "def alpha_F(g0, ncov, max_size=None, prec_f=6):\n",
      "    \n",
      "    ### Input params:\n",
      "    #   g0       = float pre-specified FSR (gamma0)\n",
      "    #   ncov     = integer total number of covariates in data\n",
      "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
      "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
      "    \n",
      "    ### Output:\n",
      "    # array of alpha_F values\n",
      "    \n",
      "    if max_size==None:\n",
      "        max_size = ncov\n",
      "        \n",
      "    # Create indices == model size at given step, call this S\n",
      "    S = np.arange(max_size)+1\n",
      "    \n",
      "    # alpha_F_i = gamma_0 * (1 + S_i) / (ncov - S_i)\n",
      "    alpha_F = g0 * (1 + S) / (ncov - S)\n",
      "    \n",
      "    # if table run on all vars, the last alpha = inf\n",
      "    #  instead set equal to 1 == include all vars\n",
      "    alpha_F[np.isinf(alpha_F)] = 1.\n",
      "    \n",
      "    return np.around(alpha_F,prec_f)\n",
      "    \n",
      "    \n",
      "    \n",
      "\"\"\" Gamma computation \"\"\"\n",
      "def gamma_F(pvs, ncov, max_size=None, prec_f=4):\n",
      "    \n",
      "    import numpy as np\n",
      "    \n",
      "    ### Input params:\n",
      "    #   pvs      = vector of p-values (sorted or unsorted) from forward sel procedure\n",
      "    #   ncov     = integer total number of covariates in data\n",
      "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
      "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
      "    \n",
      "    ### Output:\n",
      "    # array of gamma_F values\n",
      "    \n",
      "    # sort pvalues to be monotonically increasing \n",
      "    pv_s = np.sort(pvs)\n",
      "    \n",
      "    if max_size==None:\n",
      "        max_size = ncov\n",
      "        \n",
      "    # Create indices == model size at given step, call this S\n",
      "    S = np.arange(max_size)+1\n",
      "    \n",
      "    # gamma_F_i = p_s_i * (ncov - S_i) / (1 + S_i)\n",
      "    g_F = pv_s * (ncov - S) / (1 + S)\n",
      "    \n",
      "    # if table run on all vars, the last gamma = 0,\n",
      "    #  instead set equal to the last pv_sort == final rate of unimp var inclusion\n",
      "    if(g_F[-1]==0): \n",
      "        g_F[-1]=pv_s[-1]\n",
      "    \n",
      "    return np.around(g_F,prec_f)\n",
      "        \n",
      "    \n",
      "    \n",
      "\"\"\" Alpha computation for specific gamma \"\"\"\n",
      "def alpha_F_g(g, gf, ncov, prec_f):\n",
      "    \n",
      "    ### Input params:\n",
      "    #   g    = float or vector (length k) of specified FSR at which to compute alpha\n",
      "    #   gf   = vector gamma_F's computed from gamma0, pv_sorted\n",
      "    #          used to compute largest size model (S) for which gamma_F < g\n",
      "    #   ncov = integer of total number covariates in data\n",
      "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
      "    \n",
      "    ### Output:\n",
      "    # integer alpha_F value\n",
      "    \n",
      "    ### Compute model size for gf closest to (but still <) g\n",
      "    #S = np.array([max(np.which(x<=y)) for x in gf y in g])+1\n",
      "    if isinstance(g,np.ndarray): # if g is a vector\n",
      "        s_s = [np.where(gf>y) for y in g]\n",
      "        S = np.array([min(x[0]) for x in s_s])\n",
      "        return np.around(g * (1 + S) / (ncov - S),prec_f)\n",
      "    else: # if g is a number\n",
      "        S = min(np.where(gf>g)[0])\n",
      "        return round(g * (1 + S) / (ncov - S),prec_f)\n",
      "\n",
      "\n",
      "    \n",
      "\"\"\" Beta-hat computation for specific gamma \"\"\"\n",
      "def beta_est(x, y, g, gf, vname, prec_b=6):\n",
      "    \n",
      "    ### Input params:\n",
      "    #   x      = python dataframe of original p covariates, n x p\n",
      "    #   y      = python outcome dataframe, n x 1\n",
      "    #   g      = float of specified FSR at which to compute alpha\n",
      "    #   gf     = vector gamma_F's computed from gamma0, pv_sorted\n",
      "    #            used to compute largest size model (S) for which gamma_F < g\n",
      "    #   vname  = ordered vector of names of vars entered into model under forward selection\n",
      "    #   prec_b = precision on beta-hat estimates\n",
      "    \n",
      "    ### Output:\n",
      "    # array of estimated parameters\n",
      "    \n",
      "    ### Compute model size corresponding to g\n",
      "    S = min(np.where(gf>g)[0])\n",
      "    \n",
      "    ### Pull the cov names of those vars included in the above size model\n",
      "    modvars = vname[:S]\n",
      "    \n",
      "    ### Create linear regression object\n",
      "    from sklearn import linear_model\n",
      "    linmod = linear_model.LinearRegression()\n",
      "\n",
      "    ### Fit the linear model using the selected model vars\n",
      "    linmod.fit(X2.loc[:,list(modvars)], Y2)\n",
      "    \n",
      "    return np.around(linmod.coef_, prec_b)\n",
      "\n",
      "    \n",
      "    \n",
      "\"\"\" FSR Results Table \"\"\"\n",
      "def fsrtable(size, vname, p_orig, p_sort, alphaf, gammaf):\n",
      "    \n",
      "    ### Input params:\n",
      "    #   size   = model size at each step of forward sel proc                   [S]\n",
      "    #   vname  = variable name that entered at each step (num vars = p)        [Var]\n",
      "    #   p_orig = p-values at each step                                         [p]\n",
      "    #   p_sort = ascending p-values                                            [p_s]\n",
      "    #   alphaf = alpha-to-enter (p-value cutoff) for model entry at each step  [alpha_F]\n",
      "    #   gammaf = FSR at each step                                              [gamma_F]\n",
      "    \n",
      "    ### Output:\n",
      "    # table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
      "    \n",
      "    ### Convert all arrays to dataframes\n",
      "    sized = pd.DataFrame(size)\n",
      "    vnamed = pd.DataFrame(vname)\n",
      "    p_od = pd.DataFrame(p_orig)\n",
      "    p_sd = pd.DataFrame(p_sort)\n",
      "    ad = pd.DataFrame(alphaf)\n",
      "    gd = pd.DataFrame(gammaf)\n",
      "    \n",
      "    ### Combine the arrays\n",
      "    tab = pd.concat([sized,vnamed,p_od,p_sd,ad,gd],axis=1)\n",
      "    tab.columns = ['S','Var','p','p_s','alpha_F','gamma_F']\n",
      "    \n",
      "    return tab\n",
      "    \n",
      "    \n",
      "    \n",
      "\"\"\" FastFSR function \"\"\"\n",
      "def ffsr(x,y,g0=0.05,betaout=False,gs=None,max_size=None,var_incl=None,prec_f=4,prec_b=6):\n",
      "    \n",
      "    ### Input params:\n",
      "    #   x        = python dataframe of original p covariates, n x p\n",
      "    #   y        = python outcome dataframe, n x 1\n",
      "    #   g0       = float pre-specified FSR of interest (\"gamma0\")\n",
      "    #   gs       = float or vector of gamma's at which to specifically compute alpha_F\n",
      "    #   max_size = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
      "    #   var_incl = array of cols corresponding to those vars to force into model\n",
      "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
      "    #   prec_b   = integer of precision (num digits) desired in beta-hat parameter estimates of final model\n",
      "    \n",
      "    ### Output: \n",
      "    #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
      "    # Table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
      "    #   S:       model size at given step\n",
      "    #   Var:     name of var that entered at given step\n",
      "    #   p:       p-value of var that entered at given step\n",
      "    #   p_s:     sorted p-value (vector or original p-values sorted in increasing order)\n",
      "    #   alpha_F: cutoff value for model entry given gamma_0 and current p_s value\n",
      "    #   gamma_F: FSR given current alpha_F and model size (== step num)\n",
      "    #       and\n",
      "    # Vector of alpha_F's for specified gamma's (g)\n",
      "\n",
      "    import numpy as np\n",
      "    import pandas as pd\n",
      "    \n",
      "    ### Clean and check data\n",
      "    # make sure x,y = pandas dataframes or else convert them\n",
      "    try: \n",
      "        x.columns.values #isinstance(x,pd.DataFrame)\n",
      "    except:\n",
      "        if isinstance(x,np.ndarray):\n",
      "            x = pd.DataFrame(x)\n",
      "            vnum = list(np.arange(x.shape[1])+1)\n",
      "            vchr = list(np.repeat(\"V\",x.shape[1]))\n",
      "            x.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
      "        else:\n",
      "            raise Exception(\"x must be pandas DataFrame\")\n",
      "    try: \n",
      "        y.columns.values #isinstance(y,pd.DataFrame)\n",
      "    except:\n",
      "        if isinstance(y,np.ndarray):\n",
      "            y = pd.DataFrame(y)\n",
      "        else:\n",
      "            raise Exception(\"y must be pandas DataFrame\")\n",
      "    \n",
      "    # remove missing values\n",
      "    yna = np.isnan(np.array(y))\n",
      "    xna = np.isnan(x).any(axis=1).reshape(x.shape[0],1)\n",
      "    anyna = np.array([int(max(a,b)) for a,b in zip(xna,yna)])\n",
      "    missrow = np.where(anyna==1)[0]\n",
      "    y = y.drop(y.index[missrow])\n",
      "    x = x.drop(x.index[missrow])\n",
      "    \n",
      "    # check that p < n to ensure regression solutions\n",
      "    if x.shape[1] >= x.shape[0]:\n",
      "        raise Exception(\"N must be > p for valid regression solutions\")\n",
      "    \n",
      "    ### If max model size not specified, select all possible cov.s\n",
      "    if max_size==None:\n",
      "        max_size = x.shape[1]\n",
      "        \n",
      "    ### Perform forward selection\n",
      "    fwd_sel = forward(x, y, max_size, var_incl)\n",
      "    \n",
      "    ### Save order of covariate entry into model\n",
      "    cov_entry_order = cov_order(x.columns.values, max_size, var_incl)\n",
      "    \n",
      "    ### Compute p-value of each covariate entering the model\n",
      "    p_orig = pval_comp(max_size, prec_f)\n",
      "    \n",
      "    ### Sort p-values in ascending order\n",
      "    p_sort = np.sort(p_orig)\n",
      "    \n",
      "    ### Alpha_F computation for all steps in fwd sel proc\n",
      "    a_F = alpha_F(g0, x.shape[1], max_size, prec_f)\n",
      "    \n",
      "    ### Gamma_F computation\n",
      "    g_F = gamma_F(p_sort, x.shape[1], max_size, prec_f)\n",
      "    \n",
      "    ### Model size\n",
      "    S = np.arange(max_size)+1\n",
      "    \n",
      "    ### Combine S, Cov_names, p-vals, sorted p-vals, alpha_F, gamma_F into table\n",
      "    fsr_results = fsrtable(S, cov_entry_order, p_orig, p_sort, a_F, g_F)\n",
      "    \n",
      "    ### Return selected output: FSR table (+ betahat) (+ alpha_specific)\n",
      "    if gs!=None: \n",
      "        ### Compute alpha_F for specific gammas (gs)\n",
      "        if betaout==True:\n",
      "            ### Compute beta_hat of model corresponding to specific gamma0\n",
      "            return fsr_results, beta_est(x, y, g0, g_F, cov_entry_order, prec_b), alpha_F_g(gs, g_f, x.shape[1])\n",
      "        else:\n",
      "            return fsr_results, alpha_F_g(gs, g_f, x.shape[1])\n",
      "    else:\n",
      "        if betaout==True:\n",
      "            ### Compute beta_hat of model corresponding to specific gamma0\n",
      "            return fsr_results, beta_est(x, y, g0, g_F, cov_entry_order, prec_b)\n",
      "        else:\n",
      "            return fsr_results\n",
      "\n",
      "# Notes: \n",
      "# 1. appropriate transformations are expected to have been applied prior to utilization of FSR algorithm\n",
      "\n",
      "# To-do:\n",
      "# 1. will need to adjust above functions to handle fwd_sel steps with tied p-values for >1 cov\n",
      "# 2. adjust for optimal bagging"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import rpy2.robjects as ro\n",
      "import pandas.rpy.common as com\n",
      "from rpy2.robjects.packages import importr\n",
      "\n",
      "# load R package\n",
      "#leaps = importr('leaps')\n",
      "#stats = importr('stats')\n",
      "#base = importr('base')\n",
      "\n",
      "#regsub = ro.r('leaps::regsubsets')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "np.random.seed(1234)\n",
      "\n",
      "X = np.random.multivariate_normal(np.zeros(15),np.eye(15),(100))\n",
      "beta = np.array([0,0,5,6,0,0,4,0,0,0,5,0,0,0,0]).reshape(15,1) # signif betas: 3,4,7,11\n",
      "Y = X.dot(beta)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y2 = pd.DataFrame(Y)\n",
      "X2 = pd.DataFrame(X)\n",
      "X2.columns = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###########################################################\n",
      "### Test functions:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fwd_r = forward(X2,Y2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "codnames = cov_order(X2.columns.values)\n",
      "\n",
      "print codnames\n",
      "\n",
      "print ro.r('fwd$vorder')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['V4' 'V7' 'V3' 'V11' 'V2' 'V10' 'V1' 'V5' 'V15' 'V12' 'V14' 'V8' 'V9' 'V6'\n",
        " 'V13']\n",
        " [1]  1  5  8  4 12  3 11  2  6 16 13 15  9 10  7 14\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "po = pval_comp(X2.shape[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gg00 = 0.05\n",
      "af = alpha_F(gg00, X2.shape[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gf = gamma_F(po, X2.shape[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sss = np.arange(X2.shape[1])+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fsr_results = fsrtable(sss, codnames, po, np.sort(po), af, gf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fsr_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>S</th>\n",
        "      <th>Var</th>\n",
        "      <th>p</th>\n",
        "      <th>p_s</th>\n",
        "      <th>alpha_F</th>\n",
        "      <th>gamma_F</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>  1</td>\n",
        "      <td>  V4</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.007143</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>  2</td>\n",
        "      <td>  V7</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.011538</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>  3</td>\n",
        "      <td>  V3</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.016667</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>  4</td>\n",
        "      <td> V11</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.022727</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>  5</td>\n",
        "      <td>  V2</td>\n",
        "      <td> 0.0006</td>\n",
        "      <td> 0.0006</td>\n",
        "      <td> 0.030000</td>\n",
        "      <td> 0.0010</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>  6</td>\n",
        "      <td> V10</td>\n",
        "      <td> 0.0115</td>\n",
        "      <td> 0.0115</td>\n",
        "      <td> 0.038889</td>\n",
        "      <td> 0.0148</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>  7</td>\n",
        "      <td>  V1</td>\n",
        "      <td> 0.0159</td>\n",
        "      <td> 0.0159</td>\n",
        "      <td> 0.050000</td>\n",
        "      <td> 0.0159</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>  8</td>\n",
        "      <td>  V5</td>\n",
        "      <td> 0.1112</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td> 0.064286</td>\n",
        "      <td> 0.0707</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>  9</td>\n",
        "      <td> V15</td>\n",
        "      <td> 0.0909</td>\n",
        "      <td> 0.1112</td>\n",
        "      <td> 0.083333</td>\n",
        "      <td> 0.0667</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 10</td>\n",
        "      <td> V12</td>\n",
        "      <td> 0.1371</td>\n",
        "      <td> 0.1371</td>\n",
        "      <td> 0.110000</td>\n",
        "      <td> 0.0623</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 11</td>\n",
        "      <td> V14</td>\n",
        "      <td> 0.2147</td>\n",
        "      <td> 0.2147</td>\n",
        "      <td> 0.150000</td>\n",
        "      <td> 0.0716</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 12</td>\n",
        "      <td>  V8</td>\n",
        "      <td> 0.2563</td>\n",
        "      <td> 0.2563</td>\n",
        "      <td> 0.216667</td>\n",
        "      <td> 0.0591</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 13</td>\n",
        "      <td>  V9</td>\n",
        "      <td> 0.3736</td>\n",
        "      <td> 0.3736</td>\n",
        "      <td> 0.350000</td>\n",
        "      <td> 0.0534</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 14</td>\n",
        "      <td>  V6</td>\n",
        "      <td> 0.6494</td>\n",
        "      <td> 0.6494</td>\n",
        "      <td> 0.750000</td>\n",
        "      <td> 0.0433</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 15</td>\n",
        "      <td> V13</td>\n",
        "      <td> 0.7110</td>\n",
        "      <td> 0.7110</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.7110</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "     S  Var       p     p_s   alpha_F  gamma_F\n",
        "0    1   V4  0.0000  0.0000  0.007143   0.0000\n",
        "1    2   V7  0.0000  0.0000  0.011538   0.0000\n",
        "2    3   V3  0.0000  0.0000  0.016667   0.0000\n",
        "3    4  V11  0.0000  0.0000  0.022727   0.0000\n",
        "4    5   V2  0.0006  0.0006  0.030000   0.0010\n",
        "5    6  V10  0.0115  0.0115  0.038889   0.0148\n",
        "6    7   V1  0.0159  0.0159  0.050000   0.0159\n",
        "7    8   V5  0.1112  0.0909  0.064286   0.0707\n",
        "8    9  V15  0.0909  0.1112  0.083333   0.0667\n",
        "9   10  V12  0.1371  0.1371  0.110000   0.0623\n",
        "10  11  V14  0.2147  0.2147  0.150000   0.0716\n",
        "11  12   V8  0.2563  0.2563  0.216667   0.0591\n",
        "12  13   V9  0.3736  0.3736  0.350000   0.0534\n",
        "13  14   V6  0.6494  0.6494  0.750000   0.0433\n",
        "14  15  V13  0.7110  0.7110  1.000000   0.7110"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ffsr(X2,Y2,0.05,max_size=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>S</th>\n",
        "      <th>Var</th>\n",
        "      <th>p</th>\n",
        "      <th>p_s</th>\n",
        "      <th>alpha_F</th>\n",
        "      <th>gamma_F</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td>  V4</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0071</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td>  V7</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0115</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td>  V3</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0167</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4</td>\n",
        "      <td> V11</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0227</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5</td>\n",
        "      <td>  V2</td>\n",
        "      <td> 0.0003</td>\n",
        "      <td> 0.0003</td>\n",
        "      <td> 0.0300</td>\n",
        "      <td> 0.0005</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 6</td>\n",
        "      <td> V10</td>\n",
        "      <td> 0.0085</td>\n",
        "      <td> 0.0085</td>\n",
        "      <td> 0.0389</td>\n",
        "      <td> 0.0109</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 7</td>\n",
        "      <td>  V1</td>\n",
        "      <td> 0.0120</td>\n",
        "      <td> 0.0120</td>\n",
        "      <td> 0.0500</td>\n",
        "      <td> 0.0120</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 8</td>\n",
        "      <td>  V5</td>\n",
        "      <td> 0.0973</td>\n",
        "      <td> 0.0973</td>\n",
        "      <td> 0.0643</td>\n",
        "      <td> 0.0757</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "   S  Var       p     p_s  alpha_F  gamma_F\n",
        "0  1   V4  0.0000  0.0000   0.0071   0.0000\n",
        "1  2   V7  0.0000  0.0000   0.0115   0.0000\n",
        "2  3   V3  0.0000  0.0000   0.0167   0.0000\n",
        "3  4  V11  0.0000  0.0000   0.0227   0.0000\n",
        "4  5   V2  0.0003  0.0003   0.0300   0.0005\n",
        "5  6  V10  0.0085  0.0085   0.0389   0.0109\n",
        "6  7   V1  0.0120  0.0120   0.0500   0.0120\n",
        "7  8   V5  0.0973  0.0973   0.0643   0.0757"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ffsr(X2,Y2,0.05,var_incl=np.array([5]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:96: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
        "-c:59: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>S</th>\n",
        "      <th>Var</th>\n",
        "      <th>p</th>\n",
        "      <th>p_s</th>\n",
        "      <th>alpha_F</th>\n",
        "      <th>gamma_F</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>  1</td>\n",
        "      <td>  V5</td>\n",
        "      <td> 0.3534</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0071</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>  2</td>\n",
        "      <td>  V4</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0115</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>  3</td>\n",
        "      <td>  V3</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0167</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>  4</td>\n",
        "      <td> V11</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0227</td>\n",
        "      <td> 0.0000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>  5</td>\n",
        "      <td>  V7</td>\n",
        "      <td> 0.0000</td>\n",
        "      <td> 0.0392</td>\n",
        "      <td> 0.0300</td>\n",
        "      <td> 0.0653</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>  6</td>\n",
        "      <td>  V2</td>\n",
        "      <td> 0.0392</td>\n",
        "      <td> 0.1283</td>\n",
        "      <td> 0.0389</td>\n",
        "      <td> 0.1650</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>  7</td>\n",
        "      <td>  V6</td>\n",
        "      <td> 0.1285</td>\n",
        "      <td> 0.1285</td>\n",
        "      <td> 0.0500</td>\n",
        "      <td> 0.1285</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>  8</td>\n",
        "      <td>  V1</td>\n",
        "      <td> 0.1283</td>\n",
        "      <td> 0.2355</td>\n",
        "      <td> 0.0643</td>\n",
        "      <td> 0.1832</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>  9</td>\n",
        "      <td> V13</td>\n",
        "      <td> 0.2355</td>\n",
        "      <td> 0.2583</td>\n",
        "      <td> 0.0833</td>\n",
        "      <td> 0.1550</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 10</td>\n",
        "      <td> V15</td>\n",
        "      <td> 0.2583</td>\n",
        "      <td> 0.3126</td>\n",
        "      <td> 0.1100</td>\n",
        "      <td> 0.1421</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 11</td>\n",
        "      <td>  V9</td>\n",
        "      <td> 0.3420</td>\n",
        "      <td> 0.3420</td>\n",
        "      <td> 0.1500</td>\n",
        "      <td> 0.1140</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 12</td>\n",
        "      <td> V12</td>\n",
        "      <td> 0.3126</td>\n",
        "      <td> 0.3534</td>\n",
        "      <td> 0.2167</td>\n",
        "      <td> 0.0816</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 13</td>\n",
        "      <td> V10</td>\n",
        "      <td> 0.5287</td>\n",
        "      <td> 0.5287</td>\n",
        "      <td> 0.3500</td>\n",
        "      <td> 0.0755</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 14</td>\n",
        "      <td> V14</td>\n",
        "      <td> 0.5864</td>\n",
        "      <td> 0.5864</td>\n",
        "      <td> 0.7500</td>\n",
        "      <td> 0.0391</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 15</td>\n",
        "      <td>  V8</td>\n",
        "      <td> 0.8649</td>\n",
        "      <td> 0.8649</td>\n",
        "      <td> 1.0000</td>\n",
        "      <td> 0.8649</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "     S  Var       p     p_s  alpha_F  gamma_F\n",
        "0    1   V5  0.3534  0.0000   0.0071   0.0000\n",
        "1    2   V4  0.0000  0.0000   0.0115   0.0000\n",
        "2    3   V3  0.0000  0.0000   0.0167   0.0000\n",
        "3    4  V11  0.0000  0.0000   0.0227   0.0000\n",
        "4    5   V7  0.0000  0.0392   0.0300   0.0653\n",
        "5    6   V2  0.0392  0.1283   0.0389   0.1650\n",
        "6    7   V6  0.1285  0.1285   0.0500   0.1285\n",
        "7    8   V1  0.1283  0.2355   0.0643   0.1832\n",
        "8    9  V13  0.2355  0.2583   0.0833   0.1550\n",
        "9   10  V15  0.2583  0.3126   0.1100   0.1421\n",
        "10  11   V9  0.3420  0.3420   0.1500   0.1140\n",
        "11  12  V12  0.3126  0.3534   0.2167   0.0816\n",
        "12  13  V10  0.5287  0.5287   0.3500   0.0755\n",
        "13  14  V14  0.5864  0.5864   0.7500   0.0391\n",
        "14  15   V8  0.8649  0.8649   1.0000   0.8649"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ftab, bhats = ffsr(X2,Y2,0.05,betaout=True)\n",
      "print ftab\n",
      "print\n",
      "print bhats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     S  Var       p     p_s  alpha_F  gamma_F\n",
        "0    1   V4  0.0000  0.0000   0.0071   0.0000\n",
        "1    2   V7  0.0000  0.0000   0.0115   0.0000\n",
        "2    3   V3  0.0000  0.0000   0.0167   0.0000\n",
        "3    4  V11  0.0000  0.0000   0.0227   0.0000\n",
        "4    5   V2  0.0006  0.0006   0.0300   0.0010\n",
        "5    6  V10  0.0115  0.0115   0.0389   0.0148\n",
        "6    7   V1  0.0159  0.0159   0.0500   0.0159\n",
        "7    8   V5  0.1112  0.0909   0.0643   0.0707\n",
        "8    9  V15  0.0909  0.1112   0.0833   0.0667\n",
        "9   10  V12  0.1371  0.1371   0.1100   0.0623\n",
        "10  11  V14  0.2147  0.2147   0.1500   0.0716\n",
        "11  12   V8  0.2563  0.2563   0.2167   0.0591\n",
        "12  13   V9  0.3736  0.3736   0.3500   0.0534\n",
        "13  14   V6  0.6494  0.6494   0.7500   0.0433\n",
        "14  15  V13  0.7110  0.7110   1.0000   0.7110\n",
        "\n",
        "[[ 6.  4.  5.  5.  0.  0.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}