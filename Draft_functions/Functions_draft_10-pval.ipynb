{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                            \"\"\" Pseudocode for Fast FSR algorithm \"\"\"\n",
    "\n",
    "\"\"\" Date: 4/17/15 \n",
    "    Modified: Correct p-value computations \n",
    "    Date: 4/19/15\n",
    "    Modified: Added corrections from Draft8-R_comparisons: p-mono, gamma_F\"\"\"\n",
    "\n",
    "\n",
    "\"\"\" Data type check \"\"\"\n",
    "def df_type(dat):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat = dataset whose type is to be checked / transformed\n",
    "    \n",
    "    ### Output:\n",
    "    #   error msg or True boolean\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    if isinstance(dat,pd.DataFrame)==False and isinstance(dat,np.ndarray)==False:\n",
    "        raise Exception(\"Data must be pandas DataFrame\")\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" p-value computation function \"\"\"\n",
    "def pval_comp(max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of p-values of each covariate at its given entry step\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.stats as st\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    # Pull RSS values & num_obs from fwd_proc object\n",
    "    rss = np.array(ro.r('fwd$rss'))\n",
    "    N = np.array(ro.r('fwd$nn'))\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(rss)-1\n",
    "    \n",
    "    # vector of model sizes\n",
    "    sizes = np.arange(max_size)+1\n",
    "    \n",
    "    # compute the F stats as defined above where p_f - p_r = 1 for each iteration\n",
    "    fstats = (rss[0:max_size] - rss[1:(max_size+1)]) / (rss[1:(max_size+1)] / (N - (sizes+1)))\n",
    "    \n",
    "    # return the p-values by comparing these stats to the F distn: F(1, n - p_f)\n",
    "    return 1 - st.f.cdf(fstats, 1, N-(sizes+1))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Covariate model entry order \"\"\"\n",
    "def cov_order(xcolnames,max_size=None,col_incl=None):\n",
    "    \n",
    "    # Input params:\n",
    "    #   xcolnames = array of names of covariates (same order as columns in original dataset)\n",
    "    #   max_size  = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl  = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    # array of covariate names sorted according to order of entry into the model\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
    "    \n",
    "    import numpy as np\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(xcolnames)\n",
    "        \n",
    "    ### Pull the cov entry order\n",
    "    vorder = ro.r('fwd$vorder[-1]') # remove intercept\n",
    "    vorder = vorder[0:max_size] # keep only the max model size number of covs\n",
    "    \n",
    "    ### Shift these values down by two (one to exclude intercept, one to make python indices)\n",
    "    vorderinds = np.array(vorder)-2\n",
    "    \n",
    "    ### Rearrange the var order st forced vars are at start of list\n",
    "    if col_incl==None:\n",
    "        col_incl = np.arange(max_size)+1\n",
    "    keep = xcolnames[[col_incl-1]] # pull var names of those vars forced into model (this is an array)\n",
    "    poss = [x for x in xcolnames if x not in keep] # pull var names of those not forced in (this is a list)\n",
    "    col_names = np.array(list(keep)+poss) # = rearranged array of varnames w/forced-in vars at start of list\n",
    "    \n",
    "    ### Sort the columns of X in order to obtain the var names in the entry order\n",
    "    return col_names[vorderinds[::]]\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\" Forward selection function \"\"\"\n",
    "def forward(x,y,max_size=None,col_incl=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x        = python dataframe of original p covariates, n x p\n",
    "    #   y        = python outcome dataframe, n x 1\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    # regsubsets R object -- the raw full output of the forward selection proc\n",
    "    \n",
    "    ### Load python packages to call R functions\n",
    "    import rpy2.robjects as ro\n",
    "    import pandas.rpy.common as com\n",
    "    \n",
    "    ### Convert x and y to R matrices <-- MAKE SURE x,y input == DATAFRAMES (or else change them to df's)!!!\n",
    "    ### and declare as R objects in global environment\n",
    "    ro.globalenv['x2'] = com.convert_to_r_matrix(x)\n",
    "    ro.globalenv['y2'] = com.convert_to_r_matrix(y)\n",
    "    if max_size==None:\n",
    "        max_size = x.shape[1]\n",
    "    ro.globalenv['maxv'] = ro.Vector(max_size)\n",
    "    if col_incl==None:\n",
    "        ro.r('coli=NULL')\n",
    "    else:\n",
    "        ro.globalenv['coli'] = ro.FloatVector(col_incl[:])\n",
    "    \n",
    "    ### Perform forward selection with regsubsets function\n",
    "    ro.globalenv['fwd'] = ro.r('leaps::regsubsets(x=x2,y=y2,method=\"forward\",nvmax=maxv,force.in=coli)')\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Gamma computation \"\"\"\n",
    "def gamma_F(pvs, ncov, max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   pvs      = vector of p-values (monotonically increasing) from forward sel procedure\n",
    "    #   ncov     = integer total number of covariates in data\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of gamma_F values\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = ncov\n",
    "        \n",
    "    # Create indices == model size at given step, call this S\n",
    "    S = np.arange(max_size)+1\n",
    "    \n",
    "    # gamma_F_i = p_s_i * (ncov - S_i) / (1 + S_i)\n",
    "    g_F = pvs * (ncov - S) / (1 + S)\n",
    "    \n",
    "    # Check for duplicate p-values\n",
    "    dups = list(set([x for x in list(pvs) if list(pvs).count(x) > 1]))\n",
    "    for i in range(len(dups)): g_F[pvs==dups[i]] = min(g_F[pvs==dups[i]])\n",
    "    \n",
    "    # if table run on all vars, the last gamma = 0,\n",
    "    #  instead set equal to the last pv_mono == final rate of unimp var inclusion\n",
    "    if(g_F[-1]==0): \n",
    "        g_F[-1]=pvs[-1]\n",
    "    \n",
    "    return g_F\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for model selection \"\"\"\n",
    "def alpha_F(g0, ncov, max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   g0       = float pre-specified FSR (gamma0)\n",
    "    #   ncov     = integer total number of covariates in data\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of alpha_F values\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = ncov\n",
    "        \n",
    "    # Create indices == model size at given step, call this S\n",
    "    S = np.arange(max_size)+1\n",
    "    \n",
    "    # alpha_F_i = gamma_0 * (1 + S_i) / (ncov - S_i)\n",
    "    alpha_F = g0 * (1 + S) / (ncov - S)\n",
    "    \n",
    "    # if table run on all vars, the last alpha = inf\n",
    "    #  instead set equal to 1 == include all vars\n",
    "    alpha_F[np.isinf(alpha_F)] = 1.\n",
    "    \n",
    "    return alpha_F        \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for specific gamma \"\"\"\n",
    "def alpha_F_g(g, gf, ncov):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   g    = float or vector (length k) of specified FSR at which to compute alpha\n",
    "    #   gf   = vector gamma_F's computed from gamma0, pv_sorted\n",
    "    #          used to compute largest size model (S) for which gamma_F < g\n",
    "    #   ncov = integer of total number covariates in data\n",
    "    \n",
    "    ### Output:\n",
    "    # integer alpha_F value\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    ### Compute model size for gf closest to (but still <) g\n",
    "    #S = np.array([max(np.which(x<=y)) for x in gf y in g])+1\n",
    "    if isinstance(g,np.ndarray): # if g is a vector\n",
    "        s_s = [np.where(gf>y) for y in g]\n",
    "        S = np.array([min(x[0]) for x in s_s])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "    else: # if g is a number\n",
    "        S = min(np.where(gf>g)[0])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" Beta-hat computation for specific gamma \"\"\"\n",
    "def beta_est(x, y, g, gf, vname):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x      = python dataframe of original p covariates, n x p\n",
    "    #   y      = python outcome dataframe, n x 1\n",
    "    #   g      = float of specified FSR at which to compute alpha\n",
    "    #   gf     = vector gamma_F's computed from gamma0, pv_mono\n",
    "    #            used to compute largest size model (S) for which gamma_F < g\n",
    "    #   vname  = ordered vector of names of vars entered into model under forward selection\n",
    "    \n",
    "    ### Output:\n",
    "    # array of estimated parameters\n",
    "    \n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    ### Compute model size corresponding to g\n",
    "    S = min(np.where(gf>g)[0])\n",
    "\n",
    "    ### Pull the cov names of those vars included in the above size model\n",
    "    modvars = vname[:S]\n",
    "\n",
    "    ### Fit the linear model using the selected model vars\n",
    "    fit = sm.OLS(y,x.loc[:,list(modvars)]).fit()\n",
    "    betaout = pd.DataFrame([fit.params,fit.bse]).T\n",
    "    betaout.columns = ['beta','beta_se']\n",
    "    \n",
    "    return betaout\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" FSR Results Table \"\"\"\n",
    "def fsrtable(size, vname, p_orig, p_mono, alphaf, gammaf, prec_f=4):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   size   = model size at each step of forward sel proc                   [S]\n",
    "    #   vname  = variable name that entered at each step (num vars = p)        [Var]\n",
    "    #   p_orig = p-values at each step                                         [p]\n",
    "    #   p_mono = ascending p-values                                            [p_s]\n",
    "    #   alphaf = alpha-to-enter (p-value cutoff) for model entry at each step  [alpha_F]\n",
    "    #   gammaf = FSR at each step                                              [gamma_F]\n",
    "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
    "    \n",
    "    ### Output:\n",
    "    # table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Convert all arrays to dataframes\n",
    "    sized = pd.DataFrame(size)\n",
    "    vnamed = pd.DataFrame(vname)\n",
    "    p_od = pd.DataFrame(np.around(p_orig,prec_f))\n",
    "    p_md = pd.DataFrame(np.around(p_mono,prec_f))\n",
    "    ad = pd.DataFrame(np.around(alphaf,prec_f))\n",
    "    gd = pd.DataFrame(np.around(gammaf,prec_f))\n",
    "    \n",
    "    ### Combine the arrays\n",
    "    tab = pd.concat([sized,vnamed,p_od,p_md,ad,gd],axis=1)\n",
    "    tab.columns = ['S','Var','p','p_m','alpha_F','gamma_F']\n",
    "    \n",
    "    return tab\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" FastFSR function \"\"\"\n",
    "def ffsr(X,Y,g0=0.05,betaout=False,gs=None,max_size=None,var_incl=None,bag=False,prec_f=4,prec_b=6):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x        = python dataframe of original p covariates, n x p\n",
    "    #   y        = python outcome dataframe, n x 1\n",
    "    #   g0       = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   betaout  = boolean of whether to include estimated betahats from final selected model\n",
    "    #   gs       = float or vector of gamma's at which to specifically compute alpha_F\n",
    "    #   max_size = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   var_incl = array of cols corresponding to those vars to force into model\n",
    "    #   bag      = boolean of whether to output FSR table (non-bagging results) or reduced output for bagging purposes\n",
    "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
    "    #   prec_b   = integer of precision (num digits) desired in beta-hat parameter estimates of final model\n",
    "    \n",
    "    ### Output: \n",
    "    #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
    "    # Table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    #   S:       model size at given step\n",
    "    #   Var:     name of var that entered at given step\n",
    "    #   p:       p-value of var that entered at given step\n",
    "    #   p_m:     mono. inc. p-value (vector or original p-values arranged to be monotonically increasing)\n",
    "    #   alpha_F: cutoff value for model entry given gamma_0 and current p_s value\n",
    "    #   gamma_F: FSR given current alpha_F and model size (== step num)\n",
    "    #       and\n",
    "    #   vector of alpha_F's for specified gamma's (g)\n",
    "    #       and\n",
    "    #   vector of estimated beta param's for final model (based on g0)\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data - make sure X, Y = pandas dataframes or else convert them\n",
    "    if bag==False:\n",
    "        if df_type(X)==True:\n",
    "            if isinstance(X,pd.DataFrame):\n",
    "                x = X.copy()\n",
    "            else:\n",
    "                if isinstance(X,np.ndarray):\n",
    "                    x = pd.DataFrame(X)\n",
    "                    vnum = list(np.arange(x.shape[1])+1)\n",
    "                    vchr = list(np.repeat(\"V\",x.shape[1]))\n",
    "                    x.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "        else:\n",
    "            return df_type(X)\n",
    "        if df_type(Y)==True:\n",
    "            if isinstance(Y,pd.DataFrame):\n",
    "                y = Y.copy()\n",
    "            else:\n",
    "                if isinstance(Y,np.ndarray):\n",
    "                    y = pd.DataFrame(Y)\n",
    "        else:\n",
    "            return df_type(Y)\n",
    "        # Remove missing values\n",
    "        yna = np.isnan(y).any(axis=1)\n",
    "        xna = np.isnan(x).any(axis=1).reshape(x.shape[0],1)\n",
    "        anyna = np.array([int(max(a,b)) for a,b in zip(xna,yna)])\n",
    "        missrow = np.where(anyna==1)[0]\n",
    "        y = y.drop(y.index[missrow])\n",
    "        x = x.drop(x.index[missrow])\n",
    "        # Check that p < n to ensure regression solutions\n",
    "        if x.shape[1] >= x.shape[0]:\n",
    "            raise Exception(\"N must be > p for valid regression solutions\")\n",
    "    else:\n",
    "        x, y = X.copy(), Y.copy()\n",
    "    \n",
    "    ### If max model size not specified, select all possible cov.s\n",
    "    if max_size==None:\n",
    "        max_size = x.shape[1]\n",
    "        \n",
    "    ### Perform forward selection\n",
    "    fwd_sel = forward(x, y, max_size, var_incl)\n",
    "    \n",
    "    ### Save order of covariate entry into model\n",
    "    cov_entry_order = cov_order(x.columns.values, max_size, var_incl)\n",
    "    \n",
    "    ### Compute p-value of each covariate entering the model\n",
    "    p_orig = pval_comp(max_size)\n",
    "    \n",
    "    ### Arrange p-values in mono. inc. order\n",
    "    p_mono = np.array([max(p_orig[:(i+1)]) for i in range(len(p_orig))])\n",
    "        \n",
    "    ### Gamma_F computation\n",
    "    g_F = gamma_F(p_mono, x.shape[1], max_size)\n",
    "    \n",
    "    ### Check if betaout desired, if so compute beta_hat of model corresponding to specific gamma0\n",
    "    if betaout==True or bag==True:\n",
    "        betahats = beta_est(x, y, g0, g_F, cov_entry_order)\n",
    "        \n",
    "    ### Check if bagging desired\n",
    "    if bag==False: \n",
    "        ### Alpha_F computation for all steps in fwd sel proc\n",
    "        a_F = alpha_F(g0, x.shape[1], max_size)\n",
    "        \n",
    "        ### Model size\n",
    "        S = np.arange(max_size)+1\n",
    "        \n",
    "        ### Combine S, Cov_names, p-vals, sorted p-vals, alpha_F, gamma_F into table\n",
    "        fsr_results = fsrtable(S, cov_entry_order, p_orig, p_mono, a_F, g_F)\n",
    "        \n",
    "        ### Return selected output: FSR table (+ betahat) (+ alpha_specific)\n",
    "        if gs!=None: \n",
    "            ### Compute alpha_F for specific gammas (gs)\n",
    "            if betaout==True:\n",
    "                return fsr_results, np.around(betahats, prec_b), alpha_F_g(gs, g_F, x.shape[1])\n",
    "            else:\n",
    "                return fsr_results, alpha_F_g(gs, g_F, x.shape[1])\n",
    "        else:\n",
    "            if betaout==True:\n",
    "                return fsr_results, np.around(betahats, prec_b)\n",
    "            else:\n",
    "                return fsr_results\n",
    "    else:\n",
    "        return betahats, alpha_F_g(g0, g_F, x.shape[1]), len(betahats)\n",
    "\n",
    "    \n",
    "    \n",
    "def bagfsr(X,Y,g0,B=200,max_s=None,v_incl=None,prec=4):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   X      = python dataframe of original p covariates, n x p\n",
    "    #   Y      = python outcome dataframe, n x 1\n",
    "    #   g0     = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   B      = integer of number of bagged samples\n",
    "    #   max_s  = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   v_incl = array of cols corresponding to those vars to force into model\n",
    "    #   prec   = integer of precision (num digits) desired in beta-hat parameter estimates of final model\n",
    "    \n",
    "    ### Output: \n",
    "    #   Mean of betahats\n",
    "    #   SEs of betahats\n",
    "    #   Avg alpha-to-enter\n",
    "    #   Avg model size\n",
    "    #   Prop of times each var included in model\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data - make sure X, Y = pandas dataframes or else convert them\n",
    "    if df_type(X)==True:\n",
    "        if isinstance(X,pd.DataFrame):\n",
    "            x = X.copy()\n",
    "        else:\n",
    "            if isinstance(X,np.ndarray):\n",
    "                x = pd.DataFrame(X)\n",
    "                vnum = list(np.arange(x.shape[1])+1)\n",
    "                vchr = list(np.repeat(\"V\",x.shape[1]))\n",
    "                x.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "    else:\n",
    "        return df_type(X)\n",
    "    if df_type(Y)==True:\n",
    "        if isinstance(Y,pd.DataFrame):\n",
    "            y = Y.copy()\n",
    "        else:\n",
    "            if isinstance(Y,np.ndarray):\n",
    "                y = pd.DataFrame(Y)\n",
    "    else:\n",
    "        return df_type(Y)\n",
    "    \n",
    "    # Remove missing values\n",
    "    yna = np.isnan(y).any(axis=1)\n",
    "    xna = np.isnan(x).any(axis=1).reshape(x.shape[0],1)\n",
    "    anyna = np.array([int(max(a,b)) for a,b in zip(xna,yna)])\n",
    "    missrow = np.where(anyna==1)[0]\n",
    "    y = y.drop(y.index[missrow])\n",
    "    x = x.drop(x.index[missrow])\n",
    "    \n",
    "    # check that p < n to ensure regression solutions\n",
    "    if x.shape[1] >= x.shape[0]:\n",
    "        raise Exception(\"N must be > p for valid regression solutions\")\n",
    "    \n",
    "    ### Combine data into single dataframe\n",
    "    dat = pd.concat([y,x],axis=1)\n",
    "    \n",
    "    ### Create array to keep track of number of times vars enter model\n",
    "    nentries = pd.DataFrame(np.zeros(x.shape[1]),index=x.columns.values)\n",
    "    \n",
    "    ### Create array to store all estimated coefficients, ses, alphas, sizes\n",
    "    allbetas = pd.DataFrame(np.zeros([B,x.shape[1]]),columns=x.columns.values)\n",
    "    allses = allbetas.copy()\n",
    "    alphas = []\n",
    "    sizes = []\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    ### Bagging loops\n",
    "    for i in range(B):\n",
    "\n",
    "        # Draw with replacement from rows of data\n",
    "        \n",
    "        n_row = dat.shape[0]\n",
    "        rand_row = np.random.randint(0,n_row,n_row)\n",
    "        newdat = dat.iloc[rand_row,:]\n",
    "        newdat.index = np.arange(n_row)+1\n",
    "        \n",
    "        ### Obtain FSR results\n",
    "        fsrout = ffsr(newdat.iloc[:,1:],pd.DataFrame(newdat.iloc[:,0]),g0,bag=True,max_size=max_s,var_incl=v_incl)\n",
    "        allbetas.loc[i,fsrout[0].index.values] = fsrout[0].iloc[:,0]\n",
    "        allses.loc[i,fsrout[0].index.values] = fsrout[0].iloc[:,1]\n",
    "        alphas.append(fsrout[1])\n",
    "        sizes.append(fsrout[2])\n",
    "\n",
    "        ### Update counts num times var included\n",
    "        nentries.loc[fsrout[0].index[np.abs(np.around(fsrout[0].iloc[:,0],prec))>0]] += 1\n",
    "        \n",
    "    ### Compute averages\n",
    "    avgbeta = np.around(allbetas.mean(axis=0),prec) # mean across rows / colmeans == mean of each cov's betahat\n",
    "    avgse = np.around(allses.mean(axis=0),prec)\n",
    "    avgalpha = np.mean(alphas)\n",
    "    avgsize = np.mean(sizes)\n",
    "    var_props = nentries/float(B)\n",
    "    cov_res = pd.concat([avgbeta,avgse,var_props],axis=1)\n",
    "    cov_res.columns = ['betahat','betase','prop_incl']\n",
    "    \n",
    "    return cov_res, avgalpha, avgsize\n",
    "    \n",
    "    \n",
    "\n",
    "# Notes: \n",
    "# 1. appropriate transformations are expected to have been applied prior to utilization of FSR algorithm\n",
    "\n",
    "# To-do:\n",
    "# 1. adjust betaest fcn and ffsr to allow for specification of intercept and whether data should be normalized in estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "### Code to test / build functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%load_ext rpy2.ipython # code to load/connect to R software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rpy2.robjects as ro\n",
    "import pandas.rpy.common as com\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# load R package\n",
    "leaps = importr('leaps')\n",
    "stats = importr('stats')\n",
    "base = importr('base')\n",
    "\n",
    "regsub = ro.r('leaps::regsubsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "X = np.random.multivariate_normal(np.zeros(15),np.eye(15),(100))\n",
    "beta = np.array([0,0,5,6,0,0,4,0,0,0,5,0,0,0,0]).reshape(15,1) # signif betas: 3,4,7,11\n",
    "Y = X.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y2 = pd.DataFrame(Y)\n",
    "X2 = pd.DataFrame(X)\n",
    "X2.columns = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011063307394438393"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = list(X2)\n",
    "\n",
    "bb = []\n",
    "newf = feats[3]\n",
    "bbb = bb + [newf]\n",
    "bbb = bbb + [feats[7]]\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "x = X2\n",
    "y = Y2\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X2.loc[:,bbb], Y2)\n",
    "\n",
    "regr.score(X2.loc[:,bbb],Y2)\n",
    "#type(X2.loc[:5,feats[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_forw_select(features, max_k, criterion_func, print_steps=False):\n",
    "    \"\"\"\n",
    "    Implementation of a Sequential Forward Selection algorithm.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        features (list): The feature space as a list of features.\n",
    "        max_k: Termination criterion; the size of the returned feature subset.\n",
    "        criterion_func (function): Function that is used to evaluate the\n",
    "            performance of the feature subset.\n",
    "        print_steps (bool): Prints the algorithm procedure if True.\n",
    "    \n",
    "    Returns the selected feature subset, a list of features of length max_k.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialization\n",
    "    feat_sub = [features[0]]\n",
    "    k = 0\n",
    "    d = len(features)\n",
    "    if max_k > d:\n",
    "        max_k = d\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # Inclusion step\n",
    "        if print_steps:\n",
    "            print('\\nInclusion from feature space', features)\n",
    "        crit_func_max = criterion_func(feat_sub + [features[1]])\n",
    "        best_feat = features[1]\n",
    "        for x in features[2:]:\n",
    "            crit_func_eval = criterion_func(feat_sub + [x])\n",
    "            if crit_func_eval < crit_func_max:\n",
    "                crit_func_max = crit_func_eval\n",
    "                best_feat = x\n",
    "        feat_sub.append(best_feat)\n",
    "        if print_steps:\n",
    "            print('include: {} -> feature subset: {}'.format(best_feat, feat_sub))\n",
    "        features.remove(best_feat)\n",
    "        \n",
    "        # Termination condition\n",
    "        k = len(feat_sub)\n",
    "        if k == max_k:\n",
    "            break\n",
    "                \n",
    "    return feat_sub\n",
    "\n",
    "def criterion_f(f):\n",
    "\n",
    "    x = X2.copy()\n",
    "    x.insert(0,'int',1.)\n",
    "    y = Y2\n",
    "\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    mod = sm.OLS(y, x.loc[:,f])\n",
    "    rs = mod.fit()\n",
    "    \n",
    "    return rs.pvalues[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['int', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15']\n",
      "('\\nInclusion from feature space', ['int', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15'])\n",
      "include: V4 -> feature subset: ['int', 'V4']\n",
      "('\\nInclusion from feature space', ['int', 'V1', 'V2', 'V3', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15'])\n",
      "include: V7 -> feature subset: ['int', 'V4', 'V7']\n",
      "('\\nInclusion from feature space', ['int', 'V1', 'V2', 'V3', 'V5', 'V6', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15'])\n",
      "include: V3 -> feature subset: ['int', 'V4', 'V7', 'V3']\n",
      "('\\nInclusion from feature space', ['int', 'V1', 'V2', 'V5', 'V6', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15'])\n",
      "include: V11 -> feature subset: ['int', 'V4', 'V7', 'V3', 'V11']\n",
      "('\\nInclusion from feature space', ['int', 'V1', 'V2', 'V5', 'V6', 'V8', 'V9', 'V10', 'V12', 'V13', 'V14', 'V15'])\n",
      "include: V13 -> feature subset: ['int', 'V4', 'V7', 'V3', 'V11', 'V13']\n"
     ]
    }
   ],
   "source": [
    "feats = list(X2)\n",
    "\n",
    "X3 = X2.copy()\n",
    "X3.insert(0,'int',1.)\n",
    "\n",
    "b = ['int'] + [feats[3]]\n",
    "mod = sm.OLS(Y2, X3.loc[:,b])\n",
    "rs = mod.fit()\n",
    "# print rs.pvalues[-1]\n",
    "# print criterion_f(b)\n",
    "\n",
    "# b = b + [feats[2]]\n",
    "# mod = sm.OLS(Y2, X2.loc[:,b])\n",
    "# rs = mod.fit()\n",
    "# print rs.pvalues\n",
    "# print criterion_f(b)\n",
    "\n",
    "# b = b + [feats[6]]\n",
    "# mod = sm.OLS(Y2, X3.loc[:,b])\n",
    "# rs = mod.fit()\n",
    "# print rs.pvalues\n",
    "# print criterion_f(b)\n",
    "\n",
    "# b = b + [feats[2]]\n",
    "# mod = sm.OLS(Y2, X3.loc[:,b])\n",
    "# rs = mod.fit()\n",
    "# print rs.pvalues\n",
    "# print criterion_f(b)\n",
    "\n",
    "# b = b + [feats[10]]\n",
    "# mod = sm.OLS(Y2, X3.loc[:,b])\n",
    "# rs = mod.fit()\n",
    "# print rs.pvalues\n",
    "# print criterion_f(b)\n",
    "\n",
    "# b = b + [feats[1]]\n",
    "# mod = sm.OLS(Y2, X3.loc[:,b])\n",
    "# rs = mod.fit()\n",
    "# print rs.pvalues\n",
    "# print criterion_f(b)\n",
    "\n",
    "feats = list(X3)\n",
    "print feats\n",
    "seq_forw_select(feats, 6, criterion_f, print_steps=True)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "# mod = sm.OLS(Y2, X2.loc[:,b])\n",
    "# rs = mod.fit()\n",
    "# rs.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### USELESS\n",
    "\n",
    "from sklearn import linear_model\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X2, Y2)\n",
    "\n",
    "# The coefficients\n",
    "#modvar = \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "#?SelectKBest\n",
    "X_new = SelectKBest(f_regression, k=4).fit_transform(X2, Y2)\n",
    "print X_new[:5,:5]\n",
    "X2.iloc[:5,[2,3,6,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### USELESS\n",
    "\n",
    "from sklearn import linear_model\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X2, Y2)\n",
    "\n",
    "# The coefficients\n",
    "#modvar = \n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "\n",
    "def f_regression(X,Y):\n",
    "   return sklearn.feature_selection.f_regression(X,Y,center=False)\n",
    "\n",
    "#?SelectKBest\n",
    "X_new = SelectKBest(f_regression, k='all').fit(X2.iloc[:,[2,3]], Y2)\n",
    "print X_new.scores_\n",
    "# print X_new[:5,:5]\n",
    "# print X2.iloc[:5,[2,3,6,10]]\n",
    "\n",
    "featureSelector = SelectKBest(f_regression,k='all')\n",
    "featureSelector.fit(X2,Y2)\n",
    "featureSelector.fit(X2.iloc[:,0],Y2)\n",
    "#print featureSelector.scores_\n",
    "# list(featureSelector.get_support(indices=True))\n",
    "\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# X_new2 = DecisionTreeRegressor(min_samples_split=15).fit(X2,Y2)\n",
    "# import scipy.stats as ss\n",
    "# print ss.rankdata(X_new2.feature_importances_,method='max')\n",
    "# print X_new2.feature_importances_\n",
    "#?ss.rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "# iris = load_iris()\n",
    "# X, y = iris.data, iris.target\n",
    "# X.shape\n",
    "# X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "# X_new.shape\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "rfe = RFE(estimator=svc, n_features_to_select=10, step=1)\n",
    "rfe.fit(X2, np.array(Y2))\n",
    "rfe.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.08292178e-12]\n",
      "[  6.08292178e-12   2.31260818e-07]\n",
      "[  6.08292178e-12   2.31260818e-07   3.04135487e-09]\n",
      "['V4', 'V7', 'V3']\n",
      "[  6.08292178e-12   2.31260818e-07   3.04135487e-09   6.12984256e-09]\n",
      "['V4', 'V7', 'V3', 'V11']\n",
      "6.12984256479e-09\n"
     ]
    }
   ],
   "source": [
    "##### USELESS\n",
    "\n",
    "#criterion_f(feats[2:3])\n",
    "\n",
    "feats = list(X2)\n",
    "\n",
    "b = [feats[3]]\n",
    "selection = SelectKBest(f_regression,k='all').fit(X2.loc[:,b], Y2)\n",
    "print selection.pvalues_\n",
    "\n",
    "b = b + [feats[6]]\n",
    "selection = SelectKBest(f_regression,k='all').fit(X2.loc[:,b], Y2)\n",
    "print selection.pvalues_\n",
    "\n",
    "b = b + [feats[2]]\n",
    "selection = SelectKBest(f_regression,k='all').fit(X2.loc[:,b], Y2)\n",
    "print selection.pvalues_\n",
    "print b\n",
    "\n",
    "b = b + [feats[10]]\n",
    "selection = SelectKBest(f_regression,k='all').fit(X2.loc[:,b], Y2)\n",
    "print selection.pvalues_\n",
    "print b\n",
    "print selection.pvalues_[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V5']\n",
      "['V5', 'V8']\n",
      "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15']\n"
     ]
    }
   ],
   "source": [
    "### USELESS\n",
    "\n",
    "b = b + [feats[2]]\n",
    "selection = SelectKBest(f_regression,k='all').fit(X2.loc[:,b], Y2)\n",
    "print selection.scores_\n",
    "feats = list(X2)\n",
    "newf = feats[4]\n",
    "# print newf\n",
    "newf2 = [newf,feats[7]] #newf.append(feats[7])\n",
    "# print newf2\n",
    "bb = []\n",
    "bbb = bb + [newf]\n",
    "print bbb\n",
    "bbb = bbb + [feats[7]]\n",
    "print bbb\n",
    "print feats\n",
    "\n",
    "#seq_forw_select(feats, 4, criterion_f, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "### Test functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fwd_r = forward(X2,Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V4' 'V7' 'V3' 'V11' 'V2' 'V10' 'V1' 'V5' 'V15' 'V12' 'V14' 'V8' 'V9' 'V6'\n",
      " 'V13']\n",
      " [1]  1  5  8  4 12  3 11  2  6 16 13 15  9 10  7 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "codnames = cov_order(X2.columns.values)\n",
    "\n",
    "print codnames\n",
    "\n",
    "print ro.r('fwd$vorder')\n",
    "# ro.globalenv['out_cov'] = fwd_proc\n",
    "    \n",
    "# ### Pull the cov entry order\n",
    "# vorder = ro.r('out_cov$vorder[-1]') # remove intercept\n",
    "# vorder = vorder[0:max_size] # keep only the max model size number of covs\n",
    "\n",
    "# ### Shift these values down by two (one to exclude intercept, one to make python indices)\n",
    "# vorderinds = np.array(vorder)-2\n",
    "\n",
    "# ### Rearrange the var order st forced vars are at start of list\n",
    "# col_names = xcolnames\n",
    "# keep = col_nam[[col_incl-1]] # pull var names of those vars forced into model (this is an array)\n",
    "# poss = [x for x in col_nam if x not in keep] # pull var names of those not forced in (this is a list)\n",
    "# col_names2 = np.array(list(keep)+poss) # = rearranged array of varnames w/forced-in vars at start of list\n",
    "\n",
    "# ### Sort the columns of X in order to obtain the var names in the entry order\n",
    "# return col_names2[vorderinds[::]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "po = pval_comp(X2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg00 = 0.05\n",
    "af = alpha_F(gg00, X2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gf = gamma_F(po, X2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = np.arange(X2.shape[1])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fsr_results = fsrtable(sss, codnames, po, np.sort(po), af, gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Var</th>\n",
       "      <th>p</th>\n",
       "      <th>p_s</th>\n",
       "      <th>alpha_F</th>\n",
       "      <th>gamma_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td>  1</td>\n",
       "      <td>  V4</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0071</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td>  2</td>\n",
       "      <td>  V7</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0115</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td>  3</td>\n",
       "      <td>  V3</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0167</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td>  4</td>\n",
       "      <td> V11</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0227</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>  5</td>\n",
       "      <td>  V2</td>\n",
       "      <td> 0.0002</td>\n",
       "      <td> 0.0002</td>\n",
       "      <td> 0.0300</td>\n",
       "      <td> 0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>  6</td>\n",
       "      <td> V10</td>\n",
       "      <td> 0.0075</td>\n",
       "      <td> 0.0075</td>\n",
       "      <td> 0.0389</td>\n",
       "      <td> 0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td>  7</td>\n",
       "      <td>  V1</td>\n",
       "      <td> 0.0111</td>\n",
       "      <td> 0.0111</td>\n",
       "      <td> 0.0500</td>\n",
       "      <td> 0.0111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>  8</td>\n",
       "      <td>  V5</td>\n",
       "      <td> 0.0954</td>\n",
       "      <td> 0.0784</td>\n",
       "      <td> 0.0643</td>\n",
       "      <td> 0.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td>  9</td>\n",
       "      <td> V15</td>\n",
       "      <td> 0.0784</td>\n",
       "      <td> 0.0954</td>\n",
       "      <td> 0.0833</td>\n",
       "      <td> 0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 10</td>\n",
       "      <td> V12</td>\n",
       "      <td> 0.1238</td>\n",
       "      <td> 0.1238</td>\n",
       "      <td> 0.1100</td>\n",
       "      <td> 0.0563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 11</td>\n",
       "      <td> V14</td>\n",
       "      <td> 0.2015</td>\n",
       "      <td> 0.2015</td>\n",
       "      <td> 0.1500</td>\n",
       "      <td> 0.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 12</td>\n",
       "      <td>  V8</td>\n",
       "      <td> 0.2453</td>\n",
       "      <td> 0.2453</td>\n",
       "      <td> 0.2167</td>\n",
       "      <td> 0.0566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> 13</td>\n",
       "      <td>  V9</td>\n",
       "      <td> 0.3651</td>\n",
       "      <td> 0.3651</td>\n",
       "      <td> 0.3500</td>\n",
       "      <td> 0.0522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td> 14</td>\n",
       "      <td>  V6</td>\n",
       "      <td> 0.6455</td>\n",
       "      <td> 0.6455</td>\n",
       "      <td> 0.7500</td>\n",
       "      <td> 0.0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> 15</td>\n",
       "      <td> V13</td>\n",
       "      <td> 0.7094</td>\n",
       "      <td> 0.7094</td>\n",
       "      <td> 1.0000</td>\n",
       "      <td> 0.7094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     S  Var       p     p_s  alpha_F  gamma_F\n",
       "0    1   V4  0.0000  0.0000   0.0071   0.0000\n",
       "1    2   V7  0.0000  0.0000   0.0115   0.0000\n",
       "2    3   V3  0.0000  0.0000   0.0167   0.0000\n",
       "3    4  V11  0.0000  0.0000   0.0227   0.0000\n",
       "4    5   V2  0.0002  0.0002   0.0300   0.0003\n",
       "5    6  V10  0.0075  0.0075   0.0389   0.0096\n",
       "6    7   V1  0.0111  0.0111   0.0500   0.0111\n",
       "7    8   V5  0.0954  0.0784   0.0643   0.0610\n",
       "8    9  V15  0.0784  0.0954   0.0833   0.0572\n",
       "9   10  V12  0.1238  0.1238   0.1100   0.0563\n",
       "10  11  V14  0.2015  0.2015   0.1500   0.0672\n",
       "11  12   V8  0.2453  0.2453   0.2167   0.0566\n",
       "12  13   V9  0.3651  0.3651   0.3500   0.0522\n",
       "13  14   V6  0.6455  0.6455   0.7500   0.0430\n",
       "14  15  V13  0.7094  0.7094   1.0000   0.7094"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     S  Var       p     p_s  alpha_F  gamma_F\n",
      "0    1   V4  0.0000  0.0000   0.0071   0.0000\n",
      "1    2   V7  0.0000  0.0000   0.0115   0.0000\n",
      "2    3   V3  0.0000  0.0000   0.0167   0.0000\n",
      "3    4  V11  0.0000  0.0000   0.0227   0.0000\n",
      "4    5   V2  0.0002  0.0002   0.0300   0.0003\n",
      "5    6  V10  0.0075  0.0075   0.0389   0.0096\n",
      "6    7   V1  0.0111  0.0111   0.0500   0.0111\n",
      "7    8   V5  0.0954  0.0784   0.0643   0.0610\n",
      "8    9  V15  0.0784  0.0954   0.0833   0.0572\n",
      "9   10  V12  0.1238  0.1238   0.1100   0.0563\n",
      "10  11  V14  0.2015  0.2015   0.1500   0.0672\n",
      "11  12   V8  0.2453  0.2453   0.2167   0.0566\n",
      "12  13   V9  0.3651  0.3651   0.3500   0.0522\n",
      "13  14   V6  0.6455  0.6455   0.7500   0.0430\n",
      "14  15  V13  0.7094  0.7094   1.0000   0.7094\n",
      "\n",
      "     beta  beta_se\n",
      "V4      6        0\n",
      "V7      4        0\n",
      "V3      5        0\n",
      "V11     5        0\n",
      "V2      0        0\n",
      "V10     0        0\n",
      "V1     -0        0\n"
     ]
    }
   ],
   "source": [
    "ftab, bhats = ffsr(X2,Y2,0.05,betaout=True)\n",
    "print ftab\n",
    "print\n",
    "print bhats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003\n",
      "[ 0.05   0.003]\n"
     ]
    }
   ],
   "source": [
    "gs = ftab.gamma_F\n",
    "isinstance(np.array([0.05,0.1]),np.ndarray)\n",
    "sub = [np.where(gs>y) for y in np.array([0.05,0.1])]\n",
    "sub\n",
    "ss = [min(x[0]) for x in sub]\n",
    "ss\n",
    "min(np.where(gs>0.05)[0])\n",
    "print alpha_F_g(0.005,gs,15)\n",
    "print alpha_F_g(np.array([0.05,0.005]),gs,15)\n",
    "#ss = np.array([max(np.which(x<=0.05)) for x in ftab.gamma_F])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = min(np.where(gs>0.005)[0])\n",
    "ss\n",
    "vs = ftab.Var[0:ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00100994110107\n",
      "\n",
      "[[ -9.43689571e-16   5.55111512e-16   5.00000000e+00   6.00000000e+00\n",
      "   -1.49186219e-15   1.77635684e-15   4.00000000e+00  -2.22044605e-15\n",
      "   -6.66133815e-16  -1.88737914e-15   5.00000000e+00   1.55431223e-15\n",
      "   -2.66453526e-15   7.21644966e-16   5.16253706e-15]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X2, Y2)\n",
    "\n",
    "# The coefficients\n",
    "modvar = regr.coef_\n",
    "\n",
    "print (time.time() - start)\n",
    "print\n",
    "print modvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00221705436707\n",
      "\n",
      "V1     4.440892e-16\n",
      "V2    -1.387779e-15\n",
      "V3     5.000000e+00\n",
      "V4     6.000000e+00\n",
      "V5     1.720846e-15\n",
      "V6     2.220446e-16\n",
      "V7     4.000000e+00\n",
      "V8     6.661338e-16\n",
      "V9     4.420075e-15\n",
      "V10   -3.164136e-15\n",
      "V11    5.000000e+00\n",
      "V12   -7.771561e-16\n",
      "V13   -1.505740e-15\n",
      "V14    6.383782e-16\n",
      "V15   -6.661338e-16\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "mod = sm.OLS(Y2, X2)\n",
    "rs = mod.fit()\n",
    "modvar2 = rs.params\n",
    "#modvarse2 = rs.bse\n",
    "\n",
    "print (time.time() - start)\n",
    "print\n",
    "print modvar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16) (100, 16) (100, 15)\n",
      "   int        V1        V2        V3        V4\n",
      "0    1  0.471435 -1.190976  1.432707 -0.312652\n",
      "1    1  0.002118  0.405453  0.289092  1.321158\n",
      "2    1 -0.397840  0.337438  1.047579  1.045938\n",
      "3    1 -0.897157 -0.136795  0.018289  0.755414\n",
      "4    1 -0.974236 -0.070345  0.307969 -0.208499\n",
      "\n",
      "int    2.345346e-15\n",
      "V1    -4.440892e-16\n",
      "V2    -1.609823e-15\n",
      "V3     5.000000e+00\n",
      "V4     6.000000e+00\n",
      "V5     1.221245e-15\n",
      "V6     7.938095e-15\n",
      "V7     4.000000e+00\n",
      "V8     3.219647e-15\n",
      "V9     2.782496e-15\n",
      "V10    3.275158e-15\n",
      "V11    5.000000e+00\n",
      "V12   -1.332268e-15\n",
      "V13   -4.725387e-15\n",
      "V14   -4.315992e-15\n",
      "V15   -3.774758e-15\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# to add intercept:\n",
    "\n",
    "X3 = sm.add_constant(X2)\n",
    "X4 = X2.copy()\n",
    "X4.insert(0,'int',1)\n",
    "print X4.shape, X3.shape, X2.shape\n",
    "print X4.iloc[:5,:5]\n",
    "mod = sm.OLS(Y2, X4)\n",
    "rs = mod.fit()\n",
    "modvar2 = rs.params\n",
    "#modvarse2 = rs.bse\n",
    "\n",
    "print\n",
    "print modvar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Y</td>        <th>  No. Observations:  </th>    <td>   100</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>    <td>    84</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>       <td>Gaussian</td>     <th>  Df Model:          </th>    <td>    15</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>      <td>identity</td>     <th>  Scale:             </th> <td>9.25311095482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th>   <td> -244.42</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Wed, 15 Apr 2015</td> <th>  Deviance:          </th>   <td>  777.26</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>17:32:51</td>     <th>  Pearson chi2:      </th>    <td>  777.</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>3</td>        <th>                     </th>       <td> </td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -8.6063</td> <td>    0.684</td> <td>  -12.580</td> <td> 0.000</td> <td>   -9.947    -7.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1</th>        <td>   -0.4899</td> <td>    0.319</td> <td>   -1.535</td> <td> 0.125</td> <td>   -1.115     0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V2</th>        <td>   -0.0009</td> <td>    0.361</td> <td>   -0.002</td> <td> 0.998</td> <td>   -0.709     0.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V3</th>        <td>    4.7984</td> <td>    0.333</td> <td>   14.405</td> <td> 0.000</td> <td>    4.146     5.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V4</th>        <td>    5.4745</td> <td>    0.312</td> <td>   17.562</td> <td> 0.000</td> <td>    4.863     6.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V5</th>        <td>   -0.0869</td> <td>    0.292</td> <td>   -0.298</td> <td> 0.766</td> <td>   -0.660     0.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6</th>        <td>    0.0632</td> <td>    0.334</td> <td>    0.189</td> <td> 0.850</td> <td>   -0.591     0.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V7</th>        <td>    3.8846</td> <td>    0.339</td> <td>   11.446</td> <td> 0.000</td> <td>    3.219     4.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V8</th>        <td>   -0.3027</td> <td>    0.322</td> <td>   -0.941</td> <td> 0.347</td> <td>   -0.933     0.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V9</th>        <td>    0.1804</td> <td>    0.327</td> <td>    0.551</td> <td> 0.581</td> <td>   -0.461     0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V10</th>       <td>    0.1905</td> <td>    0.305</td> <td>    0.624</td> <td> 0.533</td> <td>   -0.408     0.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V11</th>       <td>    4.6676</td> <td>    0.378</td> <td>   12.359</td> <td> 0.000</td> <td>    3.927     5.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V12</th>       <td>   -0.1051</td> <td>    0.316</td> <td>   -0.332</td> <td> 0.740</td> <td>   -0.725     0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V13</th>       <td>   -0.3743</td> <td>    0.273</td> <td>   -1.370</td> <td> 0.171</td> <td>   -0.910     0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V14</th>       <td>   -0.2015</td> <td>    0.279</td> <td>   -0.721</td> <td> 0.471</td> <td>   -0.749     0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V15</th>       <td>   -0.5519</td> <td>    0.328</td> <td>   -1.684</td> <td> 0.092</td> <td>   -1.194     0.090</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   No. Observations:                  100\n",
       "Model:                            GLM   Df Residuals:                       84\n",
       "Model Family:                Gaussian   Df Model:                           15\n",
       "Link Function:               identity   Scale:                   9.25311095482\n",
       "Method:                          IRLS   Log-Likelihood:                -244.42\n",
       "Date:                Wed, 15 Apr 2015   Deviance:                       777.26\n",
       "Time:                        17:32:51   Pearson chi2:                     777.\n",
       "No. Iterations:                     3                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -8.6063      0.684    -12.580      0.000        -9.947    -7.265\n",
       "V1            -0.4899      0.319     -1.535      0.125        -1.115     0.135\n",
       "V2            -0.0009      0.361     -0.002      0.998        -0.709     0.708\n",
       "V3             4.7984      0.333     14.405      0.000         4.146     5.451\n",
       "V4             5.4745      0.312     17.562      0.000         4.863     6.085\n",
       "V5            -0.0869      0.292     -0.298      0.766        -0.660     0.486\n",
       "V6             0.0632      0.334      0.189      0.850        -0.591     0.717\n",
       "V7             3.8846      0.339     11.446      0.000         3.219     4.550\n",
       "V8            -0.3027      0.322     -0.941      0.347        -0.933     0.328\n",
       "V9             0.1804      0.327      0.551      0.581        -0.461     0.821\n",
       "V10            0.1905      0.305      0.624      0.533        -0.408     0.789\n",
       "V11            4.6676      0.378     12.359      0.000         3.927     5.408\n",
       "V12           -0.1051      0.316     -0.332      0.740        -0.725     0.515\n",
       "V13           -0.3743      0.273     -1.370      0.171        -0.910     0.161\n",
       "V14           -0.2015      0.279     -0.721      0.471        -0.749     0.346\n",
       "V15           -0.5519      0.328     -1.684      0.092        -1.194     0.090\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = X2 + np.random.random(X2.shape[1]*X2.shape[0]).reshape(X2.shape[0],X2.shape[1])\n",
    "dd = pd.concat([Y2,X3],axis=1)\n",
    "dd.columns.values[0] = 'Y'\n",
    "dd.columns.values\n",
    "fit2 = sm.GLM.from_formula('Y ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15', data=dd, family=sm.families.Gaussian()).fit()\n",
    "#fit2 = sm.GLM(Y2,X2,family=sm.families.family.Gaussian).fit()\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>0</td>        <th>  No. Observations:  </th>    <td>   100</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>    <td>    85</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>       <td>Gaussian</td>     <th>  Df Model:          </th>    <td>    14</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>      <td>identity</td>     <th>  Scale:             </th> <td>26.3716116733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th>   <td> -297.38</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Wed, 15 Apr 2015</td> <th>  Deviance:          </th>   <td>  2241.6</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>17:32:56</td>     <th>  Pearson chi2:      </th>   <td>2.24e+03</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>3</td>        <th>                     </th>       <td> </td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1</th>  <td>   -1.4800</td> <td>    0.522</td> <td>   -2.835</td> <td> 0.005</td> <td>   -2.503    -0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V2</th>  <td>   -1.3713</td> <td>    0.582</td> <td>   -2.357</td> <td> 0.018</td> <td>   -2.512    -0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V3</th>  <td>    3.4876</td> <td>    0.534</td> <td>    6.530</td> <td> 0.000</td> <td>    2.441     4.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V4</th>  <td>    4.7535</td> <td>    0.517</td> <td>    9.189</td> <td> 0.000</td> <td>    3.740     5.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V5</th>  <td>   -0.9667</td> <td>    0.479</td> <td>   -2.019</td> <td> 0.044</td> <td>   -1.905    -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6</th>  <td>   -1.5131</td> <td>    0.522</td> <td>   -2.896</td> <td> 0.004</td> <td>   -2.537    -0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V7</th>  <td>    3.3028</td> <td>    0.568</td> <td>    5.819</td> <td> 0.000</td> <td>    2.190     4.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V8</th>  <td>   -1.3393</td> <td>    0.525</td> <td>   -2.550</td> <td> 0.011</td> <td>   -2.369    -0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V9</th>  <td>   -0.4280</td> <td>    0.546</td> <td>   -0.784</td> <td> 0.433</td> <td>   -1.498     0.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V10</th> <td>   -0.0770</td> <td>    0.514</td> <td>   -0.150</td> <td> 0.881</td> <td>   -1.085     0.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V11</th> <td>    3.8144</td> <td>    0.627</td> <td>    6.081</td> <td> 0.000</td> <td>    2.585     5.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V12</th> <td>   -0.9516</td> <td>    0.522</td> <td>   -1.823</td> <td> 0.068</td> <td>   -1.975     0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V13</th> <td>   -0.8440</td> <td>    0.457</td> <td>   -1.848</td> <td> 0.065</td> <td>   -1.739     0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V14</th> <td>   -0.9204</td> <td>    0.462</td> <td>   -1.994</td> <td> 0.046</td> <td>   -1.825    -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V15</th> <td>   -0.9954</td> <td>    0.550</td> <td>   -1.810</td> <td> 0.070</td> <td>   -2.074     0.083</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      0   No. Observations:                  100\n",
       "Model:                            GLM   Df Residuals:                       85\n",
       "Model Family:                Gaussian   Df Model:                           14\n",
       "Link Function:               identity   Scale:                   26.3716116733\n",
       "Method:                          IRLS   Log-Likelihood:                -297.38\n",
       "Date:                Wed, 15 Apr 2015   Deviance:                       2241.6\n",
       "Time:                        17:32:56   Pearson chi2:                 2.24e+03\n",
       "No. Iterations:                     3                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "V1            -1.4800      0.522     -2.835      0.005        -2.503    -0.457\n",
       "V2            -1.3713      0.582     -2.357      0.018        -2.512    -0.231\n",
       "V3             3.4876      0.534      6.530      0.000         2.441     4.534\n",
       "V4             4.7535      0.517      9.189      0.000         3.740     5.767\n",
       "V5            -0.9667      0.479     -2.019      0.044        -1.905    -0.028\n",
       "V6            -1.5131      0.522     -2.896      0.004        -2.537    -0.489\n",
       "V7             3.3028      0.568      5.819      0.000         2.190     4.415\n",
       "V8            -1.3393      0.525     -2.550      0.011        -2.369    -0.310\n",
       "V9            -0.4280      0.546     -0.784      0.433        -1.498     0.642\n",
       "V10           -0.0770      0.514     -0.150      0.881        -1.085     0.931\n",
       "V11            3.8144      0.627      6.081      0.000         2.585     5.044\n",
       "V12           -0.9516      0.522     -1.823      0.068        -1.975     0.072\n",
       "V13           -0.8440      0.457     -1.848      0.065        -1.739     0.051\n",
       "V14           -0.9204      0.462     -1.994      0.046        -1.825    -0.016\n",
       "V15           -0.9954      0.550     -1.810      0.070        -2.074     0.083\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit2 = sm.GLM(Y2,X3,family=sm.families.Gaussian()).fit()\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(np.array(rs.params[1:]).reshape(1,15),regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V4', 'V7', 'V3', 'V11', 'V2']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             beta       beta_se\n",
      "V4   6.000000e+00  9.710566e-16\n",
      "V7   4.000000e+00  9.734326e-16\n",
      "V3   5.000000e+00  9.458140e-16\n",
      "V11  5.000000e+00  1.149754e-15\n",
      "V2   4.884981e-15  1.037405e-15\n",
      "     0\n",
      "V1   0\n",
      "V2   1\n",
      "V3   1\n",
      "V4   1\n",
      "V5   0\n",
      "V6   0\n",
      "V7   1\n",
      "V8   0\n",
      "V9   0\n",
      "V10  0\n",
      "V11  1\n",
      "V12  0\n",
      "V13  0\n",
      "V14  0\n",
      "V15  0\n",
      "<class 'pandas.core.index.Index'>\n"
     ]
    }
   ],
   "source": [
    "btests = beta_est(X2, Y2, 0.05, gs, vs)\n",
    "print btests\n",
    "vps = pd.DataFrame(np.zeros(15),index=X2.columns.values)\n",
    "#print vps\n",
    "vps.loc[btests.index] += 1\n",
    "print vps\n",
    "print type(btests.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.00000000e+00   4.00000000e+00   5.00000000e+00   5.00000000e+00\n",
      "   -1.33226763e-15]]\n",
      "             beta       beta_se\n",
      "int  2.345346e-15  1.950624e-15\n",
      "V1  -4.440892e-16  2.018584e-15\n",
      "V2  -1.609823e-15  2.210142e-15\n",
      "V3   5.000000e+00  1.953846e-15\n",
      "V4   6.000000e+00  1.926021e-15\n",
      "V5   1.221245e-15  1.843307e-15\n",
      "V6   7.938095e-15  1.976243e-15\n",
      "V7   4.000000e+00  2.069584e-15\n",
      "V8   3.219647e-15  2.053536e-15\n",
      "V9   2.782496e-15  2.009177e-15\n",
      "V10  3.275158e-15  2.094942e-15\n",
      "V11  5.000000e+00  2.427111e-15\n",
      "V12 -1.332268e-15  1.962414e-15\n",
      "V13 -4.725387e-15  1.714302e-15\n",
      "V14 -4.315992e-15  1.687020e-15\n",
      "V15 -3.774758e-15  1.993998e-15\n",
      "     beta  beta_se\n",
      "int     0        0\n",
      "V1     -0        0\n",
      "V2     -0        0\n",
      "V3      5        0\n",
      "V4      6        0\n",
      "V5      0        0\n",
      "V6      0        0\n",
      "V7      4        0\n",
      "V8      0        0\n",
      "V9      0        0\n",
      "V10     0        0\n",
      "V11     5        0\n",
      "V12    -0        0\n",
      "V13    -0        0\n",
      "V14    -0        0\n",
      "V15    -0        0\n"
     ]
    }
   ],
   "source": [
    "#X2.loc[:,'V1']\n",
    "regr.fit(X2.loc[:,list(vs)], Y2)\n",
    "\n",
    "# The coefficients\n",
    "modvar = regr.coef_\n",
    "print modvar\n",
    "#print rs.params\n",
    "dftest = pd.DataFrame([rs.params,rs.bse]).T\n",
    "dftest.columns = ['beta','beta_se']\n",
    "print dftest\n",
    "print np.around(dftest,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Var</th>\n",
       "      <th>p</th>\n",
       "      <th>p_s</th>\n",
       "      <th>alpha_F</th>\n",
       "      <th>gamma_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td>  V4</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0071</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2</td>\n",
       "      <td>  V7</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0115</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 3</td>\n",
       "      <td>  V3</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0167</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 4</td>\n",
       "      <td> V11</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0227</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 5</td>\n",
       "      <td>  V2</td>\n",
       "      <td> 0.0002</td>\n",
       "      <td> 0.0002</td>\n",
       "      <td> 0.0300</td>\n",
       "      <td> 0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 6</td>\n",
       "      <td> V10</td>\n",
       "      <td> 0.0075</td>\n",
       "      <td> 0.0075</td>\n",
       "      <td> 0.0389</td>\n",
       "      <td> 0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 7</td>\n",
       "      <td>  V1</td>\n",
       "      <td> 0.0111</td>\n",
       "      <td> 0.0111</td>\n",
       "      <td> 0.0500</td>\n",
       "      <td> 0.0111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 8</td>\n",
       "      <td>  V5</td>\n",
       "      <td> 0.0954</td>\n",
       "      <td> 0.0954</td>\n",
       "      <td> 0.0643</td>\n",
       "      <td> 0.0742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S  Var       p     p_s  alpha_F  gamma_F\n",
       "0  1   V4  0.0000  0.0000   0.0071   0.0000\n",
       "1  2   V7  0.0000  0.0000   0.0115   0.0000\n",
       "2  3   V3  0.0000  0.0000   0.0167   0.0000\n",
       "3  4  V11  0.0000  0.0000   0.0227   0.0000\n",
       "4  5   V2  0.0002  0.0002   0.0300   0.0003\n",
       "5  6  V10  0.0075  0.0075   0.0389   0.0096\n",
       "6  7   V1  0.0111  0.0111   0.0500   0.0111\n",
       "7  8   V5  0.0954  0.0954   0.0643   0.0742"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffsr(X2,Y2,0.05,max_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:87: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     S  Var       p     p_s  alpha_F  gamma_F\n",
       " 0    1   V5  0.3135  0.0000   0.0071   0.0000\n",
       " 1    2   V4  0.0000  0.0000   0.0115   0.0000\n",
       " 2    3   V3  0.0000  0.0000   0.0167   0.0000\n",
       " 3    4  V11  0.0000  0.0000   0.0227   0.0000\n",
       " 4    5   V7  0.0000  0.0291   0.0300   0.0485\n",
       " 5    6   V2  0.0291  0.1097   0.0389   0.1410\n",
       " 6    7   V6  0.1097  0.1114   0.0500   0.1114\n",
       " 7    8   V1  0.1114  0.2168   0.0643   0.1686\n",
       " 8    9  V13  0.2168  0.2418   0.0833   0.1451\n",
       " 9   10  V15  0.2418  0.3013   0.1100   0.1370\n",
       " 10  11   V9  0.3280  0.3135   0.1500   0.1045\n",
       " 11  12  V12  0.3013  0.3280   0.2167   0.0757\n",
       " 12  13  V10  0.5214  0.5214   0.3500   0.0745\n",
       " 13  14  V14  0.5820  0.5820   0.7500   0.0388\n",
       " 14  15   V8  0.8641  0.8641   1.0000   0.8641,      beta  beta_se\n",
       " V5     -0        0\n",
       " V4      6        0\n",
       " V3      5        0\n",
       " V11     5        0\n",
       " V7      4        0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffsr(X2,Y2,0.05,var_incl=np.array([5]),betaout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:121: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:87: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Var</th>\n",
       "      <th>p</th>\n",
       "      <th>p_s</th>\n",
       "      <th>alpha_F</th>\n",
       "      <th>gamma_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td>  V5</td>\n",
       "      <td> 0.3135</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0071</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2</td>\n",
       "      <td>  V4</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0115</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 3</td>\n",
       "      <td>  V3</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0167</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 4</td>\n",
       "      <td> V11</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0227</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 5</td>\n",
       "      <td>  V7</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0291</td>\n",
       "      <td> 0.0300</td>\n",
       "      <td> 0.0485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 6</td>\n",
       "      <td>  V2</td>\n",
       "      <td> 0.0291</td>\n",
       "      <td> 0.1097</td>\n",
       "      <td> 0.0389</td>\n",
       "      <td> 0.1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 7</td>\n",
       "      <td>  V6</td>\n",
       "      <td> 0.1097</td>\n",
       "      <td> 0.1114</td>\n",
       "      <td> 0.0500</td>\n",
       "      <td> 0.1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 8</td>\n",
       "      <td>  V1</td>\n",
       "      <td> 0.1114</td>\n",
       "      <td> 0.3135</td>\n",
       "      <td> 0.0643</td>\n",
       "      <td> 0.2438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S  Var       p     p_s  alpha_F  gamma_F\n",
       "0  1   V5  0.3135  0.0000   0.0071   0.0000\n",
       "1  2   V4  0.0000  0.0000   0.0115   0.0000\n",
       "2  3   V3  0.0000  0.0000   0.0167   0.0000\n",
       "3  4  V11  0.0000  0.0000   0.0227   0.0000\n",
       "4  5   V7  0.0000  0.0291   0.0300   0.0485\n",
       "5  6   V2  0.0291  0.1097   0.0389   0.1410\n",
       "6  7   V6  0.1097  0.1114   0.0500   0.1114\n",
       "7  8   V1  0.1114  0.3135   0.0643   0.2438"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffsr(X,Y,0.05,max_size=8,var_incl=np.array([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V4' 'V7' 'V3' 'V11' 'V2' 'V10' 'V1']\n",
      "             beta       beta_se\n",
      "V4   6.000000e+00  1.672676e-15\n",
      "V7   4.000000e+00  1.676875e-15\n",
      "V3   5.000000e+00  1.668047e-15\n",
      "V11  5.000000e+00  2.016266e-15\n",
      "V2   1.137979e-14  1.855839e-15\n",
      "V10  5.481726e-15  1.817640e-15\n",
      "V1  -1.110223e-15  1.727931e-15\n",
      "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  V11  V12  V13  V14  V15\n",
      "0  -0   0   5   6   0   0   4   0   0    0    5    0    0    0    0\n",
      "1   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0\n",
      "2   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0\n",
      "3   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0\n",
      "4   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0\n",
      "     0\n",
      "V1   0\n",
      "V2   0\n",
      "V3   0\n",
      "V4   0\n",
      "V5   0\n",
      "V6   0\n",
      "V7   0\n",
      "V8   0\n",
      "V9   0\n",
      "V10  0\n",
      "V11  0\n",
      "V12  0\n",
      "V13  0\n",
      "V14  0\n",
      "V15  0\n",
      "     0\n",
      "V1   0\n",
      "V2   0\n",
      "V3   1\n",
      "V4   1\n",
      "V5   0\n",
      "V6   0\n",
      "V7   1\n",
      "V8   0\n",
      "V9   0\n",
      "V10  0\n",
      "V11  1\n",
      "V12  0\n",
      "V13  0\n",
      "V14  0\n",
      "V15  0\n"
     ]
    }
   ],
   "source": [
    "blahdat = pd.concat([Y2,X2],axis=1)\n",
    "save = pd.DataFrame(np.zeros([5,X2.shape[1]]),columns=X2.columns.values)\n",
    "print ffsr(blahdat.iloc[:,1:],pd.DataFrame(blahdat.iloc[:,0]),0.05,bag=True)[0].index.values\n",
    "print ffsr(blahdat.iloc[:,1:],pd.DataFrame(blahdat.iloc[:,0]),0.05,bag=True)[0]\n",
    "save.loc[0,ffsr(blahdat.iloc[:,1:],pd.DataFrame(blahdat.iloc[:,0]),0.05,bag=True)[0].index.values] = np.around(ffsr(blahdat.iloc[:,1:],pd.DataFrame(blahdat.iloc[:,0]),0.05,bag=True)[0].iloc[:,0],8)\n",
    "print save\n",
    "crap = ffsr(blahdat.iloc[:,1:],pd.DataFrame(blahdat.iloc[:,0]),0.05,bag=True)[0]\n",
    "crap.index[np.abs(np.around(crap.iloc[:,0],8))>0]\n",
    "#np.abs(np.around(crap.iloc[:,0],8))>0\n",
    "crapnp = pd.DataFrame(np.zeros(X2.shape[1]),index=X2.columns.values)\n",
    "print crapnp\n",
    "crapnp.loc[crap.index[np.abs(np.around(crap.iloc[:,0],8))>0]] += 1\n",
    "print crapnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = bagfsr(X,Y,0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>betahat</th>\n",
       "      <th>betase</th>\n",
       "      <th>prop_incl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td> 5</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td> 6</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td> 5</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     betahat  betase  prop_incl\n",
       "V1         0       0          0\n",
       "V2         0       0          0\n",
       "V3         5       0          1\n",
       "V4         6       0          1\n",
       "V5         0       0          0\n",
       "V6         0       0          0\n",
       "V7         4       0          1\n",
       "V8         0       0          0\n",
       "V9         0       0          0\n",
       "V10        0       0          0\n",
       "V11        5       0          1\n",
       "V12        0       0          0\n",
       "V13        0       0          0\n",
       "V14        0       0          0\n",
       "V15        0       0          0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.038899999999999997, 6.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
