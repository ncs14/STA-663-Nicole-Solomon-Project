{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# From Draft 15 (w/modifications)\n",
    "# 4/29/15\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ffsr.py\n"
     ]
    }
   ],
   "source": [
    "%%file ffsr.py\n",
    "\n",
    "\"\"\" Pseudocode for Fast FSR algorithm \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Data type check \"\"\"\n",
    "def df_type(dat):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose: \n",
    "    #   Check if dataset is a pandas Dataframe or a numpy Ndarray.\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat = dataset whose type is to be checked / transformed\n",
    "    \n",
    "    ### Output:\n",
    "    #   error msg or True boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    if isinstance(dat,pd.DataFrame)==False and isinstance(dat,np.ndarray)==False:\n",
    "        raise ValueError(\"Data must be pandas DataFrame\")\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" p-value computation function \"\"\"\n",
    "def pval_comp(max_size=None,col_incl=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "    #   Compute the sequential p-values of the variables added to the model.\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object \n",
    "    ###       (requires running 'forward' fcn prior to this fcn)\n",
    "    \n",
    "    ### Input params:\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    #   array of p-values of each covariate at its given entry step\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.stats as st\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    # Pull RSS values & num_obs from fwd_proc object\n",
    "    rss = np.array(ro.r('fwd$rss'))\n",
    "    N = np.array(ro.r('fwd$nn'))\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(rss)-1\n",
    "    \n",
    "    # vector of model sizes\n",
    "    sizes = np.arange(max_size)+1\n",
    "    \n",
    "    # compute the F stats as defined above where p_f - p_r = 1 for each iteration\n",
    "    fstats = (rss[0:max_size] - rss[1:(max_size+1)]) / (rss[1:(max_size+1)] / (N - (sizes+1)))\n",
    "    \n",
    "    # compute p-values by comparing these stats to the F distn: F(1, n - p_f)\n",
    "    p = 1 - st.f.cdf(fstats, 1, N-(sizes+1))\n",
    "    \n",
    "    if col_incl==None:\n",
    "        return p\n",
    "    else:\n",
    "        p[:len(col_incl)] = 0.\n",
    "        return p\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Covariate model entry order \"\"\"\n",
    "def cov_order(xcolnames,max_size=None,col_incl=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose: \n",
    "    #   Determine order of covariate entry into final model.\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object \n",
    "    ###       (requires running 'forward' fcn prior to this fcn)\n",
    "    \n",
    "    ### Input params:\n",
    "    #   xcolnames = array of names of covariates (same order as columns in original dataset)\n",
    "    #   max_size  = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl  = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    #   array of covariate names sorted according to order of entry into the model\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(xcolnames)\n",
    "        \n",
    "    ### Pull the cov entry order\n",
    "    vorder = ro.r('fwd$vorder[-1]') # remove intercept\n",
    "    vorder = vorder[0:max_size] # keep only the max model size number of covs\n",
    "    \n",
    "    ### Shift these values down by two (one to exclude intercept, one to make python indices)\n",
    "    vorderinds = np.array(vorder)-2\n",
    "    \n",
    "    ### Rearrange the var order st forced vars are at start of list\n",
    "    if col_incl==None:\n",
    "        col_incl = np.arange(max_size)+1\n",
    "    keep = xcolnames[[col_incl-1]] # pull var names of those vars forced into model (this is an array)\n",
    "    poss = [x for x in xcolnames if x not in keep] # pull var names of those not forced in (this is a list)\n",
    "    col_names = np.array(list(keep)+poss) # = rearranged array of varnames w/forced-in vars at start of list\n",
    "    \n",
    "    ### Sort the columns of X in order to obtain the var names in the entry order\n",
    "    return col_names[vorderinds[::]]\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\" Forward selection function \"\"\"\n",
    "def forward(x,y,max_size=None,col_incl=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "    #   Perform the forward selection procedure via the R function leaps::regsubsets.\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x        = python dataframe of original p covariates, n x p\n",
    "    #   y        = python outcome dataframe, n x 1\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    #   regsubsets R object -- the raw full output of the forward selection proc\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Load python packages to call R functions\n",
    "    import rpy2.robjects as ro\n",
    "    import pandas.rpy.common as com\n",
    "    \n",
    "    ### Convert x and y to R matrices <-- MAKE SURE x,y input == DATAFRAMES (or else change them to df's)!!!\n",
    "    ### and declare as R objects in global environment\n",
    "    ro.globalenv['x2'] = com.convert_to_r_matrix(x)\n",
    "    ro.globalenv['y2'] = com.convert_to_r_matrix(y)\n",
    "    if max_size==None:\n",
    "        max_size = x.shape[1]\n",
    "    ro.globalenv['maxv'] = ro.Vector(max_size)\n",
    "    if col_incl==None:\n",
    "        ro.r('coli=NULL')\n",
    "    else:\n",
    "        ro.globalenv['coli'] = ro.FloatVector(col_incl[:])\n",
    "    \n",
    "    ### Perform forward selection with regsubsets function\n",
    "    ro.globalenv['fwd'] = ro.r('leaps::regsubsets(x=x2,y=y2,method=\"forward\",nvmax=maxv,force.in=coli)')\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Gamma computation \"\"\"\n",
    "def gamma_F(pvs, ncov, sizes):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "    # Compute the gamma (FSR) values at each step in the model build procedure\n",
    "     \n",
    "    ### Input params:\n",
    "    #   pvs   = vector of p-values (monotonically increasing) from forward sel procedure\n",
    "    #   ncov  = integer total number of covariates in data\n",
    "    #   sizes = vector of model sizes\n",
    "    \n",
    "    ### Output:\n",
    "    # array of gamma_F values\n",
    "    \"\"\"    \n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if ncov<len(pvs):\n",
    "        raise ValueError(\"ncov < len(pvals) --> gamma < 0\")\n",
    "        \n",
    "    if max(sizes)>len(pvs):\n",
    "        raise ValueError(\"Largest model size > len(pvals) --> gamma < 0\")\n",
    "\n",
    "    # gamma_F_i = p_s_i * (ncov - S_i) / (1 + S_i)\n",
    "    g_F = pvs * (ncov - sizes) / (1 + sizes)\n",
    "    \n",
    "    # Check for duplicate p-values\n",
    "    dups = list(set([x for x in list(pvs) if list(pvs).count(x) > 1]))\n",
    "    for i in range(len(dups)): g_F[pvs==dups[i]] = min(g_F[pvs==dups[i]])\n",
    "    \n",
    "    # if table run on all vars, the last gamma = 0,\n",
    "    #  instead set equal to the last pv_mono == final rate of unimp var inclusion\n",
    "    if(g_F[-1]==0): \n",
    "        g_F[-1]=pvs[-1]\n",
    "    \n",
    "    return g_F\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for model selection \"\"\"\n",
    "def alpha_F(g0, ncov, sizes):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "     Compute alpha-to-enter value corresponding to each step in model build procedure\n",
    "     \n",
    "    ### Input params:\n",
    "    #   g0    = float pre-specified FSR (gamma0)\n",
    "    #   ncov  = integer total number of covariates in data\n",
    "    #   sizes = vector of model sizes\n",
    "    \n",
    "    ### Output:\n",
    "    # array of alpha_F values\n",
    "    \"\"\"    \n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if max(sizes)>ncov:\n",
    "        raise ValueError(\"Largest model size > ncov --> alpha < 0\")\n",
    "        \n",
    "    ### Check that gamma0 is valid value\n",
    "    if g0 <= 0 or g0 >= 1:\n",
    "        raise ValueError(\"Specified gamma0 (FSR) must be in (0,1)\")\n",
    "    \n",
    "    # alpha_F_i = gamma_0 * (1 + S_i) / (ncov - S_i)\n",
    "    alpha_F = g0 * (1 + sizes) / (ncov - sizes)\n",
    "    \n",
    "    # if table run on all vars, the last alpha = inf\n",
    "    #  instead set equal to 1 == include all vars\n",
    "    alpha_F[np.isinf(alpha_F)] = 1.\n",
    "    \n",
    "    return alpha_F        \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for specific gamma \"\"\"\n",
    "def alpha_F_g(g, gf, ncov):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "    # Compute alpha-to-enter for a pre-specified gamma (FSR)\n",
    "     \n",
    "    ### Input params:\n",
    "    #   g    = float or vector (length k) of specified FSR at which to compute alpha\n",
    "    #   gf   = vector gamma_F's computed from gamma0, pv_sorted\n",
    "            used to compute largest size model (S) for which gamma_F < g\n",
    "    #   ncov = integer of total number covariates in data\n",
    "    \n",
    "    ### Output:\n",
    "    # integer alpha_F value\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    ### Check that gamma0 is valid value\n",
    "    if np.any(g <= 0) or np.any(g >= 1):\n",
    "        raise ValueError(\"Specified gamma (FSR) must be in (0,1)\")\n",
    "    \n",
    "    ### Compute model size for gf closest to (but still <) g\n",
    "    #S = np.array([max(np.which(x<=y)) for x in gf y in g])+1\n",
    "    if isinstance(g,np.ndarray): # if g is a vector\n",
    "        s_s = [np.where(gf>y) for y in g]\n",
    "        S = np.array([min(x[0]) for x in s_s])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "    else: # if g is a number\n",
    "        S = min(np.where(gf>g)[0])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" Beta-hat computation for specific gamma \"\"\"\n",
    "def beta_est(x, y, g, gf, vname):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "    # Compute parameter estimates for final model given a pre-specified gamma (FSR)\n",
    "     \n",
    "    ### Input params:\n",
    "    #   x      = python dataframe of original p covariates, n x p\n",
    "    #   y      = python outcome dataframe, n x 1\n",
    "    #   g      = float of specified FSR at which to compute alpha\n",
    "    #   gf     = vector gamma_F's computed from gamma0, pv_mono\n",
    "                 used to compute largest size model (S) for which gamma_F < g\n",
    "    #   vname  = ordered vector of names of vars entered into model under forward selection\n",
    "    \n",
    "    ### Output:\n",
    "    # array of estimated parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    ### Check that gamma0 is valid value\n",
    "    if g <= 0 or g >= 1:\n",
    "        raise ValueError(\"Specified gamma (FSR) must be in (0,1)\")\n",
    "    \n",
    "    ### Compute model size corresponding to g\n",
    "    S = min(np.where(gf>g)[0])\n",
    "\n",
    "    ### Pull the cov names of those vars included in the above size model\n",
    "    modvars = vname[:S]\n",
    "\n",
    "    ### Fit the linear model using the selected model vars\n",
    "    fit = sm.OLS(y,x.loc[:,list(modvars)]).fit()\n",
    "    betaout = pd.DataFrame([fit.params,fit.bse]).T\n",
    "    betaout.columns = ['beta','beta_se']\n",
    "    \n",
    "    return betaout\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" FSR Results Table \"\"\"\n",
    "def fsrtable(size, vname, p_orig, p_mono, alphaf, gammaf, prec_f='.4f'):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "    # Build the results table for the ffsr function\n",
    "     \n",
    "    ### Input params:\n",
    "    #   size   = model size at each step of forward sel proc                   [S]\n",
    "    #   vname  = variable name that entered at each step (num vars = p)        [Var]\n",
    "    #   p_orig = p-values at each step                                         [p]\n",
    "    #   p_mono = ascending p-values                                            [p_s]\n",
    "    #   alphaf = alpha-to-enter (p-value cutoff) for model entry at each step  [alpha_F]\n",
    "    #   gammaf = FSR at each step                                              [gamma_F]\n",
    "    #   prec_f = string of precision (num digits) desired in FSR output table\n",
    "    \n",
    "    ### Output:\n",
    "    # table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "\"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Round all arrays\n",
    "    p_od = [format(x,prec_f) for x in p_orig]\n",
    "    p_md = [format(x,prec_f) for x in p_mono]\n",
    "    ad = [format(x,prec_f) for x in alphaf]\n",
    "    gd = [format(x,prec_f) for x in gammaf]\n",
    "    \n",
    "    ### Combine the arrays\n",
    "    tab = pd.DataFrame([size,vname,p_od,p_md,ad,gd]).T\n",
    "    tab.columns = ['S','Var','p','p_m','alpha_F','gamma_F']\n",
    "    \n",
    "    return tab\n",
    "\n",
    "\n",
    "\n",
    "class ffsr_obj1(object): # bag=F, gs=T, beta=T\n",
    "    def __init__(self, fsr_results, betahats, afg):\n",
    "                    self.fsres = fsr_results\n",
    "                    self.beta = betahats\n",
    "                    self.alpha = afg\n",
    "                    \n",
    "class ffsr_obj2(object): # bag=F, gs=T, beta=F\n",
    "    def __init__(self, fsr_results, afg):\n",
    "                    self.fsres = fsr_results\n",
    "                    self.alpha = afg\n",
    "\n",
    "class ffsr_obj3(object): # bag=F, gs=F, beta=T\n",
    "    def __init__(self, fsr_results, betahats):\n",
    "                    self.fsres = fsr_results\n",
    "                    self.beta = betahats\n",
    "                \n",
    "class ffsr_obj4(object): # bag=F, gs=F, beta=F\n",
    "    def __init__(self, fsr_results):\n",
    "                    self.fsres = fsr_results\n",
    "            \n",
    "class bagfsr_obj(object): # bag=T\n",
    "    def __init__(self, betahats, afg, s):\n",
    "            self.beta = betahats\n",
    "            self.alpha = afg\n",
    "            self.size = s\n",
    "                \n",
    "    \n",
    "    \n",
    "\"\"\" FastFSR function \"\"\"\n",
    "def ffsr(dat,g0=0.05,betaout=False,gs=None,max_size=None,var_incl=None,prec_f='.4f'):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "     Perform the Fast False Selection Rate procedure with linear regression.\n",
    "     If want to incorporate bagging with FFSR, use 'bagfsr()'\n",
    "     \n",
    "    ### Input params:\n",
    "    #   dat      = python dataframe of original p covariates, 1 outcome (in first col.): n x p+1\n",
    "    #   g0       = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   betaout  = boolean of whether to include estimated betahats from final selected model\n",
    "    #   gs       = float or vector of gamma's at which to specifically compute alpha_F\n",
    "    #   max_size = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   var_incl = array of cols corresponding to those vars to force into model\n",
    "    #   prec_f   = string of precision (num digits) desired in FSR output table (string to be given to 'format' python fcn)\n",
    "    \n",
    "    ### Output: \n",
    "    #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
    "    # Table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    #   S:       model size at given step\n",
    "    #   Var:     name of var that entered at given step\n",
    "    #   p:       p-value of var that entered at given step\n",
    "    #   p_m:     mono. inc. p-value (vector or original p-values arranged to be monotonically increasing)\n",
    "    #   alpha_F: cutoff value for model entry given gamma_0 and current p_s value\n",
    "    #   gamma_F: FSR given current alpha_F and model size (== step num)\n",
    "    #       and\n",
    "    #   vector of alpha_F's for specified gamma's (g)\n",
    "    #       and\n",
    "    #   vector of estimated beta param's for final model (based on g0)\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Check that gamma0 is valid value\n",
    "    if g0 <= 0 or g0 >= 1:\n",
    "        raise ValueError(\"Specified gamma0 (FSR) must be in (0,1)\")\n",
    "    \n",
    "    ### Clean and check data - make sure dat = pandas dataframes or else convert them\n",
    "    if df_type(dat)==True:\n",
    "        if isinstance(dat,pd.DataFrame):\n",
    "            d = dat.copy()\n",
    "        else:\n",
    "            if isinstance(dat,np.ndarray):\n",
    "                d = pd.DataFrame(dat)\n",
    "                vnum = list(np.arange(d.shape[1])+1)\n",
    "                vchr = list(np.repeat(\"V\",d.shape[1]))\n",
    "                d.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "    else:\n",
    "        return df_type(dat)\n",
    "\n",
    "    ### Remove missing values\n",
    "    d.dropna(inplace=True)\n",
    "\n",
    "    ### Check that p < n to ensure regression solutions\n",
    "    if (d.shape[1]-1) >= d.shape[0]:\n",
    "        raise ValueError(\"N must be > p for valid regression solutions\")\n",
    "    \n",
    "    ### If max model size not specified, select all possible cov.s\n",
    "    if max_size==None:\n",
    "        max_size = d.shape[1]-1\n",
    "        \n",
    "    ### Perform forward selection\n",
    "    fwd_sel = forward(d.iloc[:,1:], pd.DataFrame(d.iloc[:,0]), max_size, var_incl)\n",
    "    \n",
    "    ### Save order of covariate entry into model\n",
    "    cov_entry_order = cov_order(d.columns.values[1:], max_size, var_incl)\n",
    "    \n",
    "    ### Compute p-value of each covariate entering the model\n",
    "    p_orig = pval_comp(max_size, var_incl)\n",
    "    \n",
    "    ### Arrange p-values in mono. inc. order\n",
    "    p_mono = np.array([max(p_orig[:(i+1)]) for i in range(len(p_orig))])\n",
    "    \n",
    "    ### Model size\n",
    "    S = np.array([len(np.where(p_mono<=p_mono[i])[0]) for i in range(len(p_mono))])\n",
    "    \n",
    "    ### Gamma_F computation\n",
    "    g_F = gamma_F(p_mono, d.shape[1]-1, S)\n",
    "    \n",
    "    ### Check if betaout desired, if so compute beta_hat of model corresponding to specific gamma0\n",
    "    if betaout==True:\n",
    "        betahats = beta_est(d.iloc[:,1:], pd.DataFrame(d.iloc[:,0]), g0, g_F, cov_entry_order)\n",
    "        \n",
    "    ### Alpha_F computation for all steps in fwd sel proc\n",
    "    a_F = alpha_F(g0, d.shape[1]-1, S)\n",
    "\n",
    "    ### Combine S, Cov_names, p-vals, sorted p-vals, alpha_F, gamma_F into table\n",
    "    fsr_results = fsrtable(S, cov_entry_order, p_orig, p_mono, a_F, g_F)\n",
    "\n",
    "    ### Return selected output: FSR table (+ betahat) (+ alpha_specific)\n",
    "    if gs!=None: \n",
    "        ### Compute alpha_F for specific gammas (gs)\n",
    "        if betaout==True:\n",
    "            afg = alpha_F_g(gs, g_F, d.shape[1]-1)\n",
    "            return ffsr_obj1(fsr_results, betahats, afg)\n",
    "        else:\n",
    "            afg = alpha_F_g(gs, g_F, d.shape[1]-1)\n",
    "            return ffsr_obj2(fsr_results, afg)\n",
    "    else:\n",
    "        if betaout==True:\n",
    "            return ffsr_obj3(fsr_results, betahats)\n",
    "        else:\n",
    "            return ffsr_obj4(fsr_results)      \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" FastFSR for bagging function \"\"\"\n",
    "def ffsr_bag(dat,g0=0.05,max_size=None,var_incl=None,prec_f='.4f'):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "    #   Perform Fast False Selection Rate procedure in efficient manner conducive for bagging.\n",
    "     \n",
    "    ### NOTE: It is assumed that data has been transformed, cleaned, and is given in correct format.\n",
    "    \n",
    "    ### NOTE: Appropriate covariate transformations are expected to have been applied prior \n",
    "    ###       to utilization of this FSR algorithm.\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat      = python dataframe of original p covariates, 1 outcome (in first col.): n x p+1\n",
    "    #   g0       = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   betaout  = boolean of whether to include estimated betahats from final selected model\n",
    "    #   gs       = float or vector of gamma's at which to specifically compute alpha_F\n",
    "    #   max_size = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   var_incl = array of cols corresponding to those vars to force into model\n",
    "    #   bag      = boolean of whether to output FSR table (non-bagging results) or reduced output for bagging purposes\n",
    "    #   prec_f   = string of precision (num digits) desired in FSR output table (string appropriate for 'format' python fcn)\n",
    "    \n",
    "    ### Output: \n",
    "    #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
    "    #   vector of estimated beta param's for final model (based on g0)\n",
    "    #   vector of alpha_F's for specified gamma's (g)\n",
    "    #   size of final model\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### If max model size not specified, select all possible cov.s\n",
    "    if max_size==None:\n",
    "        max_size = dat.shape[1]-1\n",
    "        \n",
    "    ### Perform forward selection\n",
    "    fwd_sel = forward(dat.iloc[:,1:], pd.DataFrame(dat.iloc[:,0]), max_size, var_incl)\n",
    "    \n",
    "    ### Save order of covariate entry into model\n",
    "    cov_entry_order = cov_order(dat.columns.values[1:], max_size, var_incl)\n",
    "    \n",
    "    ### Compute p-value of each covariate entering the model\n",
    "    p_orig = pval_comp(max_size, var_incl)\n",
    "    \n",
    "    ### Arrange p-values in mono. inc. order\n",
    "    p_mono = np.array([max(p_orig[:(i+1)]) for i in range(len(p_orig))])\n",
    "    \n",
    "    ### Model size\n",
    "    S = np.array([len(np.where(p_mono<=p_mono[i])[0]) for i in range(len(p_mono))])\n",
    "        \n",
    "    ### Gamma_F computation\n",
    "    g_F = gamma_F(p_mono, dat.shape[1]-1, S)\n",
    "    \n",
    "    ### Compute beta_hat of model corresponding to specific gamma0\n",
    "    betahats = beta_est(dat.iloc[:,1:], pd.DataFrame(dat.iloc[:,0]), g0, g_F, cov_entry_order)\n",
    "        \n",
    "    return betahats, alpha_F_g(g0, g_F, dat.shape[1]-1), len(betahats)\n",
    "\n",
    "    \n",
    "    \n",
    "def bagfsr(dat,g0,B=200,max_s=None,v_incl=None,prec=4):\n",
    "    \n",
    "    \"\"\"\n",
    "    ### Purpose:\n",
    "    #   Perform bagging with Fast False Selection Rate procedure to allow for more accurate predictions.\n",
    "    \n",
    "    ### NOTE: appropriate covariate transformations are expected to have been applied prior \n",
    "    ###       to utilization of this FSR algorithm.\n",
    "     \n",
    "    ### Input params:\n",
    "    #   dat    = python dataframe of original p covariates, 1 outcome (in first col.): n x p+1\n",
    "    #   g0     = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   B      = integer of number of bagged samples\n",
    "    #   max_s  = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   v_incl = array of cols corresponding to those vars to force into model\n",
    "    #   prec   = integer of precision (num digits) desired in beta-hat parameter estimates of final model\n",
    "    \n",
    "    ### Output: \n",
    "    #   Mean of betahats\n",
    "    #   SEs of betahats\n",
    "    #   Avg alpha-to-enter\n",
    "    #   Avg model size\n",
    "    #   Prop of times each var included in model\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.utils import resample\n",
    "    \n",
    "    ### Check that gamma0 is valid value\n",
    "    if g0 <= 0 or g0 >= 1:\n",
    "        raise ValueError(\"Specified gamma0 (FSR) must be in (0,1)\")\n",
    "    \n",
    "    ### Check that B is valid value\n",
    "    if B <= 0:\n",
    "        raise ValueError(\"B must be > 0\")\n",
    "        \n",
    "    ### Clean and check data - make sure X, Y = pandas dataframes or else convert them\n",
    "    if df_type(dat)==True:\n",
    "        if isinstance(dat,pd.DataFrame):\n",
    "            d = dat.copy()\n",
    "        else:\n",
    "            if isinstance(dat,np.ndarray):\n",
    "                d = pd.DataFrame(dat)\n",
    "                vnum = list(np.arange(d.shape[1])+1)\n",
    "                vchr = list(np.repeat(\"V\",d.shape[1]))\n",
    "                d.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "    else:\n",
    "        return df_type(dat)\n",
    "    \n",
    "    ### Remove missing values\n",
    "    d.dropna(inplace=True)\n",
    "    \n",
    "    ### check that p < n to ensure regression solutions\n",
    "    if (d.shape[1]-1) >= d.shape[0]:\n",
    "        raise ValueError(\"N must be > p for valid regression solutions\")\n",
    "    \n",
    "    ### Create array to keep track of number of times vars enter model\n",
    "    nentries = pd.DataFrame(np.zeros(d.shape[1]-1),index=d.columns.values[1:])\n",
    "    \n",
    "    ### Create array to store all estimated coefficients, ses, alphas, sizes\n",
    "    allbetas = pd.DataFrame(np.zeros([B,(d.shape[1]-1)]),columns=d.columns.values[1:])\n",
    "    allses = allbetas.copy()\n",
    "    alphas = []\n",
    "    sizes = []\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    ### Bagging loops\n",
    "    for i in range(B):\n",
    "        # Draw with replacement from rows of data\n",
    "        newdat = pd.DataFrame(resample(d, replace=True))\n",
    "        newdat.columns = d.columns.values\n",
    "        \n",
    "        ### Obtain FSR results\n",
    "        fsrout = ffsr_bag(newdat,g0,max_size=max_s,var_incl=v_incl)\n",
    "        allbetas.loc[i,fsrout[0].index.values] = fsrout[0].iloc[:,0]\n",
    "        allses.loc[i,fsrout[0].index.values] = fsrout[0].iloc[:,1]\n",
    "        alphas.append(fsrout[1])\n",
    "        sizes.append(fsrout[2])\n",
    "\n",
    "        ### Update counts of num times var included\n",
    "        nentries.loc[fsrout[0].index[np.abs(np.around(fsrout[0].iloc[:,0],prec))>0]] += 1\n",
    "        \n",
    "    ### Compute averages\n",
    "    avgbeta = allbetas.mean(axis=0) # mean across rows / colmeans == mean of each cov's betahat\n",
    "    avgse = allses.mean(axis=0)\n",
    "    avgalpha = np.mean(alphas)\n",
    "    avgsize = np.mean(sizes)\n",
    "    var_props = nentries/float(B)\n",
    "    cov_res = pd.concat([avgbeta,avgse,var_props],axis=1)\n",
    "    cov_res.columns = ['betahat','betase','prop_incl']\n",
    "    \n",
    "    return bagfsr_obj(cov_res, avgalpha, avgsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
