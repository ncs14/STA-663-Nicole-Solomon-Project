{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                                    \"\"\" Pseudocode for Fast FSR algorithm \"\"\"\n",
    "\n",
    "\"\"\" Date: 3/25/15 \n",
    "    First running, basic version of FFSR functions \"\"\"\n",
    "\n",
    "    \n",
    "\"\"\" p-value computation function \"\"\"\n",
    "def pval_comp(fwd_proc,ncov):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   fwd_proc = leaps::regsubsets object generated in Python <-- must be declared in global R env\n",
    "    #   ncov     = number of covariates\n",
    "    \n",
    "    ### Output:\n",
    "    # array of p-values of each covariate at its given entry step\n",
    "    \n",
    "    # make fwd an R object in the global environment\n",
    "    ro.globalenv['out_r'] = fwd_proc\n",
    "    \n",
    "    # Use F-test to compute p-value : \n",
    "    #  F_stat = [ (RSS_r - RSS_f) / (p_f - p_r) ] / [ RSS_f / (n - p_f) ] ~ F(p_f - p_r, n - p_f)\n",
    "    #  pval = Fdistn_invcdf(F_stat)\n",
    "    \n",
    "    # create vector from 1 to number of covariates\n",
    "    ro.globalenv['ncov'] = ncov\n",
    "    ro.globalenv['ncovs'] = ro.r('1:ncov')\n",
    "    \n",
    "    # compute the F stats as defined above where p_f - p_r = 1 for each iteration\n",
    "    ro.globalenv['fstats'] = ro.r('(out_r$rss[ncovs]-out_r$rss[ncovs+1]) / (out_r$rss[ncovs+1] / (out_r$nn-(ncovs+1))')\n",
    "    \n",
    "    # return the p-values by comparing these stats to the F distn: F(1, n - p_f)\n",
    "    return np.array(ro.r('pf(fstats,1,out_r$nn-(ncovs+1),lower.tail=F)'))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Covariate model entry order \"\"\"\n",
    "def cov_order(fwd_proc,xcolnames):\n",
    "    \n",
    "    # Input params:\n",
    "    #   fwd_proc  = leaps::regsubsets object generated in Python <-- must be declared in global R env\n",
    "    #   xcolnames = names of covariates\n",
    "    \n",
    "    ### Output:\n",
    "    # covariate names sorted according to order of entry into the model\n",
    "    \n",
    "    ### Declare fwd as an object in the global R environment\n",
    "    ro.globalenv['out_cov'] = fwd_proc\n",
    "    \n",
    "    ### Pull the cov entry order\n",
    "    vorder = ro.r('out_cov$vorder')\n",
    "    \n",
    "    ### Shift these values down by two (one to exclude intercept, one to make python indices)\n",
    "    vorderinds = np.array(vorder)-2\n",
    "    \n",
    "    ### Sort the columns of X in order to obtain the var names in the entry order\n",
    "    return xcolnames[vorderinds[::]]\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\" Forward selection function \"\"\"\n",
    "def forward(x,y):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x  = python dataframe of original p covariates, n x p\n",
    "    #   y  = python outcome dataframe, n x 1\n",
    "    \n",
    "    ### Output:\n",
    "    # a regsubsets R object -- the raw full output of the forward selection proc\n",
    "    \n",
    "    ### Load python packages to call R functions\n",
    "    import rpy2.robjects as ro\n",
    "    import pandas.rpy.common as com\n",
    "    from rpy2.robjects.packages import importr\n",
    "    \n",
    "    ### Load base R package & regsubsets fcn from leaps R library\n",
    "    regsub = ro.r('leaps::regsubsets')\n",
    "    base = importr('base')\n",
    "    \n",
    "    ### Convert x and y to R matrices <-- MAKE SURE x,y input == DATAFRAMES (or else change them to df's)!!!\n",
    "    X = com.convert_to_r_matrix(x)\n",
    "    Y = com.convert_to_r_matrix(y)\n",
    "    \n",
    "    ### Perform forward selection with regsubsets function\n",
    "    # Note #2: make nvmax an input argument\n",
    "    return regsub(x=X,y=Y,method=\"forward\",nvmax=base.ncol(X))\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" FSR Results Table \"\"\"\n",
    "def fsrtable(size, vname, p_orig, p_sort, alphaf, gammaf):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   size   = model size at each step of forward sel proc                   [S]\n",
    "    #   vname  = variable name that entered at each step (num vars = p)        [Var]\n",
    "    #   p_orig = p-values at each step                                         [p]\n",
    "    #   p_sort = ascending p-values                                            [p_s]\n",
    "    #   alphaf = alpha-to-enter (p-value cutoff) for model entry at each step  [alpha_F]\n",
    "    #   gammaf = FSR at each step                                              [gamma_F]\n",
    "    \n",
    "    ### Output:\n",
    "    # table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    \n",
    "    ### Convert all arrays to dataframes\n",
    "    sized = pd.DataFrame(size)\n",
    "    vnamed = pd.DataFrame(vname)\n",
    "    p_od = pd.DataFrame(p_orig)\n",
    "    p_sd = pd.DataFrame(p_sort)\n",
    "    ad = pd.DataFrame(alphaf)\n",
    "    gd = pd.DataFrame(gammaf)\n",
    "    \n",
    "    ### Combine the arrays\n",
    "    tab = pd.concat([sized,vnamed,p_od,p_sd,ad,gd],axis=1)\n",
    "    tab.columns = ['S','Var','p','p_s','alpha_F','gamma_F']\n",
    "    \n",
    "    return tab\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" FastFSR function \"\"\"\n",
    "def ffsr(x,y,g0):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x  = python dataframe of original p covariates, n x p\n",
    "    #   y  = python outcome dataframe, n x 1\n",
    "    #   g0 = pre-specified FSR of interest\n",
    "    \n",
    "    ### Output: \n",
    "    #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
    "    # Table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    #   S:       model size at given step\n",
    "    #   Var:     name of var that entered at given step\n",
    "    #   p:       p-value of var that entered at given step\n",
    "    #   p_s:     sorted p-value (vector or original p-values sorted in increasing order)\n",
    "    #   alpha_F: cutoff value for model entry given gamma_0 and current p_s value\n",
    "    #   gamma_F: FSR given current alpha_F and model size (== step num)\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data\n",
    "    # make sure x,y = pandas dataframes or else convert them\n",
    "    # remove missing values\n",
    "    # check that p < n to ensure regression solutions\n",
    "    \n",
    "    ### Perform forward selection\n",
    "    fwd_sel = forward(x,y)\n",
    "    \n",
    "    ### Save order of covariate entry into model\n",
    "    cov_entry_order = cov_order(fwd_sel,x.columns.values)\n",
    "    \n",
    "    ### Compute p-value of each covariate entering the model\n",
    "    p_orig = pval_comp(fwd_sel,x.shape[1])\n",
    "    \n",
    "    ### Sort p-values in ascending order\n",
    "    p_sort = np.sort(p_orig)\n",
    "    \n",
    "    ### Alpha_F computation\n",
    "    a_F = alpha_F(gamma0, p_orig, x.shape[1])\n",
    "    \n",
    "    ### Gamma_F computation\n",
    "    g_F = gamma_F(a_F, p_sort, x.shape[1])\n",
    "    \n",
    "    ### Model size\n",
    "    S = np.arange(x.shape[1])+1\n",
    "    \n",
    "    ### Combine S, Cov_names, p-vals, sorted p-vals, alpha_F, gamma_F into table\n",
    "    fsr_results = fsrtable(S, cov_entry_order, p_orig, p_sort, a_F, g_F)\n",
    "    \n",
    "    return fsr_results\n",
    "\n",
    "# Notes: \n",
    "# 1. will need to adjust above functions to handle fwd_sel steps with tied p-values for >1 cov\n",
    "# 2. need to adjust function to control how many vars shown in final output\n",
    "# 3. appropriate transformations are expected to have been applied prior to utilization of FSR algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython # code to load/connect to R software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rpy2.robjects as ro\n",
    "import pandas.rpy.common as com\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# load R package\n",
    "leaps = importr('leaps')\n",
    "stats = importr('stats')\n",
    "base = importr('base')\n",
    "\n",
    "regsub = ro.r('leaps::regsubsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "X = np.random.multivariate_normal(np.zeros(15),np.eye(15),(100))\n",
    "beta = np.array([0,0,5,6,0,0,4,0,0,0,5,0,0,0,0]).reshape(15,1)\n",
    "Y = X.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y2 = pd.DataFrame(Y)\n",
    "X2 = pd.DataFrame(X)\n",
    "X2.columns = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2 = com.convert_to_r_matrix(Y2)\n",
    "x2 = com.convert_to_r_matrix(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = regsub(x=x2,y=y2,method=\"forward\",nvmax=base.ncol(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1]  1  5  8  4 12  3 11  2  6 16 13 15  9 10  7 14\n",
      "\n",
      " [1]  5  8  4 12  3 11  2  6 16 13 15  9 10  7 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ro.globalenv['out2'] = out\n",
    "print(ro.r('out2$vorder'))\n",
    "print(ro.r('out2$vorder[-1]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 3, 11, 2, 10, 1, 5, 15, 12, 14, 8, 9, 6, 13]\n",
      "['V4' 'V7' 'V3' 'V11' 'V2' 'V10' 'V1' 'V5' 'V15' 'V12' 'V14' 'V8' 'V9' 'V6'\n",
      " 'V13']\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "varorder = ro.r('out2$vorder[-1]')\n",
    "vorder2 = np.array(varorder)-2\n",
    "print list(vorder2+1)\n",
    "col_nam = X2.columns.values\n",
    "vnames = col_nam[vorder2[::]]\n",
    "print vnames\n",
    "print type(vnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 1.381848e-01 2.106624e-01 8.193067e-01 1.352818e+00 1.637391e+00\n",
      " [6] 2.386851e+00 2.807482e+00 3.134854e+00 6.637493e+00 7.394751e+00\n",
      "[11] 1.440562e+01 5.950425e+01 7.074218e+01 1.371970e+02 9.273244e+31\n",
      "\n",
      "\n",
      "[ 0.     0.     0.     0.     0.     0.008  0.012  0.08   0.097  0.126\n",
      "  0.204  0.248  0.368  0.647  0.711]\n"
     ]
    }
   ],
   "source": [
    "ro.globalenv['ncov'] = base.ncol(x2)\n",
    "ro.globalenv['ncovs'] = ro.r('1:ncov')\n",
    "ro.globalenv['fstats'] = ro.r('(out2$rss[ncovs]-out2$rss[ncovs+1])*(out2$nn-(ncovs+1)) / out2$rss[ncovs+1]')\n",
    "ps = np.array(ro.r('pf(fstats,1,out2$nn-(ncovs+1),lower.tail=F)'))\n",
    "print(ro.r('sort(fstats)'))\n",
    "print\n",
    "print np.around(np.sort(ps),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sizes = np.arange(X.shape[1])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Vname  Size             p\n",
      "0     V4     1  1.029111e-11\n",
      "1     V7     2  3.567563e-13\n",
      "2     V3     3  3.312340e-20\n",
      "3    V11     4  0.000000e+00\n",
      "4     V2     5  2.608114e-04\n",
      "5    V10     6  7.805512e-03\n",
      "6     V1     7  1.157750e-02\n",
      "7     V5     8  9.725851e-02\n",
      "8    V15     9  8.002123e-02\n",
      "9    V12    10  1.259084e-01\n",
      "10   V14    11  2.040472e-01\n",
      "11    V8    12  2.479664e-01\n",
      "12    V9    13  3.679118e-01\n",
      "13    V6    14  6.474203e-01\n",
      "14   V13    15  7.110283e-01\n"
     ]
    }
   ],
   "source": [
    "cnam = pd.DataFrame(vnames)\n",
    "sz = pd.DataFrame(sizes)\n",
    "psd = pd.DataFrame(ps)\n",
    "ttt = pd.concat([cnam,sz,psd],axis=1)\n",
    "ttt.columns = ['Vname','Size','p']\n",
    "print type(ttt)\n",
    "print ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
