{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                            \"\"\" Pseudocode for Fast FSR algorithm \"\"\"\n",
    "\n",
    "\"\"\" Date: 4/24/15 \n",
    "    Modified: Improve missing value adjustments (code to test this comes after this cell) \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" Data type check \"\"\"\n",
    "def df_type(dat):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat = dataset whose type is to be checked / transformed\n",
    "    \n",
    "    ### Output:\n",
    "    #   error msg or True boolean\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    if isinstance(dat,pd.DataFrame)==False and isinstance(dat,np.ndarray)==False:\n",
    "        raise Exception(\"Data must be pandas DataFrame\")\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" p-value computation function \"\"\"\n",
    "def pval_comp(max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of p-values of each covariate at its given entry step\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.stats as st\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    # Pull RSS values & num_obs from fwd_proc object\n",
    "    rss = np.array(ro.r('fwd$rss'))\n",
    "    N = np.array(ro.r('fwd$nn'))\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(rss)-1\n",
    "    \n",
    "    # vector of model sizes\n",
    "    sizes = np.arange(max_size)+1\n",
    "    \n",
    "    # compute the F stats as defined above where p_f - p_r = 1 for each iteration\n",
    "    fstats = (rss[0:max_size] - rss[1:(max_size+1)]) / (rss[1:(max_size+1)] / (N - (sizes+1)))\n",
    "    \n",
    "    # return the p-values by comparing these stats to the F distn: F(1, n - p_f)\n",
    "    return 1 - st.f.cdf(fstats, 1, N-(sizes+1))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Covariate model entry order \"\"\"\n",
    "def cov_order(xcolnames,max_size=None,col_incl=None):\n",
    "    \n",
    "    # Input params:\n",
    "    #   xcolnames = array of names of covariates (same order as columns in original dataset)\n",
    "    #   max_size  = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl  = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    # array of covariate names sorted according to order of entry into the model\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
    "    \n",
    "    import numpy as np\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(xcolnames)\n",
    "        \n",
    "    ### Pull the cov entry order\n",
    "    vorder = ro.r('fwd$vorder[-1]') # remove intercept\n",
    "    vorder = vorder[0:max_size] # keep only the max model size number of covs\n",
    "    \n",
    "    ### Shift these values down by two (one to exclude intercept, one to make python indices)\n",
    "    vorderinds = np.array(vorder)-2\n",
    "    \n",
    "    ### Rearrange the var order st forced vars are at start of list\n",
    "    if col_incl==None:\n",
    "        col_incl = np.arange(max_size)+1\n",
    "    keep = xcolnames[[col_incl-1]] # pull var names of those vars forced into model (this is an array)\n",
    "    poss = [x for x in xcolnames if x not in keep] # pull var names of those not forced in (this is a list)\n",
    "    col_names = np.array(list(keep)+poss) # = rearranged array of varnames w/forced-in vars at start of list\n",
    "    \n",
    "    ### Sort the columns of X in order to obtain the var names in the entry order\n",
    "    return col_names[vorderinds[::]]\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\" Forward selection function \"\"\"\n",
    "def forward(x,y,max_size=None,col_incl=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x        = python dataframe of original p covariates, n x p\n",
    "    #   y        = python outcome dataframe, n x 1\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    # regsubsets R object -- the raw full output of the forward selection proc\n",
    "    \n",
    "    ### Load python packages to call R functions\n",
    "    import rpy2.robjects as ro\n",
    "    import pandas.rpy.common as com\n",
    "    \n",
    "    ### Convert x and y to R matrices <-- MAKE SURE x,y input == DATAFRAMES (or else change them to df's)!!!\n",
    "    ### and declare as R objects in global environment\n",
    "    ro.globalenv['x2'] = com.convert_to_r_matrix(x)\n",
    "    ro.globalenv['y2'] = com.convert_to_r_matrix(y)\n",
    "    if max_size==None:\n",
    "        max_size = x.shape[1]\n",
    "    ro.globalenv['maxv'] = ro.Vector(max_size)\n",
    "    if col_incl==None:\n",
    "        ro.r('coli=NULL')\n",
    "    else:\n",
    "        ro.globalenv['coli'] = ro.FloatVector(col_incl[:])\n",
    "    \n",
    "    ### Perform forward selection with regsubsets function\n",
    "    ro.globalenv['fwd'] = ro.r('leaps::regsubsets(x=x2,y=y2,method=\"forward\",nvmax=maxv,force.in=coli)')\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Gamma computation \"\"\"\n",
    "def gamma_F(pvs, ncov, max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   pvs      = vector of p-values (monotonically increasing) from forward sel procedure\n",
    "    #   ncov     = integer total number of covariates in data\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of gamma_F values\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = ncov\n",
    "        \n",
    "    # Create indices == model size at given step, call this S\n",
    "    S = np.arange(max_size)+1\n",
    "    \n",
    "    # gamma_F_i = p_s_i * (ncov - S_i) / (1 + S_i)\n",
    "    g_F = pvs * (ncov - S) / (1 + S)\n",
    "    \n",
    "    # Check for duplicate p-values\n",
    "    dups = list(set([x for x in list(pvs) if list(pvs).count(x) > 1]))\n",
    "    for i in range(len(dups)): g_F[pvs==dups[i]] = min(g_F[pvs==dups[i]])\n",
    "    \n",
    "    # if table run on all vars, the last gamma = 0,\n",
    "    #  instead set equal to the last pv_mono == final rate of unimp var inclusion\n",
    "    if(g_F[-1]==0): \n",
    "        g_F[-1]=pvs[-1]\n",
    "    \n",
    "    return g_F\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for model selection \"\"\"\n",
    "def alpha_F(g0, ncov, max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   g0       = float pre-specified FSR (gamma0)\n",
    "    #   ncov     = integer total number of covariates in data\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of alpha_F values\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = ncov\n",
    "        \n",
    "    # Create indices == model size at given step, call this S\n",
    "    S = np.arange(max_size)+1\n",
    "    \n",
    "    # alpha_F_i = gamma_0 * (1 + S_i) / (ncov - S_i)\n",
    "    alpha_F = g0 * (1 + S) / (ncov - S)\n",
    "    \n",
    "    # if table run on all vars, the last alpha = inf\n",
    "    #  instead set equal to 1 == include all vars\n",
    "    alpha_F[np.isinf(alpha_F)] = 1.\n",
    "    \n",
    "    return alpha_F        \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for specific gamma \"\"\"\n",
    "def alpha_F_g(g, gf, ncov):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   g    = float or vector (length k) of specified FSR at which to compute alpha\n",
    "    #   gf   = vector gamma_F's computed from gamma0, pv_sorted\n",
    "    #          used to compute largest size model (S) for which gamma_F < g\n",
    "    #   ncov = integer of total number covariates in data\n",
    "    \n",
    "    ### Output:\n",
    "    # integer alpha_F value\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    ### Compute model size for gf closest to (but still <) g\n",
    "    #S = np.array([max(np.which(x<=y)) for x in gf y in g])+1\n",
    "    if isinstance(g,np.ndarray): # if g is a vector\n",
    "        s_s = [np.where(gf>y) for y in g]\n",
    "        S = np.array([min(x[0]) for x in s_s])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "    else: # if g is a number\n",
    "        S = min(np.where(gf>g)[0])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" Beta-hat computation for specific gamma \"\"\"\n",
    "def beta_est(x, y, g, gf, vname):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x      = python dataframe of original p covariates, n x p\n",
    "    #   y      = python outcome dataframe, n x 1\n",
    "    #   g      = float of specified FSR at which to compute alpha\n",
    "    #   gf     = vector gamma_F's computed from gamma0, pv_mono\n",
    "    #            used to compute largest size model (S) for which gamma_F < g\n",
    "    #   vname  = ordered vector of names of vars entered into model under forward selection\n",
    "    \n",
    "    ### Output:\n",
    "    # array of estimated parameters\n",
    "    \n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    ### Compute model size corresponding to g\n",
    "    S = min(np.where(gf>g)[0])\n",
    "\n",
    "    ### Pull the cov names of those vars included in the above size model\n",
    "    modvars = vname[:S]\n",
    "\n",
    "    ### Fit the linear model using the selected model vars\n",
    "    fit = sm.OLS(y,x.loc[:,list(modvars)]).fit()\n",
    "    betaout = pd.DataFrame([fit.params,fit.bse]).T\n",
    "    betaout.columns = ['beta','beta_se']\n",
    "    \n",
    "    return betaout\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" FSR Results Table \"\"\"\n",
    "def fsrtable(size, vname, p_orig, p_mono, alphaf, gammaf, prec_f='.4f'):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   size   = model size at each step of forward sel proc                   [S]\n",
    "    #   vname  = variable name that entered at each step (num vars = p)        [Var]\n",
    "    #   p_orig = p-values at each step                                         [p]\n",
    "    #   p_mono = ascending p-values                                            [p_s]\n",
    "    #   alphaf = alpha-to-enter (p-value cutoff) for model entry at each step  [alpha_F]\n",
    "    #   gammaf = FSR at each step                                              [gamma_F]\n",
    "    #   prec_f = string of precision (num digits) desired in FSR output table\n",
    "    \n",
    "    ### Output:\n",
    "    # table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Round all arrays\n",
    "    p_od = [format(x,prec_f) for x in p_orig]\n",
    "    p_md = [format(x,prec_f) for x in p_mono]\n",
    "    ad = [format(x,prec_f) for x in alphaf]\n",
    "    gd = [format(x,prec_f) for x in gammaf]\n",
    "    \n",
    "    ### Combine the arrays\n",
    "    tab = pd.DataFrame([size,vname,p_od,p_md,ad,gd]).T\n",
    "    tab.columns = ['S','Var','p','p_m','alpha_F','gamma_F']\n",
    "    \n",
    "    return tab\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" FastFSR function \"\"\"\n",
    "def ffsr(dat,g0=0.05,betaout=False,gs=None,max_size=None,var_incl=None,bag=False,prec_f='.4f'):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat      = python dataframe of original p covariates, 1 outcome (in first col.): n x p+1\n",
    "    #   g0       = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   betaout  = boolean of whether to include estimated betahats from final selected model\n",
    "    #   gs       = float or vector of gamma's at which to specifically compute alpha_F\n",
    "    #   max_size = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   var_incl = array of cols corresponding to those vars to force into model\n",
    "    #   bag      = boolean of whether to output FSR table (non-bagging results) or reduced output for bagging purposes\n",
    "    #   prec_f   = string of precision (num digits) desired in FSR output table (string to be given to 'format' python fcn)\n",
    "    \n",
    "    ### Output: \n",
    "    #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
    "    # Table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    #   S:       model size at given step\n",
    "    #   Var:     name of var that entered at given step\n",
    "    #   p:       p-value of var that entered at given step\n",
    "    #   p_m:     mono. inc. p-value (vector or original p-values arranged to be monotonically increasing)\n",
    "    #   alpha_F: cutoff value for model entry given gamma_0 and current p_s value\n",
    "    #   gamma_F: FSR given current alpha_F and model size (== step num)\n",
    "    #       and\n",
    "    #   vector of alpha_F's for specified gamma's (g)\n",
    "    #       and\n",
    "    #   vector of estimated beta param's for final model (based on g0)\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data - make sure dat = pandas dataframes or else convert them\n",
    "    if bag==False:\n",
    "        if df_type(dat)==True:\n",
    "            if isinstance(dat,pd.DataFrame):\n",
    "                d = dat.copy()\n",
    "            else:\n",
    "                if isinstance(dat,np.ndarray):\n",
    "                    d = pd.DataFrame(dat)\n",
    "                    vnum = list(np.arange(d.shape[1])+1)\n",
    "                    vchr = list(np.repeat(\"V\",d.shape[1]))\n",
    "                    d.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "        else:\n",
    "            return df_type(dat)\n",
    "        \n",
    "        ### Remove missing values\n",
    "        d.dropna(inplace=True)\n",
    "        \n",
    "        ### Check that p < n to ensure regression solutions\n",
    "        if (d.shape[1]-1) >= d.shape[0]:\n",
    "            raise Exception(\"N must be > p for valid regression solutions\")\n",
    "    else:\n",
    "        d = dat.copy()\n",
    "    \n",
    "    ### If max model size not specified, select all possible cov.s\n",
    "    if max_size==None:\n",
    "        max_size = d.shape[1]-1\n",
    "        \n",
    "    ### Perform forward selection\n",
    "    fwd_sel = forward(d.iloc[:,1:], pd.DataFrame(d.iloc[:,0]), max_size, var_incl)\n",
    "    \n",
    "    ### Save order of covariate entry into model\n",
    "    cov_entry_order = cov_order(d.columns.values[1:], max_size, var_incl)\n",
    "    \n",
    "    ### Compute p-value of each covariate entering the model\n",
    "    p_orig = pval_comp(max_size)\n",
    "    \n",
    "    ### Arrange p-values in mono. inc. order\n",
    "    p_mono = np.array([max(p_orig[:(i+1)]) for i in range(len(p_orig))])\n",
    "        \n",
    "    ### Gamma_F computation\n",
    "    g_F = gamma_F(p_mono, d.shape[1], max_size)\n",
    "    \n",
    "    ### Check if betaout desired, if so compute beta_hat of model corresponding to specific gamma0\n",
    "    if betaout==True or bag==True:\n",
    "        betahats = beta_est(d.iloc[:,1:], d.iloc[:,0], g0, g_F, cov_entry_order)\n",
    "        \n",
    "    ### Check if bagging desired\n",
    "    if bag==False: \n",
    "        ### Alpha_F computation for all steps in fwd sel proc\n",
    "        a_F = alpha_F(g0, d.shape[1]-1, max_size)\n",
    "        \n",
    "        ### Model size\n",
    "        S = np.arange(max_size)+1\n",
    "        \n",
    "        ### Combine S, Cov_names, p-vals, sorted p-vals, alpha_F, gamma_F into table\n",
    "        fsr_results = fsrtable(S, cov_entry_order, p_orig, p_mono, a_F, g_F)\n",
    "        \n",
    "        ### Return selected output: FSR table (+ betahat) (+ alpha_specific)\n",
    "        if gs!=None: \n",
    "            ### Compute alpha_F for specific gammas (gs)\n",
    "            if betaout==True:\n",
    "                return fsr_results, betahats, alpha_F_g(gs, g_F, d.shape[1]-1)\n",
    "            else:\n",
    "                return fsr_results, alpha_F_g(gs, g_F, d.shape[1]-1)\n",
    "        else:\n",
    "            if betaout==True:\n",
    "                return fsr_results, betahats\n",
    "            else:\n",
    "                return fsr_results\n",
    "    else:\n",
    "        return betahats, alpha_F_g(g0, g_F, d.shape[1]-1), len(betahats)\n",
    "\n",
    "    \n",
    "    \n",
    "def bagfsr(dat,g0,B=200,max_s=None,v_incl=None,prec=4):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat    = python dataframe of original p covariates, 1 outcome (in first col.): n x p+1\n",
    "    #   g0     = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   B      = integer of number of bagged samples\n",
    "    #   max_s  = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   v_incl = array of cols corresponding to those vars to force into model\n",
    "    #   prec   = integer of precision (num digits) desired in beta-hat parameter estimates of final model\n",
    "    \n",
    "    ### Output: \n",
    "    #   Mean of betahats\n",
    "    #   SEs of betahats\n",
    "    #   Avg alpha-to-enter\n",
    "    #   Avg model size\n",
    "    #   Prop of times each var included in model\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data - make sure X, Y = pandas dataframes or else convert them\n",
    "    if df_type(dat)==True:\n",
    "        if isinstance(dat,pd.DataFrame):\n",
    "            d = dat.copy()\n",
    "        else:\n",
    "            if isinstance(dat,np.ndarray):\n",
    "                d = pd.DataFrame(dat)\n",
    "                vnum = list(np.arange(d.shape[1])+1)\n",
    "                vchr = list(np.repeat(\"V\",d.shape[1]))\n",
    "                d.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "    else:\n",
    "        return df_type(dat)\n",
    "    \n",
    "    ### Remove missing values\n",
    "    d.dropna(inplace=True)\n",
    "    \n",
    "    ### check that p < n to ensure regression solutions\n",
    "    if (d.shape[1]-1) >= d.shape[0]:\n",
    "        raise Exception(\"N must be > p for valid regression solutions\")\n",
    "    \n",
    "    ### Create array to keep track of number of times vars enter model\n",
    "    nentries = pd.DataFrame(np.zeros(d.shape[1]-1),index=d.columns.values[1:])\n",
    "    \n",
    "    ### Create array to store all estimated coefficients, ses, alphas, sizes\n",
    "    allbetas = pd.DataFrame(np.zeros([B,(d.shape[1]-1)]),columns=d.columns.values[1:])\n",
    "    allses = allbetas.copy()\n",
    "    alphas = []\n",
    "    sizes = []\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    ### Bagging loops\n",
    "    for i in range(B):\n",
    "\n",
    "        # Draw with replacement from rows of data\n",
    "        n_row = d.shape[0]\n",
    "        rand_row = np.random.randint(0,n_row,n_row)\n",
    "        newdat = d.iloc[rand_row,:]\n",
    "        newdat.index = np.arange(n_row)+1\n",
    "        \n",
    "        ### Obtain FSR results\n",
    "        fsrout = ffsr(newdat.iloc[:,1:],pd.DataFrame(newdat.iloc[:,0]),g0,bag=True,max_size=max_s,var_incl=v_incl)\n",
    "        allbetas.loc[i,fsrout[0].index.values] = fsrout[0].iloc[:,0]\n",
    "        allses.loc[i,fsrout[0].index.values] = fsrout[0].iloc[:,1]\n",
    "        alphas.append(fsrout[1])\n",
    "        sizes.append(fsrout[2])\n",
    "\n",
    "        ### Update counts num times var included\n",
    "        nentries.loc[fsrout[0].index[np.abs(np.around(fsrout[0].iloc[:,0],prec))>0]] += 1\n",
    "        \n",
    "    ### Compute averages\n",
    "    avgbeta = np.around(allbetas.mean(axis=0),prec) # mean across rows / colmeans == mean of each cov's betahat\n",
    "    avgse = np.around(allses.mean(axis=0),prec)\n",
    "    avgalpha = np.mean(alphas)\n",
    "    avgsize = np.mean(sizes)\n",
    "    var_props = nentries/float(B)\n",
    "    cov_res = pd.concat([avgbeta,avgse,var_props],axis=1)\n",
    "    cov_res.columns = ['betahat','betase','prop_incl']\n",
    "    \n",
    "    return cov_res, avgalpha, avgsize\n",
    "    \n",
    "    \n",
    "\n",
    "# Notes: \n",
    "# 1. appropriate transformations are expected to have been applied prior to utilization of FSR algorithm\n",
    "\n",
    "# To-do:\n",
    "# 1. adjust betaest fcn and ffsr to allow for specification of intercept and whether data should be normalized in estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "### Code to test / build functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "X = np.random.multivariate_normal(np.zeros(15),np.eye(15),(100))\n",
    "beta = np.array([0,0,5,6,0,0,4,0,0,0,5,0,0,0,0]).reshape(15,1) # signif betas: 3,4,7,11\n",
    "Y = X.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y2 = pd.DataFrame(Y)\n",
    "X2 = pd.DataFrame(X)\n",
    "X2.columns = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16)\n",
      "(93, 16)\n"
     ]
    }
   ],
   "source": [
    "# Test potentially faster removal of missing data rows\n",
    "tx = np.random.multivariate_normal(np.zeros(15),np.eye(15),(100))\n",
    "tb = np.array([0,0,5,6,0,0,4,0,0,0,5,0,0,0,0]).reshape(15,1) # signif betas: 3,4,7,11\n",
    "ty= tx.dot(tb)\n",
    "ty[[1,3,13]] = 'NaN'\n",
    "tx[0,10], tx[8,0], tx[40,5], tx[33,14] = 'NaN', 'NaN', 'NaN', 'NaN'\n",
    "tty = pd.DataFrame(ty)\n",
    "ttx = pd.DataFrame(tx)\n",
    "ttx.columns = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\"]\n",
    "\n",
    "d = pd.concat([tty,ttx],axis=1)\n",
    "\n",
    "print d.shape\n",
    "d.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "print d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txna = np.isnan(ttx).any(axis=1)\n",
    "ttx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New handling of missing values\n",
    "def rm_miss(dat):\n",
    "    # NOTE: will override original dat file\n",
    "    dat.dropna(inplace=True)\n",
    "    return dat\n",
    "\n",
    "# Current handling of missing values\n",
    "def rm_miss2(x,y):\n",
    "    yna = np.isnan(y).any(axis=1)\n",
    "    xna = np.isnan(x).any(axis=1).reshape(x.shape[0],1)\n",
    "    anyna = np.array([int(max(a,b)) for a,b in zip(xna,yna)])\n",
    "    missrow = np.where(anyna==1)[0]\n",
    "    y = y.drop(y.index[missrow])\n",
    "    x = x.drop(x.index[missrow])\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 517 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rm_miss(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.51 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rm_miss2(ttx,tty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternate version (output)\n",
    "def rm_miss(dat):\n",
    "    # NOTE: will override original dat file\n",
    "    dat.dropna(inplace=True)\n",
    "    y = dat.iloc[:,0]\n",
    "    x = dat.iloc[:,1:]\n",
    "    return (x,y)\n",
    "\n",
    "# Current handling of missing values\n",
    "def rm_miss2(x,y):\n",
    "    yna = np.isnan(y).any(axis=1)\n",
    "    xna = np.isnan(x).any(axis=1).reshape(x.shape[0],1)\n",
    "    anyna = np.array([int(max(a,b)) for a,b in zip(xna,yna)])\n",
    "    missrow = np.where(anyna==1)[0]\n",
    "    y = y.drop(y.index[missrow])\n",
    "    x = x.drop(x.index[missrow])\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 803 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rm_miss(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.51 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rm_miss2(ttx,tty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternate version (input, output)\n",
    "def rm_miss(x,y):\n",
    "    # NOTE: will override original dat file\n",
    "    dat = pd.concat([y,x],axis=1)\n",
    "    dat.dropna(inplace=True)\n",
    "    y = dat.iloc[:,0]\n",
    "    x = dat.iloc[:,1:]\n",
    "    return (x,y)\n",
    "\n",
    "# Current handling of missing values\n",
    "def rm_miss2(x,y):\n",
    "    yna = np.isnan(y).any(axis=1)\n",
    "    xna = np.isnan(x).any(axis=1).reshape(x.shape[0],1)\n",
    "    anyna = np.array([int(max(a,b)) for a,b in zip(xna,yna)])\n",
    "    missrow = np.where(anyna==1)[0]\n",
    "    y = y.drop(y.index[missrow])\n",
    "    x = x.drop(x.index[missrow])\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.15 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rm_miss(ttx,tty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.52 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rm_miss2(ttx,tty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "### Test functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fwd_r = forward(X2,Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V4' 'V7' 'V3' 'V11' 'V2' 'V10' 'V1' 'V5' 'V15' 'V12' 'V14' 'V8' 'V9' 'V6'\n",
      " 'V13']\n"
     ]
    }
   ],
   "source": [
    "codnames = cov_order(X2.columns.values)\n",
    "\n",
    "print codnames\n",
    "\n",
    "#print ro.r('fwd$vorder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "po = pval_comp(X2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg00 = 0.05\n",
    "af = alpha_F(gg00, X2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gf = gamma_F(po, X2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = np.arange(X2.shape[1])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Var</th>\n",
       "      <th>p</th>\n",
       "      <th>p_m</th>\n",
       "      <th>alpha_F</th>\n",
       "      <th>gamma_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td>  1</td>\n",
       "      <td>  V4</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0071</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td>  2</td>\n",
       "      <td>  V7</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0115</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td>  3</td>\n",
       "      <td>  V3</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0167</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td>  4</td>\n",
       "      <td> V11</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0227</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>  5</td>\n",
       "      <td>  V2</td>\n",
       "      <td> 0.0003</td>\n",
       "      <td> 0.0003</td>\n",
       "      <td> 0.0300</td>\n",
       "      <td> 0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>  6</td>\n",
       "      <td> V10</td>\n",
       "      <td> 0.0078</td>\n",
       "      <td> 0.0078</td>\n",
       "      <td> 0.0389</td>\n",
       "      <td> 0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td>  7</td>\n",
       "      <td>  V1</td>\n",
       "      <td> 0.0116</td>\n",
       "      <td> 0.0116</td>\n",
       "      <td> 0.0500</td>\n",
       "      <td> 0.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>  8</td>\n",
       "      <td>  V5</td>\n",
       "      <td> 0.0973</td>\n",
       "      <td> 0.0800</td>\n",
       "      <td> 0.0643</td>\n",
       "      <td> 0.0756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td>  9</td>\n",
       "      <td> V15</td>\n",
       "      <td> 0.0800</td>\n",
       "      <td> 0.0973</td>\n",
       "      <td> 0.0833</td>\n",
       "      <td> 0.0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 10</td>\n",
       "      <td> V12</td>\n",
       "      <td> 0.1259</td>\n",
       "      <td> 0.1259</td>\n",
       "      <td> 0.1100</td>\n",
       "      <td> 0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 11</td>\n",
       "      <td> V14</td>\n",
       "      <td> 0.2040</td>\n",
       "      <td> 0.2040</td>\n",
       "      <td> 0.1500</td>\n",
       "      <td> 0.0680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 12</td>\n",
       "      <td>  V8</td>\n",
       "      <td> 0.2480</td>\n",
       "      <td> 0.2480</td>\n",
       "      <td> 0.2167</td>\n",
       "      <td> 0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> 13</td>\n",
       "      <td>  V9</td>\n",
       "      <td> 0.3679</td>\n",
       "      <td> 0.3679</td>\n",
       "      <td> 0.3500</td>\n",
       "      <td> 0.0526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td> 14</td>\n",
       "      <td>  V6</td>\n",
       "      <td> 0.6474</td>\n",
       "      <td> 0.6474</td>\n",
       "      <td> 0.7500</td>\n",
       "      <td> 0.0432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> 15</td>\n",
       "      <td> V13</td>\n",
       "      <td> 0.7110</td>\n",
       "      <td> 0.7110</td>\n",
       "      <td> 1.0000</td>\n",
       "      <td> 0.7110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     S  Var       p     p_m  alpha_F  gamma_F\n",
       "0    1   V4  0.0000  0.0000   0.0071   0.0000\n",
       "1    2   V7  0.0000  0.0000   0.0115   0.0000\n",
       "2    3   V3  0.0000  0.0000   0.0167   0.0000\n",
       "3    4  V11  0.0000  0.0000   0.0227   0.0000\n",
       "4    5   V2  0.0003  0.0003   0.0300   0.0004\n",
       "5    6  V10  0.0078  0.0078   0.0389   0.0100\n",
       "6    7   V1  0.0116  0.0116   0.0500   0.0116\n",
       "7    8   V5  0.0973  0.0800   0.0643   0.0756\n",
       "8    9  V15  0.0800  0.0973   0.0833   0.0480\n",
       "9   10  V12  0.1259  0.1259   0.1100   0.0572\n",
       "10  11  V14  0.2040  0.2040   0.1500   0.0680\n",
       "11  12   V8  0.2480  0.2480   0.2167   0.0572\n",
       "12  13   V9  0.3679  0.3679   0.3500   0.0526\n",
       "13  14   V6  0.6474  0.6474   0.7500   0.0432\n",
       "14  15  V13  0.7110  0.7110   1.0000   0.7110"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsr_results = fsrtable(sss, codnames, po, np.sort(po), af, gf)\n",
    "fsr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0000',\n",
       " '0.0000',\n",
       " '0.0000',\n",
       " '0.0000',\n",
       " '0.0003',\n",
       " '0.0078',\n",
       " '0.0116',\n",
       " '0.0973',\n",
       " '0.0800',\n",
       " '0.1259',\n",
       " '0.2040',\n",
       " '0.2480',\n",
       " '0.3679',\n",
       " '0.6474',\n",
       " '0.7110']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test code possibly more efficient at building output table\n",
    "format(po[6],'.4f')\n",
    "[format(x,'.4f') for x in po]\n",
    "a = '.4f'\n",
    "[format(x,a) for x in po]\n",
    "np.array([sss,codnames,[format(x,'.4f') for x in po],[format(x,'.4f') for x in af]]).T.reshape(15,4)\n",
    "pd.DataFrame([sss,codnames,[format(x,'.4f') for x in po],[format(x,'.4f') for x in af]]).T#.reshape(15,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# New function to create output table\n",
    "def fsrtable2(size, vname, p_orig, p_mono, alphaf, gammaf, prec_f='.4f'):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   size   = model size at each step of forward sel proc                   [S]\n",
    "    #   vname  = variable name that entered at each step (num vars = p)        [Var]\n",
    "    #   p_orig = p-values at each step                                         [p]\n",
    "    #   p_mono = ascending p-values                                            [p_s]\n",
    "    #   alphaf = alpha-to-enter (p-value cutoff) for model entry at each step  [alpha_F]\n",
    "    #   gammaf = FSR at each step                                              [gamma_F]\n",
    "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
    "    \n",
    "    ### Output:\n",
    "    # table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Round all arrays\n",
    "    p_od = [format(x,prec_f) for x in p_orig]\n",
    "    p_md = [format(x,prec_f) for x in p_mono]\n",
    "    ad = [format(x,prec_f) for x in alphaf]\n",
    "    gd = [format(x,prec_f) for x in gammaf]\n",
    "    \n",
    "    ### Combine the arrays\n",
    "    tab = pd.DataFrame([size,vname,p_od,p_md,ad,gd]).T\n",
    "    tab.columns = ['S','Var','p','p_m','alpha_F','gamma_F']\n",
    "    \n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.39 ms per loop\n",
      "1000 loops, best of 3: 1.72 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Compare speed of old and new table functions\n",
    "%timeit fsrtable(sss, codnames, po, np.sort(po), af, gf)\n",
    "%timeit fsrtable2(sss, codnames, po, np.sort(po), af, gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     S  Var       p     p_m  alpha_F  gamma_F\n",
      "0    1   V4  0.0000  0.0000   0.0071   0.0000\n",
      "1    2   V7  0.0000  0.0000   0.0115   0.0000\n",
      "2    3   V3  0.0000  0.0000   0.0167   0.0000\n",
      "3    4  V11  0.0000  0.0000   0.0227   0.0000\n",
      "4    5   V2  0.0003  0.0003   0.0300   0.0004\n",
      "5    6  V10  0.0078  0.0078   0.0389   0.0100\n",
      "6    7   V1  0.0116  0.0116   0.0500   0.0116\n",
      "7    8   V5  0.0973  0.0800   0.0643   0.0756\n",
      "8    9  V15  0.0800  0.0973   0.0833   0.0480\n",
      "9   10  V12  0.1259  0.1259   0.1100   0.0572\n",
      "10  11  V14  0.2040  0.2040   0.1500   0.0680\n",
      "11  12   V8  0.2480  0.2480   0.2167   0.0572\n",
      "12  13   V9  0.3679  0.3679   0.3500   0.0526\n",
      "13  14   V6  0.6474  0.6474   0.7500   0.0432\n",
      "14  15  V13  0.7110  0.7110   1.0000   0.7110\n",
      "     S  Var       p     p_m alpha_F gamma_F\n",
      "0    1   V4  0.0000  0.0000  0.0071  0.0000\n",
      "1    2   V7  0.0000  0.0000  0.0115  0.0000\n",
      "2    3   V3  0.0000  0.0000  0.0167  0.0000\n",
      "3    4  V11  0.0000  0.0000  0.0227  0.0000\n",
      "4    5   V2  0.0003  0.0003  0.0300  0.0004\n",
      "5    6  V10  0.0078  0.0078  0.0389  0.0100\n",
      "6    7   V1  0.0116  0.0116  0.0500  0.0116\n",
      "7    8   V5  0.0973  0.0800  0.0643  0.0756\n",
      "8    9  V15  0.0800  0.0973  0.0833  0.0480\n",
      "9   10  V12  0.1259  0.1259  0.1100  0.0572\n",
      "10  11  V14  0.2040  0.2040  0.1500  0.0680\n",
      "11  12   V8  0.2480  0.2480  0.2167  0.0572\n",
      "12  13   V9  0.3679  0.3679  0.3500  0.0526\n",
      "13  14   V6  0.6474  0.6474  0.7500  0.0432\n",
      "14  15  V13  0.7110  0.7110  1.0000  0.7110\n"
     ]
    }
   ],
   "source": [
    "# Confirm identical output\n",
    "print fsrtable(sss, codnames, po, np.sort(po), af, gf)\n",
    "print fsrtable2(sss, codnames, po, np.sort(po), af, gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Var</th>\n",
       "      <th>p</th>\n",
       "      <th>p_m</th>\n",
       "      <th>alpha_F</th>\n",
       "      <th>gamma_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td>  1</td>\n",
       "      <td>  V4</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0071</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td>  2</td>\n",
       "      <td>  V7</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0115</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td>  3</td>\n",
       "      <td>  V3</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0167</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td>  4</td>\n",
       "      <td> V11</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0227</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>  5</td>\n",
       "      <td>  V2</td>\n",
       "      <td> 0.0003</td>\n",
       "      <td> 0.0003</td>\n",
       "      <td> 0.0300</td>\n",
       "      <td> 0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>  6</td>\n",
       "      <td> V10</td>\n",
       "      <td> 0.0078</td>\n",
       "      <td> 0.0078</td>\n",
       "      <td> 0.0389</td>\n",
       "      <td> 0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td>  7</td>\n",
       "      <td>  V1</td>\n",
       "      <td> 0.0116</td>\n",
       "      <td> 0.0116</td>\n",
       "      <td> 0.0500</td>\n",
       "      <td> 0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>  8</td>\n",
       "      <td>  V5</td>\n",
       "      <td> 0.0973</td>\n",
       "      <td> 0.0973</td>\n",
       "      <td> 0.0643</td>\n",
       "      <td> 0.0681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td>  9</td>\n",
       "      <td> V15</td>\n",
       "      <td> 0.0800</td>\n",
       "      <td> 0.0973</td>\n",
       "      <td> 0.0833</td>\n",
       "      <td> 0.0681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 10</td>\n",
       "      <td> V12</td>\n",
       "      <td> 0.1259</td>\n",
       "      <td> 0.1259</td>\n",
       "      <td> 0.1100</td>\n",
       "      <td> 0.0687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 11</td>\n",
       "      <td> V14</td>\n",
       "      <td> 0.2040</td>\n",
       "      <td> 0.2040</td>\n",
       "      <td> 0.1500</td>\n",
       "      <td> 0.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 12</td>\n",
       "      <td>  V8</td>\n",
       "      <td> 0.2480</td>\n",
       "      <td> 0.2480</td>\n",
       "      <td> 0.2167</td>\n",
       "      <td> 0.0763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> 13</td>\n",
       "      <td>  V9</td>\n",
       "      <td> 0.3679</td>\n",
       "      <td> 0.3679</td>\n",
       "      <td> 0.3500</td>\n",
       "      <td> 0.0788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td> 14</td>\n",
       "      <td>  V6</td>\n",
       "      <td> 0.6474</td>\n",
       "      <td> 0.6474</td>\n",
       "      <td> 0.7500</td>\n",
       "      <td> 0.0863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> 15</td>\n",
       "      <td> V13</td>\n",
       "      <td> 0.7110</td>\n",
       "      <td> 0.7110</td>\n",
       "      <td> 1.0000</td>\n",
       "      <td> 0.0444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     S  Var       p     p_m alpha_F gamma_F\n",
       "0    1   V4  0.0000  0.0000  0.0071  0.0000\n",
       "1    2   V7  0.0000  0.0000  0.0115  0.0000\n",
       "2    3   V3  0.0000  0.0000  0.0167  0.0000\n",
       "3    4  V11  0.0000  0.0000  0.0227  0.0000\n",
       "4    5   V2  0.0003  0.0003  0.0300  0.0005\n",
       "5    6  V10  0.0078  0.0078  0.0389  0.0112\n",
       "6    7   V1  0.0116  0.0116  0.0500  0.0130\n",
       "7    8   V5  0.0973  0.0973  0.0643  0.0681\n",
       "8    9  V15  0.0800  0.0973  0.0833  0.0681\n",
       "9   10  V12  0.1259  0.1259  0.1100  0.0687\n",
       "10  11  V14  0.2040  0.2040  0.1500  0.0850\n",
       "11  12   V8  0.2480  0.2480  0.2167  0.0763\n",
       "12  13   V9  0.3679  0.3679  0.3500  0.0788\n",
       "13  14   V6  0.6474  0.6474  0.7500  0.0863\n",
       "14  15  V13  0.7110  0.7110  1.0000  0.0444"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.concat([Y2,X2],axis=1)\n",
    "ffsr(d,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.033678 s\n",
      "File: <ipython-input-8-e22c52bb1641>\n",
      "Function: ffsr at line 286\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   286                                           def ffsr(dat,g0=0.05,betaout=False,gs=None,max_size=None,var_incl=None,bag=False,prec_f='.4f'):\n",
      "   287                                               \n",
      "   288                                               ### Input params:\n",
      "   289                                               #   dat      = python dataframe of original p covariates, 1 outcome (in first col.): n x p+1\n",
      "   290                                               #   g0       = float pre-specified FSR of interest (\"gamma0\")\n",
      "   291                                               #   betaout  = boolean of whether to include estimated betahats from final selected model\n",
      "   292                                               #   gs       = float or vector of gamma's at which to specifically compute alpha_F\n",
      "   293                                               #   max_size = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
      "   294                                               #   var_incl = array of cols corresponding to those vars to force into model\n",
      "   295                                               #   bag      = boolean of whether to output FSR table (non-bagging results) or reduced output for bagging purposes\n",
      "   296                                               #   prec_f   = string of precision (num digits) desired in FSR output table (string to be given to 'format' python fcn)\n",
      "   297                                               \n",
      "   298                                               ### Output: \n",
      "   299                                               #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
      "   300                                               # Table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
      "   301                                               #   S:       model size at given step\n",
      "   302                                               #   Var:     name of var that entered at given step\n",
      "   303                                               #   p:       p-value of var that entered at given step\n",
      "   304                                               #   p_m:     mono. inc. p-value (vector or original p-values arranged to be monotonically increasing)\n",
      "   305                                               #   alpha_F: cutoff value for model entry given gamma_0 and current p_s value\n",
      "   306                                               #   gamma_F: FSR given current alpha_F and model size (== step num)\n",
      "   307                                               #       and\n",
      "   308                                               #   vector of alpha_F's for specified gamma's (g)\n",
      "   309                                               #       and\n",
      "   310                                               #   vector of estimated beta param's for final model (based on g0)\n",
      "   311                                           \n",
      "   312         1            7      7.0      0.0      import numpy as np\n",
      "   313         1            3      3.0      0.0      import pandas as pd\n",
      "   314                                               \n",
      "   315                                               ### Clean and check data - make sure dat = pandas dataframes or else convert them\n",
      "   316         1            2      2.0      0.0      if bag==False:\n",
      "   317         1            9      9.0      0.0          if df_type(dat)==True:\n",
      "   318         1            2      2.0      0.0              if isinstance(dat,pd.DataFrame):\n",
      "   319         1          730    730.0      2.2                  d = dat.copy()\n",
      "   320                                                       else:\n",
      "   321                                                           if isinstance(dat,np.ndarray):\n",
      "   322                                                               d = pd.DataFrame(dat)\n",
      "   323                                                               vnum = list(np.arange(d.shape[1])+1)\n",
      "   324                                                               vchr = list(np.repeat(\"V\",d.shape[1]))\n",
      "   325                                                               d.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
      "   326                                                   else:\n",
      "   327                                                       return df_type(dat)\n",
      "   328                                                   \n",
      "   329                                                   ### Remove missing values\n",
      "   330         1         2130   2130.0      6.3          d.dropna(inplace=True)\n",
      "   331                                                   \n",
      "   332                                                   ### Check that p < n to ensure regression solutions\n",
      "   333         1            7      7.0      0.0          if (d.shape[1]-1) >= d.shape[0]:\n",
      "   334                                                       raise Exception(\"N must be > p for valid regression solutions\")\n",
      "   335                                               else:\n",
      "   336                                                   d = dat.copy()\n",
      "   337                                               \n",
      "   338                                               ### If max model size not specified, select all possible cov.s\n",
      "   339         1            2      2.0      0.0      if max_size==None:\n",
      "   340         1            3      3.0      0.0          max_size = d.shape[1]-1\n",
      "   341                                                   \n",
      "   342                                               ### Perform forward selection\n",
      "   343         1        25216  25216.0     74.9      fwd_sel = forward(d.iloc[:,1:], pd.DataFrame(d.iloc[:,0]), max_size, var_incl)\n",
      "   344                                               \n",
      "   345                                               ### Save order of covariate entry into model\n",
      "   346         1          531    531.0      1.6      cov_entry_order = cov_order(d.columns.values[1:], max_size, var_incl)\n",
      "   347                                               \n",
      "   348                                               ### Compute p-value of each covariate entering the model\n",
      "   349         1         1287   1287.0      3.8      p_orig = pval_comp(max_size)\n",
      "   350                                               \n",
      "   351                                               ### Arrange p-values in mono. inc. order\n",
      "   352        16           90      5.6      0.3      p_mono = np.array([max(p_orig[:(i+1)]) for i in range(len(p_orig))])\n",
      "   353                                                   \n",
      "   354                                               ### Gamma_F computation\n",
      "   355         1          145    145.0      0.4      g_F = gamma_F(p_mono, d.shape[1], max_size)\n",
      "   356                                               \n",
      "   357                                               ### Check if betaout desired, if so compute beta_hat of model corresponding to specific gamma0\n",
      "   358         1            2      2.0      0.0      if betaout==True or bag==True:\n",
      "   359                                                   betahats = beta_est(d.iloc[:,1:], d.iloc[:,0], g0, g_F, cov_entry_order)\n",
      "   360                                                   \n",
      "   361                                               ### Check if bagging desired\n",
      "   362         1            1      1.0      0.0      if bag==False: \n",
      "   363                                                   ### Alpha_F computation for all steps in fwd sel proc\n",
      "   364         1           36     36.0      0.1          a_F = alpha_F(g0, d.shape[1]-1, max_size)\n",
      "   365                                                   \n",
      "   366                                                   ### Model size\n",
      "   367         1            7      7.0      0.0          S = np.arange(max_size)+1\n",
      "   368                                                   \n",
      "   369                                                   ### Combine S, Cov_names, p-vals, sorted p-vals, alpha_F, gamma_F into table\n",
      "   370         1         3463   3463.0     10.3          fsr_results = fsrtable(S, cov_entry_order, p_orig, p_mono, a_F, g_F)\n",
      "   371                                                   \n",
      "   372                                                   ### Return selected output: FSR table (+ betahat) (+ alpha_specific)\n",
      "   373         1            2      2.0      0.0          if gs!=None: \n",
      "   374                                                       ### Compute alpha_F for specific gammas (gs)\n",
      "   375                                                       if betaout==True:\n",
      "   376                                                           return fsr_results, betahats, alpha_F_g(gs, g_F, d.shape[1]-1)\n",
      "   377                                                       else:\n",
      "   378                                                           return fsr_results, alpha_F_g(gs, g_F, d.shape[1]-1)\n",
      "   379                                                   else:\n",
      "   380         1            2      2.0      0.0              if betaout==True:\n",
      "   381                                                           return fsr_results, betahats\n",
      "   382                                                       else:\n",
      "   383         1            1      1.0      0.0                  return fsr_results\n",
      "   384                                               else:\n",
      "   385                                                   return betahats, alpha_F_g(g0, g_F, d.shape[1]-1), len(betahats)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstats = %lprun -r -f ffsr ffsr(d, 0.05)\n",
    "lstats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 18.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n100 ffsr(d,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ffsr2_d10 as f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 19.4 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n100 f2.ffsr(X2,Y2,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Marginal improvement in speed: -0.6ms\n",
    "\n",
    "# d.copy (730, 2.2%)                             [+0.3% b/c copying both X and Y now]\n",
    "# Clean missing values (all of it; 2130, 6.3%)   [-3.8%]\n",
    "# Forward sel proc (25216, 74.9%)                [+7.5%]\n",
    "# Cov_order (531, 1.6%)                          [-0.5%]\n",
    "# Pval_comp (1287, 3.8%)                         [+0.7%]\n",
    "# Gamma_F (145, 0.4%)                            [0%]\n",
    "# Fsrtable (3463, 10.3%)                         [-3.5%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Alternate version:\n",
    "\n",
    "\"\"\" FastFSR function \"\"\"\n",
    "def ffsr2(dat,g0=0.05,betaout=False,gs=None,max_size=None,var_incl=None,bag=False,prec_f='.4f'):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat      = python dataframe of original p covariates, 1 outcome (in first col.): n x p+1\n",
    "    #   g0       = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   betaout  = boolean of whether to include estimated betahats from final selected model\n",
    "    #   gs       = float or vector of gamma's at which to specifically compute alpha_F\n",
    "    #   max_size = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   var_incl = array of cols corresponding to those vars to force into model\n",
    "    #   bag      = boolean of whether to output FSR table (non-bagging results) or reduced output for bagging purposes\n",
    "    #   prec_f   = string of precision (num digits) desired in FSR output table (string to be given to 'format' python fcn)\n",
    "    \n",
    "    ### Output: \n",
    "    #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
    "    # Table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    #   S:       model size at given step\n",
    "    #   Var:     name of var that entered at given step\n",
    "    #   p:       p-value of var that entered at given step\n",
    "    #   p_m:     mono. inc. p-value (vector or original p-values arranged to be monotonically increasing)\n",
    "    #   alpha_F: cutoff value for model entry given gamma_0 and current p_s value\n",
    "    #   gamma_F: FSR given current alpha_F and model size (== step num)\n",
    "    #       and\n",
    "    #   vector of alpha_F's for specified gamma's (g)\n",
    "    #       and\n",
    "    #   vector of estimated beta param's for final model (based on g0)\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data - make sure dat = pandas dataframes or else convert them\n",
    "    if bag==False:\n",
    "        if df_type(dat)==True:\n",
    "            if isinstance(dat,pd.DataFrame):\n",
    "                d = dat.copy()\n",
    "            else:\n",
    "                if isinstance(dat,np.ndarray):\n",
    "                    d = pd.DataFrame(dat)\n",
    "                    vnum = list(np.arange(d.shape[1])+1)\n",
    "                    vchr = list(np.repeat(\"V\",d.shape[1]))\n",
    "                    d.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "        else:\n",
    "            return df_type(dat)\n",
    "        \n",
    "        ### Remove missing values\n",
    "        d.dropna(inplace=True)\n",
    "        \n",
    "        ### Check that p < n to ensure regression solutions\n",
    "        if (d.shape[1]-1) >= d.shape[0]:\n",
    "            raise Exception(\"N must be > p for valid regression solutions\")\n",
    "    else:\n",
    "        d = dat.copy()\n",
    "    \n",
    "    ### If max model size not specified, select all possible cov.s\n",
    "    if max_size==None:\n",
    "        max_size = d.shape[1]-1\n",
    "        \n",
    "    y, x = pd.DataFrame(d.iloc[:,0]), d.iloc[:,1:]\n",
    "        \n",
    "    ### Perform forward selection\n",
    "    fwd_sel = forward(x, y, max_size, var_incl)\n",
    "    \n",
    "    ### Save order of covariate entry into model\n",
    "    cov_entry_order = cov_order(d.columns.values[1:], max_size, var_incl)\n",
    "    \n",
    "    ### Compute p-value of each covariate entering the model\n",
    "    p_orig = pval_comp(max_size)\n",
    "    \n",
    "    ### Arrange p-values in mono. inc. order\n",
    "    p_mono = np.array([max(p_orig[:(i+1)]) for i in range(len(p_orig))])\n",
    "        \n",
    "    ### Gamma_F computation\n",
    "    g_F = gamma_F(p_mono, d.shape[1], max_size)\n",
    "    \n",
    "    ### Check if betaout desired, if so compute beta_hat of model corresponding to specific gamma0\n",
    "    if betaout==True or bag==True:\n",
    "        betahats = beta_est(x, y, g0, g_F, cov_entry_order)\n",
    "        \n",
    "    ### Check if bagging desired\n",
    "    if bag==False: \n",
    "        ### Alpha_F computation for all steps in fwd sel proc\n",
    "        a_F = alpha_F(g0, d.shape[1]-1, max_size)\n",
    "        \n",
    "        ### Model size\n",
    "        S = np.arange(max_size)+1\n",
    "        \n",
    "        ### Combine S, Cov_names, p-vals, sorted p-vals, alpha_F, gamma_F into table\n",
    "        fsr_results = fsrtable(S, cov_entry_order, p_orig, p_mono, a_F, g_F)\n",
    "        \n",
    "        ### Return selected output: FSR table (+ betahat) (+ alpha_specific)\n",
    "        if gs!=None: \n",
    "            ### Compute alpha_F for specific gammas (gs)\n",
    "            if betaout==True:\n",
    "                return fsr_results, betahats, alpha_F_g(gs, g_F, d.shape[1]-1)\n",
    "            else:\n",
    "                return fsr_results, alpha_F_g(gs, g_F, d.shape[1]-1)\n",
    "        else:\n",
    "            if betaout==True:\n",
    "                return fsr_results, betahats\n",
    "            else:\n",
    "                return fsr_results\n",
    "    else:\n",
    "        return betahats, alpha_F_g(g0, g_F, d.shape[1]-1), len(betahats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 19.4 ms per loop\n",
      "100 loops, best of 3: 20.7 ms per loop\n",
      "100 loops, best of 3: 19.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n100 ffsr(d,0.05)\n",
    "%timeit -n100 f2.ffsr(X2,Y2,0.05)\n",
    "%timeit -n100 ffsr2(d,0.05)       # KEEP this version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading required package: leaps\n",
       "   var   pval  pvmax    Rsq      g\n",
       "1    4 0.0000 0.0000 0.3778 0.0000\n",
       "2    7 0.0000 0.0000 0.6402 0.0000\n",
       "3    3 0.0000 0.0000 0.8519 0.0000\n",
       "4   11 0.0000 0.0000 1.0000 0.0000\n",
       "5    2 0.0003 0.0003 1.0000 0.0004\n",
       "6   10 0.0078 0.0078 1.0000 0.0100\n",
       "7    1 0.0116 0.0116 1.0000 0.0116\n",
       "8    5 0.0973 0.0973 1.0000 0.0584\n",
       "9   15 0.0800 0.0973 1.0000 0.0584\n",
       "10  12 0.1259 0.1259 1.0000 0.0572\n",
       "11  14 0.2040 0.2040 1.0000 0.0680\n",
       "12   8 0.2480 0.2480 1.0000 0.0572\n",
       "13   9 0.3679 0.3679 1.0000 0.0526\n",
       "14   6 0.6474 0.6474 1.0000 0.0432\n",
       "15  13 0.7110 0.7110 1.0000 0.0000\n",
       "$mod\n",
       "\n",
       "Call:\n",
       "lm(formula = y ~ x)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)          xV4          xV7          xV3         xV11          xV2  \n",
       "  4.441e-16    6.000e+00    4.000e+00    5.000e+00    5.000e+00    2.758e-16  \n",
       "       xV10          xV1  \n",
       " -7.575e-16    2.434e-17  \n",
       "\n",
       "\n",
       "$size\n",
       "[1] 7\n",
       "\n",
       "$x.ind\n",
       "[1]  4  7  3 11  2 10  1\n",
       "\n",
       "$alphahat.ER\n",
       "[1] 0.05\n",
       "\n",
       "   user  system elapsed \n",
       "  0.028   0.008   0.042 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i X2,Y2\n",
    "\n",
    "fsr.fast<-function(x,y,gam0=.05,digits=4,print=T,plot=F){\n",
    "# estimated alpha for forward selection using Fast FSR (no simulation)\n",
    "# typical call: fsr.fast(x=ncaa2[,1:19],y=ncaa2[,20])->out\n",
    "# for use inside simulation loops, set print=F and plot=F\n",
    "# version 7 circa Nov. 2009, modified to handle partially blank colnames\n",
    "require(leaps)\n",
    "ok<-complete.cases(x,y)\n",
    "x<-x[ok,]                            # get rid of na's\n",
    "y<-y[ok]                             # since regsubsets can't handle na's\n",
    "m<-ncol(x)\n",
    "n<-nrow(x)\n",
    "if(m >= n) m1 <- n-5  else m1<-m     # to get rid of NA's in pv\n",
    "vm<-1:m1\n",
    "as.matrix(x)->x                      # in case x is a data frame\n",
    "if(any(colnames(x)==\"\"))colnames(x)<-NULL       # if only partially named columns\n",
    "colnames(x)<-colnames(x,do.NULL=F,prefix=\"\")    # corrects for no colnames\n",
    "pvm<-rep(0,m1)                       # to create pvm below\n",
    "regsubsets(x,y,method=\"forward\")->out.x\n",
    "pv.orig<-1-pf((out.x$rss[vm]-out.x$rss[vm+1])*(out.x$nn-(vm+1))/out.x$rss[vm+1],1,out.x$nn-(vm+1))\n",
    "for (i in 1:m1){pvm[i]<-max(pv.orig[1:i])}  # sequential max of pvalues\n",
    "alpha<-c(0,pvm)\n",
    "ng<-length(alpha)\n",
    "S<-rep(0,ng)                         # will contain num. of true entering in orig.\n",
    "real.seq<-data.frame(var=(out.x$vorder-1)[2:(m1+1)],pval=pv.orig,\n",
    "         pvmax=pvm,Rsq=round(1-out.x$rss[2:(m1+1)]/out.x$rss[1],4))\n",
    "for (ia in 2:ng){                    # loop through alpha values for S=size\n",
    "S[ia] <- sum(pvm<=alpha[ia])         # size of models at alpha[ia], S[1]=0\n",
    "}\n",
    "ghat<-(m-S)*alpha/(1+S)              # gammahat_ER\n",
    "# add additional points to make jumps\n",
    "alpha2<-alpha[2:ng]-.0000001\n",
    "ghat2<-(m-S[1:(ng-1)])*alpha2/(1+S[1:(ng-1)])\n",
    "zp<-data.frame(a=c(alpha,alpha2),g=c(ghat,ghat2))\n",
    "zp<-zp[order(zp$a),]\n",
    "gmax<-max(zp$g)\n",
    "index.max<-which.max(zp$g)           # index of largest ghat\n",
    "alphamax<-zp$a[index.max]            # alpha with largest ghat\n",
    "# gmax<-max(ghat)\n",
    "# index.max<-which.max(ghat)           # index of largest ghat\n",
    "# alphamax<-alpha[index.max]           # alpha with largest ghat\n",
    "ind<-(ghat <= gam0 & alpha<=alphamax)*1\n",
    "Sind<-S[max(which(ind > 0))]           # model size with ghat just below gam0\n",
    "alphahat.fast<-(1+Sind)*gam0/(m-Sind)  # ER est.\n",
    "size1<-sum(pvm<=alphahat.fast)+1       # size of model including intercept\n",
    "x<-x[,colnames(x)[(out.x$vorder-1)[2:size1]]]\n",
    "if(size1>1) x.ind<-(out.x$vorder-1)[2:size1]  else x.ind<-0\n",
    "if (size1==1) {mod <- lm(y~1)} else {mod <- lm(y~x)}\n",
    "# ghat3<-(m-size1+1)*alpha/(1+S)         # uses final ku est.\n",
    "ghat4<-(m-size1+1)*alpha/(1+0:m)\n",
    "#res<-data.frame(real.seq,ghigh=ghat2,glow=ghat[2:ng])\n",
    "res<-data.frame(real.seq,g=ghat[2:ng])\n",
    "if(print)print(round(res,digits))\n",
    "#if(plot){\n",
    "#plot(zp$a,zp$g,type=\"b\",xlab=\"Alpha\",ylab=\"Estimated Gamma\",xlim=c(0,alphamax))\n",
    "#points(alphahat.fast,gam0,pch=19)\n",
    "#lines(c(-1,alphahat.fast),c(gam0,gam0))\n",
    "#lines(c(alphahat.fast,alphahat.fast),c(-1,gam0))\n",
    "#}  # ends plot\n",
    "return(list(mod=mod,size=size1-1,x.ind=x.ind,alphahat.ER=alphahat.fast))\n",
    "}\n",
    "\n",
    "x2 = as.matrix(X2)\n",
    "y2 = as.matrix(Y2)\n",
    "\n",
    "#system.time(fsr.fast(x=x2,y=y2))\n",
    "start = proc.time()\n",
    "out <- fsr.fast(x=x2,y=y2)\n",
    "print(out)\n",
    "print(proc.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 23.3 ms per loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     S  Var       p     p_m alpha_F gamma_F\n",
       " 0    1   V4  0.0000  0.0000  0.0071  0.0000\n",
       " 1    2   V7  0.0000  0.0000  0.0115  0.0000\n",
       " 2    3   V3  0.0000  0.0000  0.0167  0.0000\n",
       " 3    4  V11  0.0000  0.0000  0.0227  0.0000\n",
       " 4    5   V2  0.0003  0.0003  0.0300  0.0005\n",
       " 5    6  V10  0.0078  0.0078  0.0389  0.0112\n",
       " 6    7   V1  0.0116  0.0116  0.0500  0.0130\n",
       " 7    8   V5  0.0973  0.0973  0.0643  0.0681\n",
       " 8    9  V15  0.0800  0.0973  0.0833  0.0681\n",
       " 9   10  V12  0.1259  0.1259  0.1100  0.0687\n",
       " 10  11  V14  0.2040  0.2040  0.1500  0.0850\n",
       " 11  12   V8  0.2480  0.2480  0.2167  0.0763\n",
       " 12  13   V9  0.3679  0.3679  0.3500  0.0788\n",
       " 13  14   V6  0.6474  0.6474  0.7500  0.0863\n",
       " 14  15  V13  0.7110  0.7110  1.0000  0.0444,              beta       beta_se\n",
       " V4   6.000000e+00  1.672676e-15\n",
       " V7   4.000000e+00  1.676875e-15\n",
       " V3   5.000000e+00  1.668047e-15\n",
       " V11  5.000000e+00  2.016266e-15\n",
       " V2   1.137979e-14  1.855839e-15\n",
       " V10  5.481726e-15  1.817640e-15\n",
       " V1  -1.110223e-15  1.727931e-15, 0.05)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit -n1 -r1 f = ffsr2(d,g0=0.05,betaout=True,gs=0.05)\n",
    "f\n",
    "# Faster by ~5ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Compare Python & R on NCSU's dataset\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncaa2 = pd.read_csv(\"ncaa_data2.txt\", delim_whitespace=True, skipinitialspace=True)\n",
    "type(ncaa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   var   pval  pvmax    Rsq      g\n",
       "1    2 0.0000 0.0000 0.7069 0.0000\n",
       "2    3 0.0001 0.0001 0.7539 0.0004\n",
       "3    5 0.0116 0.0116 0.7708 0.0270\n",
       "4    4 0.0053 0.0116 0.7901 0.0270\n",
       "5    7 0.0025 0.0116 0.8110 0.0270\n",
       "6   17 0.0433 0.0433 0.8197 0.0804\n",
       "7   15 0.0527 0.0527 0.8274 0.0791\n",
       "8    6 0.1056 0.1056 0.8327 0.0864\n",
       "9    9 0.0826 0.1056 0.8386 0.0864\n",
       "10   8 0.0536 0.1056 0.8457 0.0864\n",
       "11  12 0.2350 0.2350 0.8484 0.1566\n",
       "12  10 0.2864 0.2864 0.8505 0.1542\n",
       "13  13 0.3163 0.3163 0.8524 0.1054\n",
       "14  18 0.2697 0.3163 0.8546 0.1054\n",
       "15  11 0.4953 0.4953 0.8555 0.1238\n",
       "16   1 0.6326 0.6326 0.8559 0.1116\n",
       "17  14 0.7056 0.7056 0.8562 0.0784\n",
       "18  19 0.8605 0.8605 0.8563 0.0453\n",
       "19  16 0.9032 0.9032 0.8563 0.0000\n",
       "   user  system elapsed \n",
       "  0.007   0.000   0.006 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i ncaa2\n",
    "\n",
    "ncaa2 = as.matrix(ncaa2)\n",
    "\n",
    "system.time(fsr.fast(x=ncaa2[,1:19],y=ncaa2[,20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19']\n"
     ]
    }
   ],
   "source": [
    "cols = ncaa2.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "print cols\n",
    "nca2 = pd.DataFrame(ncaa2[cols],dtype='float')\n",
    "#nca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 23.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 ffsr2(nca2,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ffsr3_d11.py\n"
     ]
    }
   ],
   "source": [
    "%%file ffsr3_d11.py\n",
    "\"\"\" Pseudocode for Fast FSR algorithm \"\"\"\n",
    "\n",
    "\"\"\" Date: 4/24/15 \n",
    "    Modified: Improve missing value adjustments (code to test this comes after this cell) \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" Data type check \"\"\"\n",
    "def df_type(dat):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat = dataset whose type is to be checked / transformed\n",
    "    \n",
    "    ### Output:\n",
    "    #   error msg or True boolean\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    if isinstance(dat,pd.DataFrame)==False and isinstance(dat,np.ndarray)==False:\n",
    "        raise Exception(\"Data must be pandas DataFrame\")\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" p-value computation function \"\"\"\n",
    "def pval_comp(max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of p-values of each covariate at its given entry step\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.stats as st\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    # Pull RSS values & num_obs from fwd_proc object\n",
    "    rss = np.array(ro.r('fwd$rss'))\n",
    "    N = np.array(ro.r('fwd$nn'))\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(rss)-1\n",
    "    \n",
    "    # vector of model sizes\n",
    "    sizes = np.arange(max_size)+1\n",
    "    \n",
    "    # compute the F stats as defined above where p_f - p_r = 1 for each iteration\n",
    "    fstats = (rss[0:max_size] - rss[1:(max_size+1)]) / (rss[1:(max_size+1)] / (N - (sizes+1)))\n",
    "    \n",
    "    # return the p-values by comparing these stats to the F distn: F(1, n - p_f)\n",
    "    return 1 - st.f.cdf(fstats, 1, N-(sizes+1))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Covariate model entry order \"\"\"\n",
    "def cov_order(xcolnames,max_size=None,col_incl=None):\n",
    "    \n",
    "    # Input params:\n",
    "    #   xcolnames = array of names of covariates (same order as columns in original dataset)\n",
    "    #   max_size  = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl  = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    # array of covariate names sorted according to order of entry into the model\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
    "    \n",
    "    import numpy as np\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(xcolnames)\n",
    "        \n",
    "    ### Pull the cov entry order\n",
    "    vorder = ro.r('fwd$vorder[-1]') # remove intercept\n",
    "    vorder = vorder[0:max_size] # keep only the max model size number of covs\n",
    "    \n",
    "    ### Shift these values down by two (one to exclude intercept, one to make python indices)\n",
    "    vorderinds = np.array(vorder)-2\n",
    "    \n",
    "    ### Rearrange the var order st forced vars are at start of list\n",
    "    if col_incl==None:\n",
    "        col_incl = np.arange(max_size)+1\n",
    "    keep = xcolnames[[col_incl-1]] # pull var names of those vars forced into model (this is an array)\n",
    "    poss = [x for x in xcolnames if x not in keep] # pull var names of those not forced in (this is a list)\n",
    "    col_names = np.array(list(keep)+poss) # = rearranged array of varnames w/forced-in vars at start of list\n",
    "    \n",
    "    ### Sort the columns of X in order to obtain the var names in the entry order\n",
    "    return col_names[vorderinds[::]]\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\" Forward selection function \"\"\"\n",
    "def forward(x,y,max_size=None,col_incl=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x        = python dataframe of original p covariates, n x p\n",
    "    #   y        = python outcome dataframe, n x 1\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    # regsubsets R object -- the raw full output of the forward selection proc\n",
    "    \n",
    "    ### Load python packages to call R functions\n",
    "    import rpy2.robjects as ro\n",
    "    import pandas.rpy.common as com\n",
    "    \n",
    "    ### Convert x and y to R matrices <-- MAKE SURE x,y input == DATAFRAMES (or else change them to df's)!!!\n",
    "    ### and declare as R objects in global environment\n",
    "    ro.globalenv['x2'] = com.convert_to_r_matrix(x)\n",
    "    ro.globalenv['y2'] = com.convert_to_r_matrix(y)\n",
    "    if max_size==None:\n",
    "        max_size = x.shape[1]\n",
    "    ro.globalenv['maxv'] = ro.Vector(max_size)\n",
    "    if col_incl==None:\n",
    "        ro.r('coli=NULL')\n",
    "    else:\n",
    "        ro.globalenv['coli'] = ro.FloatVector(col_incl[:])\n",
    "    \n",
    "    ### Perform forward selection with regsubsets function\n",
    "    ro.globalenv['fwd'] = ro.r('leaps::regsubsets(x=x2,y=y2,method=\"forward\",nvmax=maxv,force.in=coli)')\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Gamma computation \"\"\"\n",
    "def gamma_F(pvs, ncov, max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   pvs      = vector of p-values (monotonically increasing) from forward sel procedure\n",
    "    #   ncov     = integer total number of covariates in data\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of gamma_F values\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = ncov\n",
    "        \n",
    "    # Create indices == model size at given step, call this S\n",
    "    S = np.arange(max_size)+1\n",
    "    \n",
    "    # gamma_F_i = p_s_i * (ncov - S_i) / (1 + S_i)\n",
    "    g_F = pvs * (ncov - S) / (1 + S)\n",
    "    \n",
    "    # Check for duplicate p-values\n",
    "    dups = list(set([x for x in list(pvs) if list(pvs).count(x) > 1]))\n",
    "    for i in range(len(dups)): g_F[pvs==dups[i]] = min(g_F[pvs==dups[i]])\n",
    "    \n",
    "    # if table run on all vars, the last gamma = 0,\n",
    "    #  instead set equal to the last pv_mono == final rate of unimp var inclusion\n",
    "    if(g_F[-1]==0): \n",
    "        g_F[-1]=pvs[-1]\n",
    "    \n",
    "    return g_F\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for model selection \"\"\"\n",
    "def alpha_F(g0, ncov, max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   g0       = float pre-specified FSR (gamma0)\n",
    "    #   ncov     = integer total number of covariates in data\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of alpha_F values\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = ncov\n",
    "        \n",
    "    # Create indices == model size at given step, call this S\n",
    "    S = np.arange(max_size)+1\n",
    "    \n",
    "    # alpha_F_i = gamma_0 * (1 + S_i) / (ncov - S_i)\n",
    "    alpha_F = g0 * (1 + S) / (ncov - S)\n",
    "    \n",
    "    # if table run on all vars, the last alpha = inf\n",
    "    #  instead set equal to 1 == include all vars\n",
    "    alpha_F[np.isinf(alpha_F)] = 1.\n",
    "    \n",
    "    return alpha_F        \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for specific gamma \"\"\"\n",
    "def alpha_F_g(g, gf, ncov):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   g    = float or vector (length k) of specified FSR at which to compute alpha\n",
    "    #   gf   = vector gamma_F's computed from gamma0, pv_sorted\n",
    "    #          used to compute largest size model (S) for which gamma_F < g\n",
    "    #   ncov = integer of total number covariates in data\n",
    "    \n",
    "    ### Output:\n",
    "    # integer alpha_F value\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    ### Compute model size for gf closest to (but still <) g\n",
    "    #S = np.array([max(np.which(x<=y)) for x in gf y in g])+1\n",
    "    if isinstance(g,np.ndarray): # if g is a vector\n",
    "        s_s = [np.where(gf>y) for y in g]\n",
    "        S = np.array([min(x[0]) for x in s_s])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "    else: # if g is a number\n",
    "        S = min(np.where(gf>g)[0])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" Beta-hat computation for specific gamma \"\"\"\n",
    "def beta_est(x, y, g, gf, vname):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x      = python dataframe of original p covariates, n x p\n",
    "    #   y      = python outcome dataframe, n x 1\n",
    "    #   g      = float of specified FSR at which to compute alpha\n",
    "    #   gf     = vector gamma_F's computed from gamma0, pv_mono\n",
    "    #            used to compute largest size model (S) for which gamma_F < g\n",
    "    #   vname  = ordered vector of names of vars entered into model under forward selection\n",
    "    \n",
    "    ### Output:\n",
    "    # array of estimated parameters\n",
    "    \n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    ### Compute model size corresponding to g\n",
    "    S = min(np.where(gf>g)[0])\n",
    "\n",
    "    ### Pull the cov names of those vars included in the above size model\n",
    "    modvars = vname[:S]\n",
    "\n",
    "    ### Fit the linear model using the selected model vars\n",
    "    fit = sm.OLS(y,x.loc[:,list(modvars)]).fit()\n",
    "    betaout = pd.DataFrame([fit.params,fit.bse]).T\n",
    "    betaout.columns = ['beta','beta_se']\n",
    "    \n",
    "    return betaout\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" FSR Results Table \"\"\"\n",
    "def fsrtable(size, vname, p_orig, p_mono, alphaf, gammaf, prec_f='.4f'):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   size   = model size at each step of forward sel proc                   [S]\n",
    "    #   vname  = variable name that entered at each step (num vars = p)        [Var]\n",
    "    #   p_orig = p-values at each step                                         [p]\n",
    "    #   p_mono = ascending p-values                                            [p_s]\n",
    "    #   alphaf = alpha-to-enter (p-value cutoff) for model entry at each step  [alpha_F]\n",
    "    #   gammaf = FSR at each step                                              [gamma_F]\n",
    "    #   prec_f = string of precision (num digits) desired in FSR output table\n",
    "    \n",
    "    ### Output:\n",
    "    # table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Round all arrays\n",
    "    p_od = [format(x,prec_f) for x in p_orig]\n",
    "    p_md = [format(x,prec_f) for x in p_mono]\n",
    "    ad = [format(x,prec_f) for x in alphaf]\n",
    "    gd = [format(x,prec_f) for x in gammaf]\n",
    "    \n",
    "    ### Combine the arrays\n",
    "    tab = pd.DataFrame([size,vname,p_od,p_md,ad,gd]).T\n",
    "    tab.columns = ['S','Var','p','p_m','alpha_F','gamma_F']\n",
    "    \n",
    "    return tab\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" FastFSR function \"\"\"\n",
    "def ffsr(dat,g0=0.05,betaout=False,gs=None,max_size=None,var_incl=None,bag=False,prec_f='.4f'):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat      = python dataframe of original p covariates, 1 outcome (in first col.): n x p+1\n",
    "    #   g0       = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   betaout  = boolean of whether to include estimated betahats from final selected model\n",
    "    #   gs       = float or vector of gamma's at which to specifically compute alpha_F\n",
    "    #   max_size = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   var_incl = array of cols corresponding to those vars to force into model\n",
    "    #   bag      = boolean of whether to output FSR table (non-bagging results) or reduced output for bagging purposes\n",
    "    #   prec_f   = string of precision (num digits) desired in FSR output table (string to be given to 'format' python fcn)\n",
    "    \n",
    "    ### Output: \n",
    "    #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
    "    # Table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    #   S:       model size at given step\n",
    "    #   Var:     name of var that entered at given step\n",
    "    #   p:       p-value of var that entered at given step\n",
    "    #   p_m:     mono. inc. p-value (vector or original p-values arranged to be monotonically increasing)\n",
    "    #   alpha_F: cutoff value for model entry given gamma_0 and current p_s value\n",
    "    #   gamma_F: FSR given current alpha_F and model size (== step num)\n",
    "    #       and\n",
    "    #   vector of alpha_F's for specified gamma's (g)\n",
    "    #       and\n",
    "    #   vector of estimated beta param's for final model (based on g0)\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data - make sure dat = pandas dataframes or else convert them\n",
    "    if bag==False:\n",
    "        if df_type(dat)==True:\n",
    "            if isinstance(dat,pd.DataFrame):\n",
    "                d = dat.copy()\n",
    "            else:\n",
    "                if isinstance(dat,np.ndarray):\n",
    "                    d = pd.DataFrame(dat)\n",
    "                    vnum = list(np.arange(d.shape[1])+1)\n",
    "                    vchr = list(np.repeat(\"V\",d.shape[1]))\n",
    "                    d.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "        else:\n",
    "            return df_type(dat)\n",
    "        \n",
    "        ### Remove missing values\n",
    "        d.dropna(inplace=True)\n",
    "        \n",
    "        ### Check that p < n to ensure regression solutions\n",
    "        if (d.shape[1]-1) >= d.shape[0]:\n",
    "            raise Exception(\"N must be > p for valid regression solutions\")\n",
    "    else:\n",
    "        d = dat.copy()\n",
    "    \n",
    "    ### If max model size not specified, select all possible cov.s\n",
    "    if max_size==None:\n",
    "        max_size = d.shape[1]-1\n",
    "        \n",
    "    y, x = pd.DataFrame(d.iloc[:,0]), d.iloc[:,1:]\n",
    "        \n",
    "    ### Perform forward selection\n",
    "    fwd_sel = forward(x, y, max_size, var_incl)\n",
    "    \n",
    "    ### Save order of covariate entry into model\n",
    "    cov_entry_order = cov_order(d.columns.values[1:], max_size, var_incl)\n",
    "    \n",
    "    ### Compute p-value of each covariate entering the model\n",
    "    p_orig = pval_comp(max_size)\n",
    "    \n",
    "    ### Arrange p-values in mono. inc. order\n",
    "    p_mono = np.array([max(p_orig[:(i+1)]) for i in range(len(p_orig))])\n",
    "        \n",
    "    ### Gamma_F computation\n",
    "    g_F = gamma_F(p_mono, d.shape[1], max_size)\n",
    "    \n",
    "    ### Check if betaout desired, if so compute beta_hat of model corresponding to specific gamma0\n",
    "    if betaout==True or bag==True:\n",
    "        betahats = beta_est(x, y, g0, g_F, cov_entry_order)\n",
    "        \n",
    "    ### Check if bagging desired\n",
    "    if bag==False: \n",
    "        ### Alpha_F computation for all steps in fwd sel proc\n",
    "        a_F = alpha_F(g0, d.shape[1]-1, max_size)\n",
    "        \n",
    "        ### Model size\n",
    "        S = np.arange(max_size)+1\n",
    "        \n",
    "        ### Combine S, Cov_names, p-vals, sorted p-vals, alpha_F, gamma_F into table\n",
    "        fsr_results = fsrtable(S, cov_entry_order, p_orig, p_mono, a_F, g_F)\n",
    "        \n",
    "        ### Return selected output: FSR table (+ betahat) (+ alpha_specific)\n",
    "        if gs!=None: \n",
    "            ### Compute alpha_F for specific gammas (gs)\n",
    "            if betaout==True:\n",
    "                return fsr_results, betahats, alpha_F_g(gs, g_F, d.shape[1]-1)\n",
    "            else:\n",
    "                return fsr_results, alpha_F_g(gs, g_F, d.shape[1]-1)\n",
    "        else:\n",
    "            if betaout==True:\n",
    "                return fsr_results, betahats\n",
    "            else:\n",
    "                return fsr_results\n",
    "    else:\n",
    "        return betahats, alpha_F_g(g0, g_F, d.shape[1]-1), len(betahats)\n",
    "\n",
    "    \n",
    "    \n",
    "def bagfsr(dat,g0,B=200,max_s=None,v_incl=None,prec=4):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat    = python dataframe of original p covariates, 1 outcome (in first col.): n x p+1\n",
    "    #   g0     = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   B      = integer of number of bagged samples\n",
    "    #   max_s  = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   v_incl = array of cols corresponding to those vars to force into model\n",
    "    #   prec   = integer of precision (num digits) desired in beta-hat parameter estimates of final model\n",
    "    \n",
    "    ### Output: \n",
    "    #   Mean of betahats\n",
    "    #   SEs of betahats\n",
    "    #   Avg alpha-to-enter\n",
    "    #   Avg model size\n",
    "    #   Prop of times each var included in model\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data - make sure X, Y = pandas dataframes or else convert them\n",
    "    if df_type(dat)==True:\n",
    "        if isinstance(dat,pd.DataFrame):\n",
    "            d = dat.copy()\n",
    "        else:\n",
    "            if isinstance(dat,np.ndarray):\n",
    "                d = pd.DataFrame(dat)\n",
    "                vnum = list(np.arange(d.shape[1])+1)\n",
    "                vchr = list(np.repeat(\"V\",d.shape[1]))\n",
    "                d.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "    else:\n",
    "        return df_type(dat)\n",
    "    \n",
    "    ### Remove missing values\n",
    "    d.dropna(inplace=True)\n",
    "    \n",
    "    ### check that p < n to ensure regression solutions\n",
    "    if (d.shape[1]-1) >= d.shape[0]:\n",
    "        raise Exception(\"N must be > p for valid regression solutions\")\n",
    "    \n",
    "    ### Create array to keep track of number of times vars enter model\n",
    "    nentries = pd.DataFrame(np.zeros(d.shape[1]-1),index=d.columns.values[1:])\n",
    "    \n",
    "    ### Create array to store all estimated coefficients, ses, alphas, sizes\n",
    "    allbetas = pd.DataFrame(np.zeros([B,(d.shape[1]-1)]),columns=d.columns.values[1:])\n",
    "    allses = allbetas.copy()\n",
    "    alphas = []\n",
    "    sizes = []\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    ### Bagging loops\n",
    "    for i in range(B):\n",
    "\n",
    "        # Draw with replacement from rows of data\n",
    "        n_row = d.shape[0]\n",
    "        rand_row = np.random.randint(0,n_row,n_row)\n",
    "        newdat = d.iloc[rand_row,:]\n",
    "        newdat.index = np.arange(n_row)+1\n",
    "        \n",
    "        ### Obtain FSR results\n",
    "        fsrout = ffsr(newdat.iloc[:,1:],pd.DataFrame(newdat.iloc[:,0]),g0,bag=True,max_size=max_s,var_incl=v_incl)\n",
    "        allbetas.loc[i,fsrout[0].index.values] = fsrout[0].iloc[:,0]\n",
    "        allses.loc[i,fsrout[0].index.values] = fsrout[0].iloc[:,1]\n",
    "        alphas.append(fsrout[1])\n",
    "        sizes.append(fsrout[2])\n",
    "\n",
    "        ### Update counts num times var included\n",
    "        nentries.loc[fsrout[0].index[np.abs(np.around(fsrout[0].iloc[:,0],prec))>0]] += 1\n",
    "        \n",
    "    ### Compute averages\n",
    "    avgbeta = np.around(allbetas.mean(axis=0),prec) # mean across rows / colmeans == mean of each cov's betahat\n",
    "    avgse = np.around(allses.mean(axis=0),prec)\n",
    "    avgalpha = np.mean(alphas)\n",
    "    avgsize = np.mean(sizes)\n",
    "    var_props = nentries/float(B)\n",
    "    cov_res = pd.concat([avgbeta,avgse,var_props],axis=1)\n",
    "    cov_res.columns = ['betahat','betase','prop_incl']\n",
    "    \n",
    "    return cov_res, avgalpha, avgsize\n",
    "    \n",
    "    \n",
    "\n",
    "# Notes: \n",
    "# 1. appropriate transformations are expected to have been applied prior to utilization of FSR algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = bagfsr(X,Y,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>betahat</th>\n",
       "      <th>betase</th>\n",
       "      <th>prop_incl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td> 5</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td> 6</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td> 5</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     betahat  betase  prop_incl\n",
       "V1         0       0          0\n",
       "V2         0       0          0\n",
       "V3         5       0          1\n",
       "V4         6       0          1\n",
       "V5         0       0          0\n",
       "V6         0       0          0\n",
       "V7         4       0          1\n",
       "V8         0       0          0\n",
       "V9         0       0          0\n",
       "V10        0       0          0\n",
       "V11        5       0          1\n",
       "V12        0       0          0\n",
       "V13        0       0          0\n",
       "V14        0       0          0\n",
       "V15        0       0          0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.038899999999999997, 6.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
