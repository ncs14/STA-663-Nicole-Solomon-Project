{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%file ffsr.py\n",
    "\"\"\" Pseudocode for Fast FSR algorithm \"\"\"\n",
    "\n",
    "\"\"\" Date: 4/8/15 \n",
    "    Modified: Profile primary function ffsr \"\"\"\n",
    "\n",
    "\"\"\" Date: 4/17/15\n",
    "    Modified: Corrected p-value function, p-mono corrected \"\"\"\n",
    "\n",
    "\"\"\" Date: 4/19/15\n",
    "    Modified: Corrected gamma_F function to correctly handle duplicate p-values \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" Data type check \"\"\"\n",
    "def df_type(dat):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   dat = dataset whose type is to be checked / transformed\n",
    "    \n",
    "    ### Output:\n",
    "    #   error msg or True boolean\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    if isinstance(dat,pd.DataFrame)==False and isinstance(dat,np.ndarray)==False:\n",
    "        raise Exception(\"Data must be pandas DataFrame\")\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" p-value computation function \"\"\"\n",
    "def pval_comp(max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of p-values of each covariate at its given entry step\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.stats as st\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    # Pull RSS values & num_obs from fwd_proc object\n",
    "    rss = np.array(ro.r('fwd$rss'))\n",
    "    N = np.array(ro.r('fwd$nn'))\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(rss)-1\n",
    "    \n",
    "    # vector of model sizes\n",
    "    sizes = np.arange(max_size)+1\n",
    "    \n",
    "    # compute the F stats as defined above where p_f - p_r = 1 for each iteration\n",
    "    fstats = (rss[0:max_size] - rss[1:(max_size+1)]) / (rss[1:(max_size+1)] / (N - (sizes+1)))\n",
    "    \n",
    "    # return the p-values by comparing these stats to the F distn: F(1, n - p_f)\n",
    "    return 1 - st.f.cdf(fstats, 1, N-(sizes+1))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Covariate model entry order \"\"\"\n",
    "def cov_order(xcolnames,max_size=None,col_incl=None):\n",
    "    \n",
    "    # Input params:\n",
    "    #   xcolnames = array of names of covariates (same order as columns in original dataset)\n",
    "    #   max_size  = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl  = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    # array of covariate names sorted according to order of entry into the model\n",
    "    \n",
    "    ### NOTE: fwd should be a global-env R object (requires running 'forward' fcn prior to this fcn) ###\n",
    "    \n",
    "    import numpy as np\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = len(xcolnames)\n",
    "        \n",
    "    ### Pull the cov entry order\n",
    "    vorder = ro.r('fwd$vorder[-1]') # remove intercept\n",
    "    vorder = vorder[0:max_size] # keep only the max model size number of covs\n",
    "    \n",
    "    ### Shift these values down by two (one to exclude intercept, one to make python indices)\n",
    "    vorderinds = np.array(vorder)-2\n",
    "    \n",
    "    ### Rearrange the var order st forced vars are at start of list\n",
    "    if col_incl==None:\n",
    "        col_incl = np.arange(max_size)+1\n",
    "    keep = xcolnames[[col_incl-1]] # pull var names of those vars forced into model (this is an array)\n",
    "    poss = [x for x in xcolnames if x not in keep] # pull var names of those not forced in (this is a list)\n",
    "    col_names = np.array(list(keep)+poss) # = rearranged array of varnames w/forced-in vars at start of list\n",
    "    \n",
    "    ### Sort the columns of X in order to obtain the var names in the entry order\n",
    "    return col_names[vorderinds[::]]\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\" Forward selection function \"\"\"\n",
    "def forward(x,y,max_size=None,col_incl=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x        = python dataframe of original p covariates, n x p\n",
    "    #   y        = python outcome dataframe, n x 1\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    #   col_incl = array vector of columns to forcefully include in all models\n",
    "    \n",
    "    ### Output:\n",
    "    # regsubsets R object -- the raw full output of the forward selection proc\n",
    "    \n",
    "    ### Load python packages to call R functions\n",
    "    import rpy2.robjects as ro\n",
    "    import pandas.rpy.common as com\n",
    "    \n",
    "    ### Convert x and y to R matrices <-- MAKE SURE x,y input == DATAFRAMES (or else change them to df's)!!!\n",
    "    ### and declare as R objects in global environment\n",
    "    ro.globalenv['x2'] = com.convert_to_r_matrix(x)\n",
    "    ro.globalenv['y2'] = com.convert_to_r_matrix(y)\n",
    "    if max_size==None:\n",
    "        max_size = x.shape[1]\n",
    "    ro.globalenv['maxv'] = ro.Vector(max_size)\n",
    "    if col_incl==None:\n",
    "        ro.r('coli=NULL')\n",
    "    else:\n",
    "        ro.globalenv['coli'] = ro.FloatVector(col_incl[:])\n",
    "    \n",
    "    ### Perform forward selection with regsubsets function\n",
    "    ro.globalenv['fwd'] = ro.r('leaps::regsubsets(x=x2,y=y2,method=\"forward\",nvmax=maxv,force.in=coli)')\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Gamma computation \"\"\"\n",
    "def gamma_F(pvs, ncov, max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   pvs      = vector of p-values (sorted or unsorted) from forward sel procedure\n",
    "    #   ncov     = integer total number of covariates in data\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of gamma_F values\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = ncov\n",
    "        \n",
    "    # Create indices == model size at given step, call this S\n",
    "    S = np.arange(max_size)+1\n",
    "    \n",
    "    # gamma_F_i = p_s_i * (ncov - S_i) / (1 + S_i)\n",
    "    g_F = pvs * (ncov - S) / (1 + S)\n",
    "    \n",
    "    # Check for duplicate p-values\n",
    "    dups = list(set([x for x in list(pvs) if list(pvs).count(x) > 1]))\n",
    "    for i in range(len(dups)): g_F[pvs==dups[i]] = min(g_F[pvs==dups[i]])\n",
    "    \n",
    "    # if table run on all vars, the last gamma = 0,\n",
    "    #  instead set equal to the last pv_sort == final rate of unimp var inclusion\n",
    "    if(g_F[-1]==0): \n",
    "        g_F[-1]=pvs[-1]\n",
    "    \n",
    "    return g_F\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for model selection \"\"\"\n",
    "def alpha_F(g0, ncov, max_size=None):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   g0       = float pre-specified FSR (gamma0)\n",
    "    #   ncov     = integer total number of covariates in data\n",
    "    #   max_size = integer max no. of vars in final model (largest model size desired)\n",
    "    \n",
    "    ### Output:\n",
    "    # array of alpha_F values\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if max_size==None:\n",
    "        max_size = ncov\n",
    "        \n",
    "    # Create indices == model size at given step, call this S\n",
    "    S = np.arange(max_size)+1\n",
    "    \n",
    "    # alpha_F_i = gamma_0 * (1 + S_i) / (ncov - S_i)\n",
    "    alpha_F = g0 * (1 + S) / (ncov - S)\n",
    "    \n",
    "    # if table run on all vars, the last alpha = inf\n",
    "    #  instead set equal to 1 == include all vars\n",
    "    alpha_F[np.isinf(alpha_F)] = 1.\n",
    "    \n",
    "    return alpha_F        \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" Alpha computation for specific gamma \"\"\"\n",
    "def alpha_F_g(g, gf, ncov):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   g    = float or vector (length k) of specified FSR at which to compute alpha\n",
    "    #   gf   = vector gamma_F's computed from gamma0, pv_sorted\n",
    "    #          used to compute largest size model (S) for which gamma_F < g\n",
    "    #   ncov = integer of total number covariates in data\n",
    "    \n",
    "    ### Output:\n",
    "    # integer alpha_F value\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    ### Compute model size for gf closest to (but still <) g\n",
    "    #S = np.array([max(np.which(x<=y)) for x in gf y in g])+1\n",
    "    if isinstance(g,np.ndarray): # if g is a vector\n",
    "        s_s = [np.where(gf>y) for y in g]\n",
    "        S = np.array([min(x[0]) for x in s_s])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "    else: # if g is a number\n",
    "        S = min(np.where(gf>g)[0])\n",
    "        return g * (1 + S) / (ncov - S)\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" Beta-hat computation for specific gamma \"\"\"\n",
    "def beta_est(x, y, g, gf, vname):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x      = python dataframe of original p covariates, n x p\n",
    "    #   y      = python outcome dataframe, n x 1\n",
    "    #   g      = float of specified FSR at which to compute alpha\n",
    "    #   gf     = vector gamma_F's computed from gamma0, pv_sorted\n",
    "    #            used to compute largest size model (S) for which gamma_F < g\n",
    "    #   vname  = ordered vector of names of vars entered into model under forward selection\n",
    "    \n",
    "    ### Output:\n",
    "    # array of estimated parameters\n",
    "    \n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    ### Compute model size corresponding to g\n",
    "    S = min(np.where(gf>g)[0])\n",
    "\n",
    "    ### Pull the cov names of those vars included in the above size model\n",
    "    modvars = vname[:S]\n",
    "\n",
    "    ### Fit the linear model using the selected model vars\n",
    "    fit = sm.OLS(y,x.loc[:,list(modvars)]).fit()\n",
    "    betaout = pd.DataFrame([fit.params,fit.bse]).T\n",
    "    betaout.columns = ['beta','beta_se']\n",
    "    \n",
    "    return betaout\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\" FSR Results Table \"\"\"\n",
    "def fsrtable(size, vname, p_orig, p_mono, alphaf, gammaf, prec_f=4):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   size   = model size at each step of forward sel proc                   [S]\n",
    "    #   vname  = variable name that entered at each step (num vars = p)        [Var]\n",
    "    #   p_orig = p-values at each step                                         [p]\n",
    "    #   p_mono = ascending p-values                                            [p_s]\n",
    "    #   alphaf = alpha-to-enter (p-value cutoff) for model entry at each step  [alpha_F]\n",
    "    #   gammaf = FSR at each step                                              [gamma_F]\n",
    "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
    "    \n",
    "    ### Output:\n",
    "    # table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Convert all arrays to dataframes\n",
    "    sized = pd.DataFrame(size)\n",
    "    vnamed = pd.DataFrame(vname)\n",
    "    p_od = pd.DataFrame(np.around(p_orig,prec_f))\n",
    "    p_sd = pd.DataFrame(np.around(p_mono,prec_f))\n",
    "    ad = pd.DataFrame(np.around(alphaf,prec_f))\n",
    "    gd = pd.DataFrame(np.around(gammaf,prec_f))\n",
    "    \n",
    "    ### Combine the arrays\n",
    "    tab = pd.concat([sized,vnamed,p_od,p_sd,ad,gd],axis=1)\n",
    "    tab.columns = ['S','Var','p','p_s','alpha_F','gamma_F']\n",
    "    \n",
    "    return tab\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\" FastFSR function \"\"\"\n",
    "def ffsr(X,Y,g0=0.05,betaout=False,gs=None,max_size=None,var_incl=None,bag=False,prec_f=4,prec_b=6):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   x        = python dataframe of original p covariates, n x p\n",
    "    #   y        = python outcome dataframe, n x 1\n",
    "    #   g0       = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   betaout  = boolean of whether to include estimated betahats from final selected model\n",
    "    #   gs       = float or vector of gamma's at which to specifically compute alpha_F\n",
    "    #   max_size = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   var_incl = array of cols corresponding to those vars to force into model\n",
    "    #   bag      = boolean of whether to output FSR table (non-bagging results) or reduced output for bagging purposes\n",
    "    #   prec_f   = integer of precision (num digits) desired in FSR output table\n",
    "    #   prec_b   = integer of precision (num digits) desired in beta-hat parameter estimates of final model\n",
    "    \n",
    "    ### Output: \n",
    "    #      (note: gamma = FSR, gamma_0 = pre-specified/desired FSR)\n",
    "    # Table of [S   Var   p   p_s   alpha_F   gamma_F], dim = num_steps(== p) x 6\n",
    "    #   S:       model size at given step\n",
    "    #   Var:     name of var that entered at given step\n",
    "    #   p:       p-value of var that entered at given step\n",
    "    #   p_s:     sorted p-value (vector or original p-values sorted in increasing order)\n",
    "    #   alpha_F: cutoff value for model entry given gamma_0 and current p_s value\n",
    "    #   gamma_F: FSR given current alpha_F and model size (== step num)\n",
    "    #       and\n",
    "    # Vector of alpha_F's for specified gamma's (g)\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data - make sure X, Y = pandas dataframes or else convert them\n",
    "    if df_type(X)==True:\n",
    "        if isinstance(X,pd.DataFrame):\n",
    "            x = X.copy()\n",
    "        else:\n",
    "            if isinstance(X,np.ndarray):\n",
    "                x = pd.DataFrame(X)\n",
    "                vnum = list(np.arange(x.shape[1])+1)\n",
    "                vchr = list(np.repeat(\"V\",x.shape[1]))\n",
    "                x.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "    else:\n",
    "        return df_type(X)\n",
    "    if df_type(Y)==True:\n",
    "        if isinstance(Y,pd.DataFrame):\n",
    "            y = Y.copy()\n",
    "        else:\n",
    "            if isinstance(Y,np.ndarray):\n",
    "                y = pd.DataFrame(Y)\n",
    "    else:\n",
    "        return df_type(Y)\n",
    "    \n",
    "    # remove missing values\n",
    "    yna = np.isnan(y).any(axis=1)\n",
    "    xna = np.isnan(x).any(axis=1).reshape(x.shape[0],1)\n",
    "    anyna = np.array([int(max(a,b)) for a,b in zip(xna,yna)])\n",
    "    missrow = np.where(anyna==1)[0]\n",
    "    y = y.drop(y.index[missrow])\n",
    "    x = x.drop(x.index[missrow])\n",
    "    \n",
    "    # check that p < n to ensure regression solutions\n",
    "    if x.shape[1] >= x.shape[0]:\n",
    "        raise Exception(\"N must be > p for valid regression solutions\")\n",
    "    \n",
    "    ### If max model size not specified, select all possible cov.s\n",
    "    if max_size==None:\n",
    "        max_size = x.shape[1]\n",
    "        \n",
    "    ### Perform forward selection\n",
    "    fwd_sel = forward(x, y, max_size, var_incl)\n",
    "    \n",
    "    ### Save order of covariate entry into model\n",
    "    cov_entry_order = cov_order(x.columns.values, max_size, var_incl)\n",
    "    \n",
    "    ### Compute p-value of each covariate entering the model\n",
    "    p_orig = pval_comp(max_size)\n",
    "    \n",
    "    ### Sort p-values in ascending order\n",
    "    p_sort = np.array([max(p_orig[:(i+1)]) for i in range(len(p_orig))])\n",
    "        \n",
    "    ### Gamma_F computation\n",
    "    g_F = gamma_F(p_sort, x.shape[1], max_size)\n",
    "    \n",
    "    ### Check if betaout desired, if so compute beta_hat of model corresponding to specific gamma0\n",
    "    if betaout==True or bag==True:\n",
    "        betahats = beta_est(x, y, g0, g_F, cov_entry_order)\n",
    "        \n",
    "    ### Check if bagging desired\n",
    "    if bag==False: \n",
    "        ### Alpha_F computation for all steps in fwd sel proc\n",
    "        a_F = alpha_F(g0, x.shape[1], max_size)\n",
    "        \n",
    "        ### Model size\n",
    "        S = np.arange(max_size)+1\n",
    "        \n",
    "        ### Combine S, Cov_names, p-vals, sorted p-vals, alpha_F, gamma_F into table\n",
    "        fsr_results = fsrtable(S, cov_entry_order, p_orig, p_sort, a_F, g_F)\n",
    "        \n",
    "        ### Return selected output: FSR table (+ betahat) (+ alpha_specific)\n",
    "        if gs!=None: \n",
    "            ### Compute alpha_F for specific gammas (gs)\n",
    "            if betaout==True:\n",
    "                return fsr_results, np.around(betahats, prec_b), alpha_F_g(gs, g_F, x.shape[1])\n",
    "            else:\n",
    "                return fsr_results, alpha_F_g(gs, g_F, x.shape[1])\n",
    "        else:\n",
    "            if betaout==True:\n",
    "                return fsr_results, np.around(betahats, prec_b)\n",
    "            else:\n",
    "                return fsr_results\n",
    "    else:\n",
    "        return betahats, alpha_F_g(g0, g_F, x.shape[1]), len(betahats)\n",
    "\n",
    "    \n",
    "    \n",
    "def bagfsr(X,Y,g0,B=200,max_s=None,v_incl=None,prec=4):\n",
    "    \n",
    "    ### Input params:\n",
    "    #   X      = python dataframe of original p covariates, n x p\n",
    "    #   Y      = python outcome dataframe, n x 1\n",
    "    #   g0     = float pre-specified FSR of interest (\"gamma0\")\n",
    "    #   B      = integer of number of bagged samples\n",
    "    #   max_s  = integer of largest model size == max num vars to incl in final model (default = num covs in dataset)\n",
    "    #   v_incl = array of cols corresponding to those vars to force into model\n",
    "    #   prec   = integer of precision (num digits) desired in beta-hat parameter estimates of final model\n",
    "    \n",
    "    ### Output: \n",
    "    #   Mean of betahats\n",
    "    #   SEs of betahats\n",
    "    #   Avg alpha-to-enter\n",
    "    #   Avg model size\n",
    "    #   Prop of times each var included in model\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Clean and check data - make sure X, Y = pandas dataframes or else convert them\n",
    "    if df_type(X)==True:\n",
    "        if isinstance(X,pd.DataFrame):\n",
    "            x = X.copy()\n",
    "        else:\n",
    "            if isinstance(X,np.ndarray):\n",
    "                x = pd.DataFrame(X)\n",
    "                vnum = list(np.arange(x.shape[1])+1)\n",
    "                vchr = list(np.repeat(\"V\",x.shape[1]))\n",
    "                x.columns = [a + str(b) for a,b in zip(vchr,vnum)]\n",
    "    else:\n",
    "        return df_type(X)\n",
    "    if df_type(Y)==True:\n",
    "        if isinstance(Y,pd.DataFrame):\n",
    "            y = Y.copy()\n",
    "        else:\n",
    "            if isinstance(Y,np.ndarray):\n",
    "                y = pd.DataFrame(Y)\n",
    "    else:\n",
    "        return df_type(Y)\n",
    "    \n",
    "    ### Combine data into single dataframe\n",
    "    dat = pd.concat([y,x],axis=1)\n",
    "    \n",
    "    ### Create array to keep track of number of times vars enter model\n",
    "    nentries = pd.DataFrame(np.zeros(x.shape[1]),index=x.columns.values)\n",
    "    \n",
    "    ### Create array to store all estimated coefficients, ses, alphas, sizes\n",
    "    allbetas = pd.DataFrame(np.zeros([B,x.shape[1]]),columns=x.columns.values)\n",
    "    allses = allbetas.copy()\n",
    "    alphas = []\n",
    "    sizes = []\n",
    "    \n",
    "    ### Bagging loops\n",
    "    for i in range(B):\n",
    "\n",
    "        # Draw with replacement from rows of data\n",
    "        np.random.seed(1234)\n",
    "        n_row = dat.shape[0]\n",
    "        rand_row = np.random.randint(0,n_row,n_row)\n",
    "        newdat = dat.iloc[rand_row,:]\n",
    "        newdat.index = np.arange(n_row)+1\n",
    "        \n",
    "        ### Obtain FSR results\n",
    "        prec_all = 8 # precision of output\n",
    "        fsrout = ffsr(newdat.iloc[:,1:],pd.DataFrame(newdat.iloc[:,0]),g0,bag=True,max_size=max_s,var_incl=v_incl)\n",
    "        allbetas.loc[i,fsrout[0].index.values] = np.around(fsrout[0].iloc[:,0],prec_all)\n",
    "        allses.loc[i,fsrout[0].index.values] = np.around(fsrout[0].iloc[:,1],prec_all)\n",
    "        alphas.append(fsrout[1])\n",
    "        sizes.append(fsrout[2])\n",
    "\n",
    "        ### Update counts num times var included\n",
    "        nentries.loc[fsrout[0].index[np.abs(np.around(fsrout[0].iloc[:,0],prec_all))>0]] += 1\n",
    "        \n",
    "    ### Compute averages\n",
    "    avgbeta = allbetas.mean(axis=0) # mean across rows / colmeans == mean of each cov's betahat\n",
    "    avgse = allses.mean(axis=0)\n",
    "    avgalpha = np.mean(alphas)\n",
    "    avgsize = np.mean(sizes)\n",
    "    var_props = nentries/float(B)\n",
    "    cov_res = pd.concat([avgbeta,avgse,var_props],axis=1)\n",
    "    cov_res.columns = ['betahat','betase','prop_incl']\n",
    "    \n",
    "    return cov_res, avgalpha, avgsize\n",
    "    \n",
    "    \n",
    "\n",
    "# Notes: \n",
    "# 1. appropriate transformations are expected to have been applied prior to utilization of FSR algorithm\n",
    "\n",
    "# To-do:\n",
    "# 1. adjust betaest fcn and ffsr to allow for specification of intercept and whether data should be normalized in estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "X = np.random.multivariate_normal(np.zeros(15),np.eye(15),(100))\n",
    "beta = np.array([0.,0,5,6,0,0,4,0,0,0,5,0,0,0,0]).reshape(15,1) # signif betas: 3,4,7,11\n",
    "Y = X.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y2 = pd.DataFrame(Y)\n",
    "X2 = pd.DataFrame(X)\n",
    "X2.columns = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# possible python function to replace R regsubsets\n",
    "def seq_forw_select(features, max_k, criterion_func, print_steps=False):\n",
    "    \"\"\"\n",
    "    Implementation of a Sequential Forward Selection algorithm.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        features (list): The feature space as a list of features.\n",
    "        max_k: Termination criterion; the size of the returned feature subset.\n",
    "        criterion_func (function): Function that is used to evaluate the\n",
    "            performance of the feature subset.\n",
    "        print_steps (bool): Prints the algorithm procedure if True.\n",
    "    \n",
    "    Returns the selected feature subset, a list of features of length max_k.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialization\n",
    "    feat_sub = []\n",
    "    k = 0\n",
    "    d = len(features)\n",
    "    if max_k > d:\n",
    "        max_k = d\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # Inclusion step\n",
    "        if print_steps:\n",
    "            print('\\nInclusion from feature space', features)\n",
    "        crit_func_max = criterion_func(feat_sub + [features[0]])\n",
    "        best_feat = features[0]\n",
    "        for x in features[1:]:\n",
    "            crit_func_eval = criterion_func(feat_sub + [x])\n",
    "            if crit_func_eval > crit_func_max:\n",
    "                crit_func_max = crit_func_eval\n",
    "                best_feat = x\n",
    "        feat_sub.append(best_feat)\n",
    "        if print_steps:\n",
    "            print('include: {} -> feature subset: {}'.format(best_feat, feat_sub))\n",
    "        features.remove(best_feat)\n",
    "        \n",
    "        # Termination condition\n",
    "        k = len(feat_sub)\n",
    "        if k == max_k:\n",
    "            break\n",
    "                \n",
    "    return feat_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Comparisons with R code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   var   pval  pvmax    Rsq      g\n",
       "1    4 0.0000 0.0000 0.3778 0.0000\n",
       "2    7 0.0000 0.0000 0.6402 0.0000\n",
       "3    3 0.0000 0.0000 0.8519 0.0000\n",
       "4   11 0.0000 0.0000 1.0000 0.0000\n",
       "5    2 0.0003 0.0003 1.0000 0.0004\n",
       "6   10 0.0078 0.0078 1.0000 0.0100\n",
       "7    1 0.0116 0.0116 1.0000 0.0116\n",
       "8    5 0.0973 0.0973 1.0000 0.0584\n",
       "9   15 0.0800 0.0973 1.0000 0.0584\n",
       "10  12 0.1259 0.1259 1.0000 0.0572\n",
       "11  14 0.2040 0.2040 1.0000 0.0680\n",
       "12   8 0.2480 0.2480 1.0000 0.0572\n",
       "13   9 0.3679 0.3679 1.0000 0.0526\n",
       "14   6 0.6474 0.6474 1.0000 0.0432\n",
       "15  13 0.7110 0.7110 1.0000 0.0000\n",
       " [1] 1.029110e-11 3.568257e-13 0.000000e+00 0.000000e+00 2.608114e-04\n",
       " [6] 7.805512e-03 1.157750e-02 9.725851e-02 8.002123e-02 1.259084e-01\n",
       "[11] 2.040472e-01 2.479664e-01 3.679118e-01 6.474203e-01 7.110283e-01\n",
       " [1]  1  5  8  4 12  3 11  2  6 16 13 15  9 10  7 14\n",
       " [1] \"np\"        \"nrbar\"     \"d\"         \"rbar\"      \"thetab\"    \"first\"    \n",
       " [7] \"last\"      \"vorder\"    \"tol\"       \"rss\"       \"bound\"     \"nvmax\"    \n",
       "[13] \"ress\"      \"ir\"        \"nbest\"     \"lopt\"      \"il\"        \"ier\"      \n",
       "[19] \"xnames\"    \"method\"    \"force.in\"  \"force.out\" \"sserr\"     \"intercept\"\n",
       "[25] \"lindep\"    \"nullrss\"   \"nn\"       \n",
       " [1] \"(Intercept)\" \"V1\"          \"V2\"          \"V3\"          \"V4\"         \n",
       " [6] \"V5\"          \"V6\"          \"V7\"          \"V8\"          \"V9\"         \n",
       "[11] \"V10\"         \"V11\"         \"V12\"         \"V13\"         \"V14\"        \n",
       "[16] \"V15\"        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i X2,Y2\n",
    "\n",
    "fsr.fast<-function(x,y,gam0=.05,digits=4,print=T,plot=F){\n",
    "# estimated alpha for forward selection using Fast FSR (no simulation)\n",
    "# typical call: fsr.fast(x=ncaa2[,1:19],y=ncaa2[,20])->out\n",
    "# for use inside simulation loops, set print=F and plot=F\n",
    "# version 7 circa Nov. 2009, modified to handle partially blank colnames\n",
    "require(leaps)\n",
    "ok<-complete.cases(x,y)\n",
    "x<-x[ok,]                            # get rid of na's\n",
    "y<-y[ok]                             # since regsubsets can't handle na's\n",
    "m<-ncol(x)\n",
    "n<-nrow(x)\n",
    "if(m >= n) m1 <- n-5  else m1<-m     # to get rid of NA's in pv\n",
    "vm<-1:m1\n",
    "as.matrix(x)->x                      # in case x is a data frame\n",
    "if(any(colnames(x)==\"\"))colnames(x)<-NULL       # if only partially named columns\n",
    "colnames(x)<-colnames(x,do.NULL=F,prefix=\"\")    # corrects for no colnames\n",
    "pvm<-rep(0,m1)                       # to create pvm below\n",
    "regsubsets(x,y,method=\"forward\")->out.x\n",
    "pv.orig<-1-pf((out.x$rss[vm]-out.x$rss[vm+1])*(out.x$nn-(vm+1))/out.x$rss[vm+1],1,out.x$nn-(vm+1))\n",
    "for (i in 1:m1){pvm[i]<-max(pv.orig[1:i])}  # sequential max of pvalues\n",
    "alpha<-c(0,pvm)\n",
    "ng<-length(alpha)\n",
    "S<-rep(0,ng)                         # will contain num. of true entering in orig.\n",
    "real.seq<-data.frame(var=(out.x$vorder-1)[2:(m1+1)],pval=pv.orig,\n",
    "         pvmax=pvm,Rsq=round(1-out.x$rss[2:(m1+1)]/out.x$rss[1],4))\n",
    "for (ia in 2:ng){                    # loop through alpha values for S=size\n",
    "S[ia] <- sum(pvm<=alpha[ia])         # size of models at alpha[ia], S[1]=0\n",
    "}\n",
    "ghat<-(m-S)*alpha/(1+S)              # gammahat_ER\n",
    "# add additional points to make jumps\n",
    "alpha2<-alpha[2:ng]-.0000001\n",
    "ghat2<-(m-S[1:(ng-1)])*alpha2/(1+S[1:(ng-1)])\n",
    "zp<-data.frame(a=c(alpha,alpha2),g=c(ghat,ghat2))\n",
    "zp<-zp[order(zp$a),]\n",
    "gmax<-max(zp$g)\n",
    "index.max<-which.max(zp$g)           # index of largest ghat\n",
    "alphamax<-zp$a[index.max]            # alpha with largest ghat\n",
    "# gmax<-max(ghat)\n",
    "# index.max<-which.max(ghat)           # index of largest ghat\n",
    "# alphamax<-alpha[index.max]           # alpha with largest ghat\n",
    "ind<-(ghat <= gam0 & alpha<=alphamax)*1\n",
    "Sind<-S[max(which(ind > 0))]           # model size with ghat just below gam0\n",
    "alphahat.fast<-(1+Sind)*gam0/(m-Sind)  # ER est.\n",
    "size1<-sum(pvm<=alphahat.fast)+1       # size of model including intercept\n",
    "x<-x[,colnames(x)[(out.x$vorder-1)[2:size1]]]\n",
    "if(size1>1) x.ind<-(out.x$vorder-1)[2:size1]  else x.ind<-0\n",
    "if (size1==1) {mod <- lm(y~1)} else {mod <- lm(y~x)}\n",
    "# ghat3<-(m-size1+1)*alpha/(1+S)         # uses final ku est.\n",
    "ghat4<-(m-size1+1)*alpha/(1+0:m)\n",
    "#res<-data.frame(real.seq,ghigh=ghat2,glow=ghat[2:ng])\n",
    "res<-data.frame(real.seq,g=ghat[2:ng])\n",
    "if(print)print(round(res,digits))\n",
    "#if(plot){\n",
    "#plot(zp$a,zp$g,type=\"b\",xlab=\"Alpha\",ylab=\"Estimated Gamma\",xlim=c(0,alphamax))\n",
    "#points(alphahat.fast,gam0,pch=19)\n",
    "#lines(c(-1,alphahat.fast),c(gam0,gam0))\n",
    "#lines(c(alphahat.fast,alphahat.fast),c(-1,gam0))\n",
    "#}  # ends plot\n",
    "return(list(mod=mod,size=size1-1,x.ind=x.ind,alphahat.ER=alphahat.fast))\n",
    "}\n",
    "\n",
    "x2 = as.matrix(X2)\n",
    "y2 = as.matrix(Y2)\n",
    "\n",
    "system.time(fsr.fast(x=x2,y=y2))\n",
    "    \n",
    "leaps::regsubsets(x2,y2,method=\"forward\")->outt\n",
    "#print(outt$rss)\n",
    "print(1-pf((outt$rss[1:15]-outt$rss[1:15+1])*(outt$nn-(1:15+1))/outt$rss[1:15+1],1,outt$nn-(1:15+1)))\n",
    "print(outt$vorder)\n",
    "print(names(outt))\n",
    "print(outt$xnames)\n",
    "\n",
    "###\n",
    "#rss2 = round(outt$rss,30)\n",
    "#print(rss2)\n",
    "#print(1-pf((rss2[1:15]-rss2[1:15+1])*(outt$nn-(1:15+1))/rss2[1:15+1],1,outt$nn-(1:15+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 163 ms, sys: 18 ms, total: 181 ms\n",
      "Wall time: 183 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Var</th>\n",
       "      <th>p</th>\n",
       "      <th>p_s</th>\n",
       "      <th>alpha_F</th>\n",
       "      <th>gamma_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td>  1</td>\n",
       "      <td>  V4</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0071</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td>  2</td>\n",
       "      <td>  V7</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0115</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td>  3</td>\n",
       "      <td>  V3</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0167</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td>  4</td>\n",
       "      <td> V11</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0227</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>  5</td>\n",
       "      <td>  V2</td>\n",
       "      <td> 0.0003</td>\n",
       "      <td> 0.0003</td>\n",
       "      <td> 0.0300</td>\n",
       "      <td> 0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>  6</td>\n",
       "      <td> V10</td>\n",
       "      <td> 0.0078</td>\n",
       "      <td> 0.0078</td>\n",
       "      <td> 0.0389</td>\n",
       "      <td> 0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td>  7</td>\n",
       "      <td>  V1</td>\n",
       "      <td> 0.0116</td>\n",
       "      <td> 0.0116</td>\n",
       "      <td> 0.0500</td>\n",
       "      <td> 0.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>  8</td>\n",
       "      <td>  V5</td>\n",
       "      <td> 0.0973</td>\n",
       "      <td> 0.0973</td>\n",
       "      <td> 0.0643</td>\n",
       "      <td> 0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td>  9</td>\n",
       "      <td> V15</td>\n",
       "      <td> 0.0800</td>\n",
       "      <td> 0.0973</td>\n",
       "      <td> 0.0833</td>\n",
       "      <td> 0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 10</td>\n",
       "      <td> V12</td>\n",
       "      <td> 0.1259</td>\n",
       "      <td> 0.1259</td>\n",
       "      <td> 0.1100</td>\n",
       "      <td> 0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 11</td>\n",
       "      <td> V14</td>\n",
       "      <td> 0.2040</td>\n",
       "      <td> 0.2040</td>\n",
       "      <td> 0.1500</td>\n",
       "      <td> 0.0680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 12</td>\n",
       "      <td>  V8</td>\n",
       "      <td> 0.2480</td>\n",
       "      <td> 0.2480</td>\n",
       "      <td> 0.2167</td>\n",
       "      <td> 0.0572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> 13</td>\n",
       "      <td>  V9</td>\n",
       "      <td> 0.3679</td>\n",
       "      <td> 0.3679</td>\n",
       "      <td> 0.3500</td>\n",
       "      <td> 0.0526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td> 14</td>\n",
       "      <td>  V6</td>\n",
       "      <td> 0.6474</td>\n",
       "      <td> 0.6474</td>\n",
       "      <td> 0.7500</td>\n",
       "      <td> 0.0432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> 15</td>\n",
       "      <td> V13</td>\n",
       "      <td> 0.7110</td>\n",
       "      <td> 0.7110</td>\n",
       "      <td> 1.0000</td>\n",
       "      <td> 0.7110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     S  Var       p     p_s  alpha_F  gamma_F\n",
       "0    1   V4  0.0000  0.0000   0.0071   0.0000\n",
       "1    2   V7  0.0000  0.0000   0.0115   0.0000\n",
       "2    3   V3  0.0000  0.0000   0.0167   0.0000\n",
       "3    4  V11  0.0000  0.0000   0.0227   0.0000\n",
       "4    5   V2  0.0003  0.0003   0.0300   0.0004\n",
       "5    6  V10  0.0078  0.0078   0.0389   0.0100\n",
       "6    7   V1  0.0116  0.0116   0.0500   0.0116\n",
       "7    8   V5  0.0973  0.0973   0.0643   0.0584\n",
       "8    9  V15  0.0800  0.0973   0.0833   0.0584\n",
       "9   10  V12  0.1259  0.1259   0.1100   0.0572\n",
       "10  11  V14  0.2040  0.2040   0.1500   0.0680\n",
       "11  12   V8  0.2480  0.2480   0.2167   0.0572\n",
       "12  13   V9  0.3679  0.3679   0.3500   0.0526\n",
       "13  14   V6  0.6474  0.6474   0.7500   0.0432\n",
       "14  15  V13  0.7110  0.7110   1.0000   0.7110"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "ffsr(X2,Y2,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# comparing the above R result with %%time result of my algorithm shows the following reduction:\n",
    "# user: - 3ms,  sys: + 1ms,  elapsed: - 3ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.02911013e-11   3.56714658e-13   1.11022302e-16   0.00000000e+00\n",
      "   2.60811395e-04   7.80551222e-03   1.15774957e-02   9.72585093e-02\n",
      "   8.00212258e-02   1.25908410e-01   2.04047217e-01   2.47966386e-01\n",
      "   3.67911801e-01   6.47420278e-01   7.11028331e-01]\n"
     ]
    }
   ],
   "source": [
    "### Discover error in p-value computation:\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "import pandas.rpy.common as com\n",
    "from rpy2.robjects.packages import importr\n",
    "import scipy.stats as st\n",
    "\n",
    "fwd_r = forward(X2,Y2)\n",
    "#print ro.r('fwd$rss')\n",
    "#print ro.r('log(fwd$rss)')\n",
    "rs = np.array(ro.r('fwd$rss'))\n",
    "rs2 = np.around(rs,30)\n",
    "ms = len(rs)-1\n",
    "#print np.around(np.log(rs),6)\n",
    "#print\n",
    "#fs = (rs[0:ms] - rs[1:(ms+1)]) / (rs[1:(ms+1)] / (float(X2.shape[0]) - (np.arange(ms)+1.)))\n",
    "#print np.around(1. - st.f.cdf(fs, 1, float(X2.shape[0])-(np.arange(ms)+1.)),12)\n",
    "# fs2 = (rs2[0:ms] - rs2[1:(ms+1)]) / (rs2[1:(ms+1)] / (float(X2.shape[0]) - (np.arange(ms)+1.)))\n",
    "# print 1. - st.f.cdf(fs2, 1, float(X2.shape[0])-(np.arange(ms)+1.))\n",
    "fs = (rs[0:ms] - rs[1:(ms+1)])* (float(X2.shape[0]) - (np.arange(ms)+2.)) / rs[1:(ms+1)] \n",
    "print 1. - st.f.cdf(fs, 1, float(X2.shape[0])-(np.arange(ms)+2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 5.950425e+01 7.074218e+01 1.371970e+02 9.273244e+31 1.440562e+01\n",
      " [6] 7.394751e+00 6.637493e+00 2.807482e+00 3.134854e+00 2.386851e+00\n",
      "[11] 1.637391e+00 1.352818e+00 8.193067e-01 2.106624e-01 1.381848e-01\n",
      "\n",
      "[  5.950425e+01   7.074218e+01   1.371970e+02   9.273244e+31   1.440562e+01\n",
      "   7.394751e+00   6.637493e+00   2.807482e+00   3.134854e+00   2.386851e+00\n",
      "   1.637391e+00   1.352818e+00   8.193067e-01   2.106624e-01   1.381848e-01]\n",
      "\n",
      " [1] 1.029110e-11 3.568257e-13 0.000000e+00 0.000000e+00 2.608114e-04\n",
      " [6] 7.805512e-03 1.157750e-02 9.725851e-02 8.002123e-02 1.259084e-01\n",
      "[11] 2.040472e-01 2.479664e-01 3.679118e-01 6.474203e-01 7.110283e-01\n",
      "\n",
      "[  1.029110e-11   3.567147e-13   1.110223e-16   0.000000e+00   2.608114e-04\n",
      "   7.805512e-03   1.157750e-02   9.725851e-02   8.002123e-02   1.259084e-01\n",
      "   2.040472e-01   2.479664e-01   3.679118e-01   6.474203e-01   7.110283e-01]\n",
      "[  1.029110e-11   1.029110e-11   1.029110e-11   1.029110e-11   2.608114e-04\n",
      "   7.805512e-03   1.157750e-02   9.725851e-02   9.725851e-02   1.259084e-01\n",
      "   2.040472e-01   2.479664e-01   3.679118e-01   6.474203e-01   7.110283e-01]\n"
     ]
    }
   ],
   "source": [
    "### Discover error in p-value computation:\n",
    "\n",
    "#print ro.r('fwd$rss[1:15]-fwd$rss[2:16]')\n",
    "print ro.r('(fwd$rss[1:15]-fwd$rss[1:15+1])*(fwd$nn-(1:15+1))/fwd$rss[1:15+1]')\n",
    "#print ro.r('fwd$nn-(1:15+1)')\n",
    "#print ro.r('(fwd$rss[1:15]-fwd$rss[1:15+1])/fwd$rss[1:15+1]')\n",
    "np.set_printoptions(precision=6)\n",
    "#print rs[0:ms]-rs[1:(ms+1)]\n",
    "#print np.exp(np.log(rs[0:ms]-rs[1:(ms+1)])-np.log(rs[1:]))* (X2.shape[0] - (np.arange(ms)+2.))\n",
    "#print \n",
    "print (rs[0:ms]-rs[1:(ms+1)])*(X2.shape[0] - (np.arange(ms)+2.))/rs[1:]\n",
    "print\n",
    "print ro.r('1-pf((fwd$rss[1:15]-fwd$rss[1:15+1])*(fwd$nn-(1:15+1))/fwd$rss[1:15+1],1,fwd$nn-(1:15+1))')\n",
    "pp =  1-st.f.cdf((rs[0:ms]-rs[1:(ms+1)])*(X2.shape[0] - (np.arange(ms)+2.))/rs[1:],1,X2.shape[0] - (np.arange(ms)+2.))\n",
    "print pp\n",
    "#print [i for i in np.arange(15)]\n",
    "ppp = np.array([max(pp[:(i+1)]) for i in range(len(pp))])\n",
    "print ppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.203771e-11   4.459477e-11   3.087330e-11   2.264042e-11   4.346857e-04\n",
      "   1.003566e-02   1.157750e-02   7.564551e-02   5.835511e-02   5.723110e-02\n",
      "   6.801574e-02   5.722301e-02   5.255883e-02   4.316135e-02   0.000000e+00]\n",
      "[  2.264042e-11   2.264042e-11   2.264042e-11   2.264042e-11   4.346857e-04\n",
      "   1.003566e-02   1.157750e-02   5.835511e-02   5.835511e-02   5.723110e-02\n",
      "   6.801574e-02   5.722301e-02   5.255883e-02   4.316135e-02   0.000000e+00]\n"
     ]
    }
   ],
   "source": [
    "dp=list(set([x for x in list(ppp) if list(ppp).count(x) > 1]))\n",
    "\n",
    "# Create indices == model size at given step, call this S\n",
    "s = np.arange(ms)+1\n",
    "\n",
    "# gamma_F_i = p_s_i * (ncov - S_i) / (1 + S_i)\n",
    "gf = ppp * (15 - s) / (1 + s)\n",
    "print gf\n",
    "\n",
    "# Check for duplicate p-values\n",
    "# dupps = list(set([x for x in list(pv_s) if list(pv_s).count(x) > 1]))\n",
    "# g_F[pv_s==dupps] = min(g_F[pv_s==dupps])\n",
    "\n",
    "# # if table run on all vars, the last gamma = 0,\n",
    "# #  instead set equal to the last pv_sort == final rate of unimp var inclusion\n",
    "# if(g_F[-1]==0): \n",
    "#     g_F[-1]=pv_s[-1]\n",
    "    \n",
    "#     return np.around(g_F,prec_f)\n",
    "# gf=gamma_F(ppp,X2.shape[1])\n",
    "# print gf\n",
    "gf2 = gf.copy()\n",
    "for i in range(len(dp)): gf2[ppp==dp[i]] = min(gf[ppp==dp[i]])\n",
    "print gf2\n",
    "#ffsr(X2,Y2,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.999993e-05,  -6.999993e-05,  -6.999993e-05,  -6.999993e-05,\n",
       "         4.180190e-04,   1.002280e-02,   1.156750e-02,   5.834911e-02,\n",
       "         5.834911e-02,   5.722655e-02,   6.801241e-02,   5.722070e-02,\n",
       "         5.255740e-02,   4.316069e-02,   0.000000e+00])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf3 = (ppp-0.00001) * (15 - s) / (1 + s)\n",
    "for i in range(len(dp)): gf3[ppp==dp[i]] = min(gf3[ppp==dp[i]])\n",
    "gf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# OPTIMIZATION PLAN:\n",
    "\n",
    "\"\"\"  \n",
    "NOTE: numba, numbapro do not work on (any) some of my FSR functions due to incompatibility w/list comprehension (among other things)\n",
    "note to self: write subfunction to remove missing values and attempt following optimization strategies\n",
    "\n",
    "1. Try to vectorize additional lines of code to improve speed/efficiency\n",
    "2. Try to translate some functions into C-code (perhaps using numexpr), or else find c equivalents which would be faster than the \n",
    "   given python versions\n",
    "    a. This should be viable for those functions that do not manipulate R objects\n",
    "    b. Perhaps search for a C/C++ forward selection function (likely faster than regsubsets which I am calling from R)\n",
    "3. Closely examine code to determine where memory is needlessly being used (e.g. are duplicates being made unnecessarily)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
